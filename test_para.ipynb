{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distrib\n",
    "import kornia\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "J = 4\n",
    "N = 3\n",
    "B = 1\n",
    "magn = 5\n",
    "grad = True\n",
    "#預設機率與強度超參數的初始值\n",
    "magnNorm = torch.ones(1)*magn/10.0 # normalize to 10 like in RandAugment\n",
    "probNorm = torch.ones(1)*1/(K-2) # 1/(K-2) probability\n",
    "magnLogit = torch.log(magnNorm/(1-magnNorm)) # convert to logit\n",
    "probLogit = torch.log(probNorm/(1-probNorm)) # convert to logit\n",
    "# affine transforms (mid, range)\n",
    "angle = [0.0, 30.0] # [-30.0:30.0] rotation angle\n",
    "trans = [0.0, 0.45] # [-0.45:0.45] X/Y translate\n",
    "shear = [0.0, 0.30] # [-0.30:0.30] X/Y shear\n",
    "scale = [1.0, 0.50] # [ 0.50:1.50] X/Y scale\n",
    "# color transforms (mid, range)\n",
    "bri = [0.0, 0.9] # [-0.9:0.9] brightness\n",
    "con = [1.0, 0.9] # [0.1:1.9] contrast\n",
    "sat = [0.1, 1.9] # [-0.30:0.30] saturation\n",
    "#hue = [1.0, 0.50] # [ 0.70:1.30] hue\n",
    "#gam = [1.0, 0.50] # [ 0.70:1.30] gamma\n",
    "# actP: 機率的激活函數，actM: 強度的激活函數\n",
    "actP = nn.Sigmoid()\n",
    "actM = nn.Sigmoid()\n",
    "# 建立機率與強度的可學習超參數矩陣 shape = (擴增方法數量*資料數量)\n",
    "paramP = nn.Parameter(probLogit*torch.ones(K+J,N), requires_grad=grad)\n",
    "paramM = nn.Parameter(magnLogit*torch.ones(K+J,N), requires_grad=grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [0]\n",
    "paramPos = torch.log(    actP(paramP[:,idx])) # [-Inf:0] [擴增方法數, data point number] 取針對該資料的使用機率之參數\n",
    "paramNeg = torch.log(1.0-actP(paramP[:,idx])) # [-Inf:0] [擴增方法數, data point number] 取針對該資料的不使用機率之參數\n",
    "paramM = actM(paramM[:,idx]) # (K+J)xB [0:1], default=magn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramP = torch.cat([paramPos.view(-1,1), paramNeg.view(-1,1)], dim=1) # B*(K+J)x2\n",
    "# reparametrize probabilities and magnitudes\n",
    "sampleP = F.gumbel_softmax(paramP, tau=1.0, hard=True) # B*(K+J)x2\n",
    "sampleP = sampleP[:,0]\n",
    "sampleP = sampleP.reshape(K+J,B)\n",
    "# # reparametrize magnitudes\n",
    "# #sampleM = paramM[:K] * torch.rand(K,B).to(device) # KxB, prior: U[0,1]\n",
    "sampleM = paramM[:K] * torch.randn(K,B) # KxB, prior: N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R: torch.tensor = torch.zeros(B,3,3) + torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANG: torch.tensor = sampleP[0] * sampleM[0] * angle[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=10\n",
    "H=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayeh/miniconda3/envs/autodo/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "CTR: torch.tensor = torch.cat((W*torch.ones(B)//2, H*torch.ones(B)//2)).view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scale factor\n",
    "SCL: torch.tensor = torch.zeros_like(CTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCL[:,0] = scale[0] + sampleP[3] * sampleM[3] * scale[1] # mid + B(0/1)*U[0,1]*M/10\n",
    "SCL[:,1] = scale[0] + sampleP[4] * sampleM[4] * scale[1] # mid + B(0/1)*U[0,1]*M/10\n",
    "R[:,0:2] = kornia.get_rotation_matrix2d(CTR, ANG, SCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T: torch.tensor = torch.zeros_like(R) + torch.eye(3)\n",
    "T[:,0,2] = W * sampleP[1] * sampleM[1] * trans[1]\n",
    "T[:,1,2] = H * sampleP[2] * sampleM[2] * trans[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('autodo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab1c5bcb2e12e60572765b72c297d9973a4d1aa919b4c84abd79a2f642f5ee12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
