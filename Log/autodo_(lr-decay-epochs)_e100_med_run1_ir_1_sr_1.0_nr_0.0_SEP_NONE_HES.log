[2022-08-17 12:42:10,473] implicit-augment.py->main line:123 [INFO]Namespace(aug_model='SEP', data='./local_data', dataset='med', epochs=100, gpu='1', hyper_alpha=0.01, hyper_beta=0, hyper_est=True, hyper_gamma=0, hyper_iters=5, hyper_opt='HES', hyper_steps=0, imbalance_ratio=1, log_interval=500, los_model='NONE', lr_cosine=True, lr_decay_epochs='30,55,80', lr_decay_rate=0.1, lr_warm=True, lr_warm_epochs=5, no_cuda=False, noise_ratio=0.0, overfit=False, oversplit=False, plot_debug=False, run_folder='run1', scale=1, subsample_ratio=1.0, workers=4)
[2022-08-17 12:45:37,916] implicit-augment.py->main line:123 [INFO]Namespace(aug_model='SEP', data='./local_data', dataset='med', epochs=100, gpu='1', hyper_alpha=0.01, hyper_beta=0, hyper_est=True, hyper_gamma=0, hyper_iters=5, hyper_opt='HES', hyper_steps=0, imbalance_ratio=1, log_interval=500, los_model='NONE', lr_cosine=True, lr_decay_epochs='30,55,80', lr_decay_rate=0.1, lr_warm=True, lr_warm_epochs=5, no_cuda=False, noise_ratio=0.0, overfit=False, oversplit=False, plot_debug=False, run_folder='run1', scale=1, subsample_ratio=1.0, workers=4)
[2022-08-17 12:45:48,103] implicit-augment.py->main line:337 [INFO]Valid/Train Split: 2563/10248
[2022-08-17 12:45:48,108] implicit-augment.py->main line:403 [INFO]Test/Valid/Train Split: 1423/2563/10248 out of total 14234 train images
[2022-08-17 12:45:48,161] implicit-augment.py->main line:446 [INFO]Run: ./local_data/med/run1/UNet_e100_opt_HES_est_True_aug_model_SEP_los_model_NONE_ir_1_sr_1.0_nr_0.0
[2022-08-17 12:45:48,162] implicit-augment.py->main line:454 [INFO]0% (0/100)
[2022-08-17 12:45:50,079] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 0, batch_idx: 0, global_img_step: 0
[2022-08-17 12:53:23,503] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 0, batch_idx: 1000, global_img_step: 1
[2022-08-17 13:00:57,175] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 0, batch_idx: 2000, global_img_step: 2
[2022-08-17 13:05:11,666] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 0	 Inner Train loss: 0.8198, acc=0.6903, lr=0.000010	
[2022-08-17 13:06:04,938] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 0	 Test loss: 0.7491, score: 0.7227
[2022-08-17 13:06:04,939] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 0 with 0.7227 Dice score
[2022-08-17 13:06:05,196] implicit-augment.py->main line:454 [INFO]1% (1/100)
[2022-08-17 13:06:06,285] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 1, batch_idx: 0, global_img_step: 3
[2022-08-17 13:13:40,353] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 1, batch_idx: 1000, global_img_step: 4
[2022-08-17 13:21:14,469] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 1, batch_idx: 2000, global_img_step: 5
[2022-08-17 13:25:28,899] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 1	 Inner Train loss: 0.7460, acc=0.7217, lr=0.000010	
[2022-08-17 13:26:22,721] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 1	 Test loss: 0.7172, score: 0.7435
[2022-08-17 13:26:22,722] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 1 with 0.7435 Dice score
[2022-08-17 13:26:23,436] implicit-augment.py->main line:454 [INFO]2% (2/100)
[2022-08-17 13:26:24,479] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 2, batch_idx: 0, global_img_step: 6
[2022-08-17 13:33:59,222] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 2, batch_idx: 1000, global_img_step: 7
[2022-08-17 13:41:33,326] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 2, batch_idx: 2000, global_img_step: 8
[2022-08-17 13:45:47,975] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 2	 Inner Train loss: 0.7061, acc=0.7380, lr=0.000010	
[2022-08-17 13:46:41,716] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 2	 Test loss: 0.6741, score: 0.7569
[2022-08-17 13:46:41,717] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 2 with 0.7569 Dice score
[2022-08-17 13:46:42,162] implicit-augment.py->main line:454 [INFO]3% (3/100)
[2022-08-17 13:46:43,185] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 3, batch_idx: 0, global_img_step: 9
[2022-08-17 13:54:17,566] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 3, batch_idx: 1000, global_img_step: 10
[2022-08-17 14:01:51,797] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 3, batch_idx: 2000, global_img_step: 11
[2022-08-17 14:06:06,286] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 3	 Inner Train loss: 0.6862, acc=0.7456, lr=0.000010	
[2022-08-17 14:07:00,138] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 3	 Test loss: 0.6406, score: 0.7508
[2022-08-17 14:07:00,140] implicit-augment.py->main line:454 [INFO]4% (4/100)
[2022-08-17 14:07:01,185] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 4, batch_idx: 0, global_img_step: 12
[2022-08-17 14:14:35,423] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 4, batch_idx: 1000, global_img_step: 13
[2022-08-17 14:22:09,902] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 4, batch_idx: 2000, global_img_step: 14
[2022-08-17 14:26:24,417] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 4	 Inner Train loss: 0.6675, acc=0.7529, lr=0.000010	
[2022-08-17 14:27:18,422] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 4	 Test loss: 0.6344, score: 0.7643
[2022-08-17 14:27:18,424] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 4 with 0.7643 Dice score
[2022-08-17 14:27:18,834] implicit-augment.py->main line:454 [INFO]5% (5/100)
[2022-08-17 14:27:19,999] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 5, batch_idx: 0, global_img_step: 15
[2022-08-17 14:34:54,346] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 5, batch_idx: 1000, global_img_step: 16
[2022-08-17 14:42:28,745] automodels.py->Med_innerTrain line:1037 [INFO]Train epoch: 5, batch_idx: 2000, global_img_step: 17
[2022-08-17 14:46:43,281] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 5	 Inner Train loss: 0.6560, acc=0.7578, lr=0.000010	
[2022-08-17 14:47:36,874] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 5	 Test loss: 0.6306, score: 0.7584
[2022-08-17 14:47:36,875] implicit-augment.py->main line:454 [INFO]6% (6/100)
[2022-08-17 14:47:38,320] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849,
        -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849])
[2022-08-17 14:47:38,324] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-08-17 14:47:38,497] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 6, batch_idx: 0, global_img_step: 18, aug_ops:[('contrast', tensor([0.1074]))]
[2022-08-17 14:47:38,498] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.013939	gLtNorm 61.2602 (61.2602)	gLvNorm 0.1728 (0.1728)	mvpNorm 57.4125 (57.4125)

[2022-08-17 15:10:43,736] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 6, batch_idx: 2500, global_img_step: 19, aug_ops:[('saturation', tensor([0.6031]))]
[2022-08-17 15:10:43,738] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.018300	gLtNorm 37.0319 (25.6396)	gLvNorm 0.3325 (0.3065)	mvpNorm 43.8611 (26.0789)

[2022-08-17 15:33:12,077] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 6, batch_idx: 5000, global_img_step: 20, aug_ops:[('idenity', [1.0])]
[2022-08-17 15:33:12,078] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.022661	gLtNorm 3.0633 (25.8791)	gLvNorm 0.0730 (0.3023)	mvpNorm 2.9959 (26.4087)

[2022-08-17 15:34:21,767] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 6, batch_idx: 0, global_img_step: 21, aug_ops:[('idenity', [1.0])]
[2022-08-17 15:48:35,117] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 6, batch_idx: 1000, global_img_step: 22, aug_ops:[('idenity', [1.0])]
[2022-08-17 16:02:50,217] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 6, batch_idx: 2000, global_img_step: 23, aug_ops:[('gaussian blur', tensor([0.3250])), ('elastic transform', tensor([0.1887])), ('ShearY', tensor([0.4032]))]
[2022-08-17 16:10:52,806] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 6	 Inner Train loss: 0.8397, acc=0.6797, lr=0.000010	
[2022-08-17 16:11:46,892] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 6	 Test loss: 0.7178, score: 0.7191
[2022-08-17 16:11:46,893] implicit-augment.py->main line:454 [INFO]7% (7/100)
[2022-08-17 16:11:47,861] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.6474, -2.3224, -2.3224, -2.3224, -2.3224, -2.4849, -2.6474, -2.4849,
        -2.4849, -2.6474, -2.3224, -2.3224, -2.6474, -2.3224, -2.6474])
[2022-08-17 16:11:47,866] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-08-17 16:11:48,105] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 7, batch_idx: 0, global_img_step: 24, aug_ops:[('TranslateX', tensor([0.1278]))]
[2022-08-17 16:11:48,105] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.022877	gLtNorm 1.6654 (1.6654)	gLvNorm 0.6268 (0.6268)	mvpNorm 3.3559 (3.3559)

[2022-08-17 16:34:20,233] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 7, batch_idx: 2500, global_img_step: 25, aug_ops:[('idenity', [1.0])]
[2022-08-17 16:34:20,234] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.027238	gLtNorm 8.6973 (1.8123)	gLvNorm 0.2759 (0.4453)	mvpNorm 6.0212 (2.2687)

[2022-08-17 16:56:53,655] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 7, batch_idx: 5000, global_img_step: 26, aug_ops:[('idenity', [1.0])]
[2022-08-17 16:56:53,656] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.031599	gLtNorm 2.8295 (1.7358)	gLvNorm 0.0112 (0.4430)	mvpNorm 2.8625 (2.1919)

[2022-08-17 16:58:05,303] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 7, batch_idx: 0, global_img_step: 27, aug_ops:[('idenity', [1.0])]
[2022-08-17 17:12:20,091] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 7, batch_idx: 1000, global_img_step: 28, aug_ops:[('Hsv', tensor([-0.7356, -0.3569, -0.3764])), ('gaussian blur', tensor([0.2955]))]
[2022-08-17 17:26:42,264] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 7, batch_idx: 2000, global_img_step: 29, aug_ops:[('idenity', [1.0])]
[2022-08-17 17:34:41,548] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 7	 Inner Train loss: 0.7816, acc=0.7036, lr=0.000010	
[2022-08-17 17:35:35,472] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 7	 Test loss: 0.6734, score: 0.7463
[2022-08-17 17:35:35,474] implicit-augment.py->main line:454 [INFO]8% (8/100)
[2022-08-17 17:35:36,786] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3889, -2.5809, -2.5809, -2.5809, -2.5809, -2.4849, -2.3889, -2.4849,
        -2.4849, -2.3890, -2.0639, -2.0639, -2.3889, -2.0639, -2.3889])
[2022-08-17 17:35:36,792] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-08-17 17:35:37,022] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 8, batch_idx: 0, global_img_step: 30, aug_ops:[('Hsv', tensor([-0.2095,  0.1502, -0.0273]))]
[2022-08-17 17:35:37,023] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.031816	gLtNorm 0.1628 (0.1628)	gLvNorm 0.4696 (0.4696)	mvpNorm 0.6208 (0.6208)

[2022-08-17 17:58:09,486] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 8, batch_idx: 2500, global_img_step: 31, aug_ops:[('idenity', [1.0])]
[2022-08-17 17:58:09,487] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.036177	gLtNorm 0.1660 (1.1632)	gLvNorm 1.0931 (0.3988)	mvpNorm 1.3784 (1.6212)

[2022-08-17 18:21:08,751] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 8, batch_idx: 5000, global_img_step: 32, aug_ops:[('idenity', [1.0])]
[2022-08-17 18:21:08,752] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.040538	gLtNorm 0.0472 (1.0978)	gLvNorm 0.1137 (0.4012)	mvpNorm 0.1067 (1.5502)

[2022-08-17 18:22:20,103] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 8, batch_idx: 0, global_img_step: 33, aug_ops:[('gaussian noise', tensor([-0.2089]))]
[2022-08-17 18:36:27,952] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 8, batch_idx: 1000, global_img_step: 34, aug_ops:[('contrast', tensor([0.0881])), ('Rotate', tensor([0.0227]))]
[2022-08-17 18:50:37,187] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 8, batch_idx: 2000, global_img_step: 35, aug_ops:[('contrast', tensor([0.5289])), ('Hed', tensor([ 0.4344, -0.8415,  0.1725])), ('ShearX', tensor([0.1000]))]
[2022-08-17 18:58:33,930] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 8	 Inner Train loss: 0.7731, acc=0.7076, lr=0.000010	
[2022-08-17 18:59:26,982] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 8	 Test loss: 0.6972, score: 0.7269
[2022-08-17 18:59:26,983] implicit-augment.py->main line:454 [INFO]9% (9/100)
[2022-08-17 18:59:28,277] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.7528, -2.2170, -2.9448, -2.9448, -2.2170, -2.4849, -2.0251, -2.4849,
        -2.4849, -2.0251, -2.4278, -1.7000, -2.0251, -1.7000, -2.7528])
[2022-08-17 18:59:28,283] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3639])
[2022-08-17 18:59:28,524] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 9, batch_idx: 0, global_img_step: 36, aug_ops:[('idenity', [1.0])]
[2022-08-17 18:59:28,525] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.040754	gLtNorm 0.3666 (0.3666)	gLvNorm 0.3106 (0.3106)	mvpNorm 1.0348 (1.0348)

[2022-08-17 19:21:47,332] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 9, batch_idx: 2500, global_img_step: 37, aug_ops:[('idenity', [1.0])]
[2022-08-17 19:21:47,333] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.045115	gLtNorm 0.4799 (1.4576)	gLvNorm 0.9279 (0.4791)	mvpNorm 0.2915 (1.8850)

[2022-08-17 19:43:59,972] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 9, batch_idx: 5000, global_img_step: 38, aug_ops:[('Hsv', tensor([ 0.4013, -0.2544, -0.0206])), ('gaussian blur', tensor([-0.0403]))]
[2022-08-17 19:43:59,974] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.049476	gLtNorm 0.4303 (1.4286)	gLvNorm 0.1133 (0.4839)	mvpNorm 0.5828 (1.8452)

[2022-08-17 19:45:07,158] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 9, batch_idx: 0, global_img_step: 39, aug_ops:[('contrast', tensor([-0.2997])), ('saturation', tensor([-0.2206])), ('Rotate', tensor([0.9890]))]
[2022-08-17 19:59:17,313] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 9, batch_idx: 1000, global_img_step: 40, aug_ops:[('Rotate', tensor([1.]))]
[2022-08-17 20:13:24,440] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 9, batch_idx: 2000, global_img_step: 41, aug_ops:[('TranslateX', tensor([0.4945]))]
[2022-08-17 20:21:22,959] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 9	 Inner Train loss: 0.7602, acc=0.7132, lr=0.000010	
[2022-08-17 20:22:15,877] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 9	 Test loss: 0.7039, score: 0.7152
[2022-08-17 20:22:15,879] implicit-augment.py->main line:454 [INFO]10% (10/100)
[2022-08-17 20:22:16,827] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3273, -2.6426, -3.3702, -2.5192, -2.6426, -2.4849, -1.5995, -2.4849,
        -2.4849, -1.5995, -2.8534, -1.2744, -2.4506, -2.1256, -2.3272])
[2022-08-17 20:22:16,833] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0617])
[2022-08-17 20:22:17,213] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 10, batch_idx: 0, global_img_step: 42, aug_ops:[('contrast', tensor([0.2555])), ('gaussian blur', tensor([0.0064])), ('sharpen', tensor([-0.1841]))]
[2022-08-17 20:22:17,214] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.049659	gLtNorm 0.1095 (0.1095)	gLvNorm 0.0591 (0.0591)	mvpNorm 0.1023 (0.1023)

[2022-08-17 20:44:38,955] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 10, batch_idx: 2500, global_img_step: 43, aug_ops:[('sharpen', tensor([0.3550]))]
[2022-08-17 20:44:38,956] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.049659	gLtNorm 0.2905 (0.5821)	gLvNorm 0.1121 (0.3327)	mvpNorm 0.2204 (0.8607)

[2022-08-17 21:06:50,645] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 10, batch_idx: 5000, global_img_step: 44, aug_ops:[('saturation', tensor([-0.2448]))]
[2022-08-17 21:06:50,646] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.049659	gLtNorm 0.1066 (0.5795)	gLvNorm 0.1017 (0.3266)	mvpNorm 0.0202 (0.8591)

[2022-08-17 21:07:57,830] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 10, batch_idx: 0, global_img_step: 45, aug_ops:[('TranslateY', tensor([-0.7840]))]
[2022-08-17 21:22:07,274] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 10, batch_idx: 1000, global_img_step: 46, aug_ops:[('ShearY', tensor([0.0185]))]
[2022-08-17 21:36:15,835] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 10, batch_idx: 2000, global_img_step: 47, aug_ops:[('idenity', [1.0])]
[2022-08-17 21:44:12,156] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 10	 Inner Train loss: 0.7568, acc=0.7143, lr=0.000010	
[2022-08-17 21:45:05,059] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 10	 Test loss: 0.6836, score: 0.7354
[2022-08-17 21:45:05,061] implicit-augment.py->main line:454 [INFO]11% (11/100)
[2022-08-17 21:45:06,040] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3273, -2.6426, -3.3702, -2.0226, -2.1460, -2.4849, -1.1030, -2.4849,
        -2.4849, -1.5995, -2.8534, -1.2744, -2.4506, -2.1256, -2.3272])
[2022-08-17 21:45:06,046] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0617])
[2022-08-17 21:45:06,315] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 11, batch_idx: 0, global_img_step: 48, aug_ops:[('gaussian noise', tensor([-0.0532]))]
[2022-08-17 21:45:06,316] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.049510	gLtNorm 0.2527 (0.2527)	gLvNorm 0.3476 (0.3476)	mvpNorm 0.2579 (0.2579)

[2022-08-17 22:07:21,889] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 11, batch_idx: 2500, global_img_step: 49, aug_ops:[('sharpen', tensor([0.6657])), ('ShearY', tensor([0.3477]))]
[2022-08-17 22:07:21,890] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.049510	gLtNorm 6.5017 (0.7912)	gLvNorm 0.2060 (0.4177)	mvpNorm 8.3260 (1.1951)

[2022-08-17 22:29:39,980] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 11, batch_idx: 5000, global_img_step: 50, aug_ops:[('contrast', tensor([0.7659]))]
[2022-08-17 22:29:39,982] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.049510	gLtNorm 0.2257 (0.7432)	gLvNorm 0.3150 (0.4135)	mvpNorm 0.2352 (1.1478)

[2022-08-17 22:30:47,197] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 11, batch_idx: 0, global_img_step: 51, aug_ops:[('idenity', [1.0])]
[2022-08-17 22:44:58,478] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 11, batch_idx: 1000, global_img_step: 52, aug_ops:[('Hsv', tensor([-0.1747,  0.1140,  0.4695])), ('ShearY', tensor([-0.3513]))]
[2022-08-17 22:59:08,846] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 11, batch_idx: 2000, global_img_step: 53, aug_ops:[('elastic transform', tensor([0.3650]))]
[2022-08-17 23:07:07,122] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 11	 Inner Train loss: 0.7461, acc=0.7194, lr=0.000010	
[2022-08-17 23:08:00,003] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 11	 Test loss: 0.7032, score: 0.7360
[2022-08-17 23:08:00,005] implicit-augment.py->main line:454 [INFO]12% (12/100)
[2022-08-17 23:08:00,978] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-1.8322, -2.1475, -2.8753, -2.5177, -2.6410, -2.4849, -1.5981, -2.4849,
        -2.4849, -1.1044, -3.3485, -0.7793, -1.9555, -2.6207, -1.8322])
[2022-08-17 23:08:00,984] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0000, -0.4951, -0.4951, -0.4951,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4951,
         0.0000, -0.0617])
[2022-08-17 23:08:01,239] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 12, batch_idx: 0, global_img_step: 54, aug_ops:[('idenity', [1.0])]
[2022-08-17 23:08:01,240] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.049334	gLtNorm 0.0446 (0.0446)	gLvNorm 0.3590 (0.3590)	mvpNorm 0.2189 (0.2189)

[2022-08-17 23:30:18,124] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 12, batch_idx: 2500, global_img_step: 55, aug_ops:[('idenity', [1.0])]
[2022-08-17 23:30:18,124] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.049334	gLtNorm 0.2031 (0.8679)	gLvNorm 1.2314 (0.3395)	mvpNorm 0.9210 (1.2061)

[2022-08-17 23:52:46,074] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 12, batch_idx: 5000, global_img_step: 56, aug_ops:[('Hed', tensor([ 0.2953, -1.0000,  0.4873])), ('gaussian noise', tensor([-0.4270])), ('ShearY', tensor([-0.1771]))]
[2022-08-17 23:52:46,075] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.049334	gLtNorm 3.8582 (0.8442)	gLvNorm 0.1745 (0.3338)	mvpNorm 3.4952 (1.1676)

[2022-08-17 23:53:54,110] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 12, batch_idx: 0, global_img_step: 57, aug_ops:[('idenity', [1.0])]
[2022-08-18 00:08:01,573] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 12, batch_idx: 1000, global_img_step: 58, aug_ops:[('gaussian noise', tensor([-0.1865])), ('ShearX', tensor([-0.6603]))]
[2022-08-18 00:22:06,430] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 12, batch_idx: 2000, global_img_step: 59, aug_ops:[('Hed', tensor([-0.0032,  0.0843,  1.0000])), ('sharpen', tensor([-0.9077])), ('TranslateX', tensor([0.1404]))]
[2022-08-18 00:30:00,027] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 12	 Inner Train loss: 0.7495, acc=0.7168, lr=0.000010	
[2022-08-18 00:30:52,893] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 12	 Test loss: 0.7080, score: 0.7347
[2022-08-18 00:30:52,894] implicit-augment.py->main line:454 [INFO]13% (13/100)
[2022-08-18 00:30:53,877] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3255, -1.6541, -2.3820, -3.0110, -3.1344, -2.4849, -2.0914, -2.4849,
        -2.4849, -1.5977, -3.8418, -0.2860, -2.4489, -2.1274, -1.3388])
[2022-08-18 00:30:53,882] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0000, -0.4951, -0.4951, -0.4951,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4951,
        -0.4933, -0.0617])
[2022-08-18 00:30:54,106] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 13, batch_idx: 0, global_img_step: 60, aug_ops:[('Equalize', tensor([-0.0832]))]
[2022-08-18 00:30:54,106] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.049131	gLtNorm 0.0250 (0.0250)	gLvNorm 0.5195 (0.5195)	mvpNorm 0.4997 (0.4997)

[2022-08-18 00:53:15,774] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 13, batch_idx: 2500, global_img_step: 61, aug_ops:[('idenity', [1.0])]
[2022-08-18 00:53:15,775] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.049131	gLtNorm 0.1432 (0.7492)	gLvNorm 0.0093 (0.4283)	mvpNorm 0.1624 (1.1479)

[2022-08-18 01:15:39,366] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 13, batch_idx: 5000, global_img_step: 62, aug_ops:[('elastic transform', tensor([0.4684]))]
[2022-08-18 01:15:39,367] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.049131	gLtNorm 0.0727 (0.7389)	gLvNorm 0.0394 (0.4279)	mvpNorm 0.0292 (1.1305)

[2022-08-18 01:16:47,509] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 13, batch_idx: 0, global_img_step: 63, aug_ops:[('ShearY', tensor([0.8864]))]
[2022-08-18 01:30:57,676] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 13, batch_idx: 1000, global_img_step: 64, aug_ops:[('Equalize', tensor([0.5225]))]
[2022-08-18 01:45:02,182] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 13, batch_idx: 2000, global_img_step: 65, aug_ops:[('brightness', tensor([0.5851]))]
[2022-08-18 01:52:59,073] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 13	 Inner Train loss: 0.7400, acc=0.7213, lr=0.000010	
[2022-08-18 01:53:52,055] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 13	 Test loss: 0.6801, score: 0.7300
[2022-08-18 01:53:52,056] implicit-augment.py->main line:454 [INFO]14% (14/100)
[2022-08-18 01:53:53,084] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.8168, -1.1629, -2.8727, -3.5018, -2.6431, -2.4849, -2.5803, -2.4849,
        -2.4849, -1.1065, -4.3331, -0.7773, -2.9402, -1.6361, -1.8301])
[2022-08-18 01:53:53,090] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.4913, -0.4951, -0.4951, -0.4951,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4913,  0.0000,  0.0038,
        -0.4933, -0.0617])
[2022-08-18 01:53:53,308] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 14, batch_idx: 0, global_img_step: 66, aug_ops:[('elastic transform', tensor([0.9110])), ('TranslateX', tensor([-0.3921]))]
[2022-08-18 01:53:53,309] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.048902	gLtNorm 0.0251 (0.0251)	gLvNorm 0.0789 (0.0789)	mvpNorm 0.0283 (0.0283)

[2022-08-18 02:16:12,873] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 14, batch_idx: 2500, global_img_step: 67, aug_ops:[('sharpen', tensor([-0.4016])), ('ShearX', tensor([-0.4511]))]
[2022-08-18 02:16:12,874] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.048902	gLtNorm 0.3520 (0.7722)	gLvNorm 0.0838 (0.2842)	mvpNorm 0.2350 (1.0837)

[2022-08-18 02:38:31,649] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 14, batch_idx: 5000, global_img_step: 68, aug_ops:[('Hsv', tensor([-0.2488, -0.6482, -0.1923]))]
[2022-08-18 02:38:31,650] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.048902	gLtNorm 0.1641 (0.8646)	gLvNorm 0.1876 (0.2847)	mvpNorm 0.3594 (1.1844)

[2022-08-18 02:39:38,701] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 14, batch_idx: 0, global_img_step: 69, aug_ops:[('brightness', tensor([0.0153])), ('Equalize', tensor([0.0153]))]
[2022-08-18 02:53:47,529] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 14, batch_idx: 1000, global_img_step: 70, aug_ops:[('Rotate', tensor([0.1102])), ('TranslateX', tensor([0.3255])), ('TranslateY', tensor([0.9818]))]
[2022-08-18 03:07:58,561] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 14, batch_idx: 2000, global_img_step: 71, aug_ops:[('ShearY', tensor([0.3005]))]
[2022-08-18 03:15:55,339] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 14	 Inner Train loss: 0.7299, acc=0.7244, lr=0.000010	
[2022-08-18 03:16:48,297] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 14	 Test loss: 0.6876, score: 0.7394
[2022-08-18 03:16:48,298] implicit-augment.py->main line:454 [INFO]15% (15/100)
[2022-08-18 03:16:49,318] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.3058, -0.6738, -2.3837, -3.9908, -3.1322, -2.4849, -3.0685, -2.4849,
        -2.4849, -0.6174, -3.8441, -0.2883, -2.4512, -2.1251, -2.3190])
[2022-08-18 03:16:49,324] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.4913, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000,  0.0000,  0.0000,  0.0000,  0.4913,  0.0000,  0.0038,
        -0.4933, -0.0617])
[2022-08-18 03:16:49,571] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 15, batch_idx: 0, global_img_step: 72, aug_ops:[('brightness', tensor([0.0045])), ('Hed', tensor([-0.2032,  0.4717, -0.2112])), ('gaussian noise', tensor([0.9858])), ('Rotate', tensor([-0.5388])), ('ShearY', tensor([0.7247]))]
[2022-08-18 03:16:49,571] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.048647	gLtNorm 0.0718 (0.0718)	gLvNorm 0.2610 (0.2610)	mvpNorm 0.5983 (0.5983)

[2022-08-18 03:39:09,461] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 15, batch_idx: 2500, global_img_step: 73, aug_ops:[('contrast', tensor([0.2671])), ('gaussian blur', tensor([-0.4822])), ('Rotate', tensor([-0.6148]))]
[2022-08-18 03:39:09,462] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.048647	gLtNorm 0.1120 (0.9887)	gLvNorm 0.0131 (0.3488)	mvpNorm 0.1871 (1.3567)

[2022-08-18 04:01:27,539] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 15, batch_idx: 5000, global_img_step: 74, aug_ops:[('idenity', [1.0])]
[2022-08-18 04:01:27,540] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.048647	gLtNorm 0.0183 (1.0500)	gLvNorm 0.1299 (0.3495)	mvpNorm 0.1331 (1.4156)

[2022-08-18 04:02:35,158] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 15, batch_idx: 0, global_img_step: 75, aug_ops:[('saturation', tensor([0.0252])), ('Hsv', tensor([-0.2669, -0.1392,  0.1250])), ('elastic transform', tensor([-0.0013]))]
[2022-08-18 04:16:45,814] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 15, batch_idx: 1000, global_img_step: 76, aug_ops:[('brightness', tensor([-0.6201])), ('Hed', tensor([-0.0394, -0.0844,  0.0040])), ('gaussian blur', tensor([0.0806])), ('ShearY', tensor([0.4601]))]
[2022-08-18 04:30:53,623] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 15, batch_idx: 2000, global_img_step: 77, aug_ops:[('contrast', tensor([0.5396])), ('sharpen', tensor([0.1401]))]
[2022-08-18 04:38:47,747] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 15	 Inner Train loss: 0.7363, acc=0.7217, lr=0.000010	
[2022-08-18 04:39:40,704] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 15	 Test loss: 0.6691, score: 0.7544
[2022-08-18 04:39:40,705] implicit-augment.py->main line:454 [INFO]16% (16/100)
[2022-08-18 04:39:41,684] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.7922, -1.1603, -1.8972, -3.5043, -3.6186, -2.4849, -2.5821, -2.4849,
        -2.4849, -1.1039, -3.3576,  0.1982, -1.9648, -2.6115, -2.8055])
[2022-08-18 04:39:41,689] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.4913, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000,  0.0000,  0.0000,  0.0000,  0.4913,  0.0000,  0.4903,
        -0.4933, -0.0617])
[2022-08-18 04:39:41,923] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 16, batch_idx: 0, global_img_step: 78, aug_ops:[('TranslateX', tensor([-0.5048]))]
[2022-08-18 04:39:41,923] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.048366	gLtNorm 0.0530 (0.0530)	gLvNorm 0.1553 (0.1553)	mvpNorm 0.0310 (0.0310)

[2022-08-18 05:02:01,308] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 16, batch_idx: 2500, global_img_step: 79, aug_ops:[('Hsv', tensor([-0.4112,  0.7451, -0.9122])), ('gaussian blur', tensor([-0.1792]))]
[2022-08-18 05:02:01,310] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.048366	gLtNorm 12.7935 (1.0183)	gLvNorm 1.1922 (0.3456)	mvpNorm 16.5658 (1.3670)

[2022-08-18 05:24:12,663] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 16, batch_idx: 5000, global_img_step: 80, aug_ops:[('sharpen', tensor([0.0325]))]
[2022-08-18 05:24:12,664] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.048366	gLtNorm 0.1024 (0.9882)	gLvNorm 0.0893 (0.3456)	mvpNorm 0.2110 (1.3352)

[2022-08-18 05:25:20,115] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 16, batch_idx: 0, global_img_step: 81, aug_ops:[('sharpen', tensor([-0.2360])), ('Rotate', tensor([0.0848])), ('TranslateY', tensor([-0.3341]))]
[2022-08-18 05:39:25,549] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 16, batch_idx: 1000, global_img_step: 82, aug_ops:[('idenity', [1.0])]
[2022-08-18 05:53:30,344] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 16, batch_idx: 2000, global_img_step: 83, aug_ops:[('contrast', tensor([0.2818])), ('sharpen', tensor([-0.1025])), ('elastic transform', tensor([0.2021]))]
[2022-08-18 06:01:26,515] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 16	 Inner Train loss: 0.7264, acc=0.7253, lr=0.000010	
[2022-08-18 06:02:19,354] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 16	 Test loss: 0.6737, score: 0.7472
[2022-08-18 06:02:19,355] implicit-augment.py->main line:454 [INFO]17% (17/100)
[2022-08-18 06:02:20,350] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.3086, -1.6440, -1.4136, -3.0207, -4.1021, -2.4849, -2.0984, -2.4849,
        -2.4849, -1.5831, -2.8740, -0.2855, -2.4483, -2.1279, -3.2891])
[2022-08-18 06:02:20,355] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.4913, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000,  0.0000,  0.0000,  0.0000,  0.0076,  0.0000,  0.0066,
        -0.4933, -0.0617])
[2022-08-18 06:02:20,567] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 17, batch_idx: 0, global_img_step: 84, aug_ops:[('contrast', tensor([-0.1627]))]
[2022-08-18 06:02:20,567] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.048059	gLtNorm 2.1962 (2.1962)	gLvNorm 0.1616 (0.1616)	mvpNorm 2.4365 (2.4365)

[2022-08-18 06:24:36,125] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 17, batch_idx: 2500, global_img_step: 85, aug_ops:[('Hed', tensor([0.2929, 0.2485, 0.0502])), ('sharpen', tensor([0.3239])), ('TranslateX', tensor([0.1918]))]
[2022-08-18 06:24:36,126] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.048059	gLtNorm 0.0171 (0.6709)	gLvNorm 0.0740 (0.3237)	mvpNorm 0.1509 (1.0160)

[2022-08-18 06:46:52,375] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 17, batch_idx: 5000, global_img_step: 86, aug_ops:[('TranslateY', tensor([-0.2087]))]
[2022-08-18 06:46:52,376] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.048059	gLtNorm 0.1289 (0.6216)	gLvNorm 0.1312 (0.3224)	mvpNorm 0.1664 (0.9574)

[2022-08-18 06:47:59,393] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 17, batch_idx: 0, global_img_step: 87, aug_ops:[('Hsv', tensor([ 0.3937, -1.0000, -0.4187])), ('sharpen', tensor([0.0094])), ('Equalize', tensor([-0.0039]))]
[2022-08-18 07:02:05,490] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 17, batch_idx: 1000, global_img_step: 88, aug_ops:[('idenity', [1.0])]
[2022-08-18 07:16:11,925] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 17, batch_idx: 2000, global_img_step: 89, aug_ops:[('ShearY', tensor([0.0283]))]
[2022-08-18 07:24:06,334] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 17	 Inner Train loss: 0.7289, acc=0.7241, lr=0.000010	
[2022-08-18 07:24:59,175] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 17	 Test loss: 0.6664, score: 0.7474
[2022-08-18 07:24:59,177] implicit-augment.py->main line:454 [INFO]18% (18/100)
[2022-08-18 07:25:00,147] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.8297, -1.1634, -1.8942, -3.5013, -4.5818, -2.4849, -1.6179, -2.4849,
        -2.4849, -2.0637, -2.3934,  0.1951, -2.9289, -2.6085, -2.8085])
[2022-08-18 07:25:00,153] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000,  0.0000,  0.0000,  0.0000,  0.0076,  0.0000,  0.0066,
        -0.4933, -0.0617])
[2022-08-18 07:25:00,395] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 18, batch_idx: 0, global_img_step: 90, aug_ops:[('Hed', tensor([ 0.0009, -0.1293,  0.2439])), ('ShearX', tensor([-0.8630])), ('ShearY', tensor([-0.3009]))]
[2022-08-18 07:25:00,396] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.047727	gLtNorm 0.1876 (0.1876)	gLvNorm 0.3689 (0.3689)	mvpNorm 0.4440 (0.4440)

[2022-08-18 07:47:18,803] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 18, batch_idx: 2500, global_img_step: 91, aug_ops:[('Hsv', tensor([ 1.0000, -0.9254,  0.3013])), ('Rotate', tensor([0.0644]))]
[2022-08-18 07:47:18,804] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.047727	gLtNorm 0.3725 (0.8732)	gLvNorm 0.3192 (0.3335)	mvpNorm 1.2112 (1.2105)

[2022-08-18 08:09:38,547] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 18, batch_idx: 5000, global_img_step: 92, aug_ops:[('contrast', tensor([0.7179])), ('Hed', tensor([ 0.1050,  0.1831, -0.0640])), ('gaussian noise', tensor([0.1943])), ('Rotate', tensor([-0.2762])), ('Equalize', tensor([0.7164]))]
[2022-08-18 08:09:38,548] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.047727	gLtNorm 0.0349 (0.8767)	gLvNorm 0.0445 (0.3400)	mvpNorm 0.0662 (1.2265)

[2022-08-18 08:10:45,716] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 18, batch_idx: 0, global_img_step: 93, aug_ops:[('TranslateY', tensor([0.3028]))]
[2022-08-18 08:24:49,036] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 18, batch_idx: 1000, global_img_step: 94, aug_ops:[('sharpen', tensor([-0.2519])), ('gaussian noise', tensor([0.2769]))]
[2022-08-18 08:39:01,007] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 18, batch_idx: 2000, global_img_step: 95, aug_ops:[('saturation', tensor([-1.])), ('Hsv', tensor([-0.3049, -0.1660, -1.0000])), ('TranslateY', tensor([-0.0056])), ('ShearX', tensor([-0.7982]))]
[2022-08-18 08:46:56,160] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 18	 Inner Train loss: 0.7265, acc=0.7251, lr=0.000010	
[2022-08-18 08:47:49,254] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 18	 Test loss: 0.7317, score: 0.7288
[2022-08-18 08:47:49,256] implicit-augment.py->main line:454 [INFO]19% (19/100)
[2022-08-18 08:47:50,247] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3524, -1.6406, -1.4169, -3.0240, -5.0501, -2.4849, -1.1406, -2.4849,
        -2.4849, -1.5865, -1.9161,  0.6724, -3.4062, -2.1312, -3.2858])
[2022-08-18 08:47:50,253] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.4773,  0.0000,  0.0000,  0.0076,  0.0000,  0.4839,
        -0.4933, -0.0617])
[2022-08-18 08:47:50,487] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 19, batch_idx: 0, global_img_step: 96, aug_ops:[('gaussian noise', tensor([0.3708])), ('Rotate', tensor([-0.1465])), ('TranslateX', tensor([-0.0399]))]
[2022-08-18 08:47:50,488] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.047371	gLtNorm 0.2903 (0.2903)	gLvNorm 12.8986 (12.8986)	mvpNorm 15.3369 (15.3369)

[2022-08-18 09:10:07,026] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 19, batch_idx: 2500, global_img_step: 97, aug_ops:[('Hed', tensor([-0.2008, -0.4758,  0.2121]))]
[2022-08-18 09:10:07,028] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.047371	gLtNorm 0.0333 (1.1154)	gLvNorm 0.1887 (0.4683)	mvpNorm 0.2546 (1.5879)

[2022-08-18 09:32:22,728] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 19, batch_idx: 5000, global_img_step: 98, aug_ops:[('brightness', tensor([0.0608])), ('ShearY', tensor([0.3056]))]
[2022-08-18 09:32:22,729] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.047371	gLtNorm 0.1066 (1.0023)	gLvNorm 0.1106 (0.4651)	mvpNorm 0.0113 (1.4627)

[2022-08-18 09:33:29,858] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 19, batch_idx: 0, global_img_step: 99, aug_ops:[('ShearY', tensor([-0.7010]))]
[2022-08-18 09:47:34,519] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 19, batch_idx: 1000, global_img_step: 100, aug_ops:[('sharpen', tensor([0.5844])), ('ShearX', tensor([0.2185])), ('ShearY', tensor([-0.3444]))]
[2022-08-18 10:01:41,052] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 19, batch_idx: 2000, global_img_step: 101, aug_ops:[('brightness', tensor([-0.7761])), ('saturation', tensor([0.5264])), ('ShearY', tensor([0.1752])), ('Equalize', tensor([-0.7761]))]
[2022-08-18 10:09:39,104] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 19	 Inner Train loss: 0.7166, acc=0.7299, lr=0.000010	
[2022-08-18 10:10:32,078] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 19	 Test loss: 0.6849, score: 0.7347
[2022-08-18 10:10:32,079] implicit-augment.py->main line:454 [INFO]20% (20/100)
[2022-08-18 10:10:33,083] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-1.8790, -1.1670, -1.8905, -3.4977, -4.5765, -2.4849, -0.6669, -2.9586,
        -2.4849, -2.0602, -2.3898,  1.1461, -3.8799, -1.6575, -2.8121])
[2022-08-18 10:10:33,090] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.4773, -0.4737,  0.0000, -0.4661, -0.4737,  0.4839,
        -0.4933,  0.4120])
[2022-08-18 10:10:33,251] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 20, batch_idx: 0, global_img_step: 102, aug_ops:[('contrast', tensor([-0.0896])), ('Hsv', tensor([ 0.7319,  0.3395, -0.4211]))]
[2022-08-18 10:10:33,251] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.046990	gLtNorm 0.1461 (0.1461)	gLvNorm 0.0670 (0.0670)	mvpNorm 0.2255 (0.2255)

[2022-08-18 10:32:49,746] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 20, batch_idx: 2500, global_img_step: 103, aug_ops:[('TranslateY', tensor([-0.0368])), ('ShearY', tensor([0.0808]))]
[2022-08-18 10:32:49,747] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.046990	gLtNorm 0.1291 (0.7605)	gLvNorm 0.1147 (0.3392)	mvpNorm 0.0510 (1.0938)

[2022-08-18 10:55:04,917] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 20, batch_idx: 5000, global_img_step: 104, aug_ops:[('idenity', [1.0])]
[2022-08-18 10:55:04,917] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.046990	gLtNorm 0.3826 (0.7764)	gLvNorm 0.1887 (0.3329)	mvpNorm 0.8422 (1.0933)

[2022-08-18 10:56:11,851] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 20, batch_idx: 0, global_img_step: 105, aug_ops:[('contrast', tensor([-0.4579])), ('Hed', tensor([-0.1776, -0.7724, -0.3902])), ('TranslateY', tensor([-0.4839])), ('ShearY', tensor([0.1432])), ('Equalize', tensor([0.4037]))]
[2022-08-18 11:10:20,600] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 20, batch_idx: 1000, global_img_step: 106, aug_ops:[('saturation', tensor([0.1316])), ('gaussian noise', tensor([-0.7350])), ('TranslateX', tensor([-0.5303]))]
[2022-08-18 11:24:31,905] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 20, batch_idx: 2000, global_img_step: 107, aug_ops:[('contrast', tensor([-0.3380])), ('ShearX', tensor([0.3066]))]
[2022-08-18 11:32:27,357] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 20	 Inner Train loss: 0.7217, acc=0.7271, lr=0.000010	
[2022-08-18 11:33:20,286] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 20	 Test loss: 0.6751, score: 0.7384
[2022-08-18 11:33:20,287] implicit-augment.py->main line:454 [INFO]21% (21/100)
[2022-08-18 11:33:21,311] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3489, -1.6369, -2.3604, -3.0278, -5.0463, -2.4849, -0.1970, -2.9586,
        -2.4849, -2.5300, -1.9199,  0.6762, -4.3489, -2.1274, -3.2820])
[2022-08-18 11:33:21,317] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.4773, -0.4737,  0.0000, -0.4661, -0.4737,  0.4839,
        -0.4933,  0.4120])
[2022-08-18 11:33:21,624] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 21, batch_idx: 0, global_img_step: 108, aug_ops:[('sharpen', tensor([-0.2055]))]
[2022-08-18 11:33:21,625] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.046585	gLtNorm 0.1955 (0.1955)	gLvNorm 0.5040 (0.5040)	mvpNorm 1.0452 (1.0452)

[2022-08-18 11:55:41,483] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 21, batch_idx: 2500, global_img_step: 109, aug_ops:[('idenity', [1.0])]
[2022-08-18 11:55:41,484] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.046585	gLtNorm 0.0201 (0.6200)	gLvNorm 0.1094 (0.3110)	mvpNorm 0.1177 (0.9358)

[2022-08-18 12:18:03,042] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 21, batch_idx: 5000, global_img_step: 110, aug_ops:[('elastic transform', tensor([-0.1208]))]
[2022-08-18 12:18:03,044] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.046585	gLtNorm 0.0239 (0.6032)	gLvNorm 0.0852 (0.3062)	mvpNorm 0.0982 (0.9233)

[2022-08-18 12:19:10,766] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 21, batch_idx: 0, global_img_step: 111, aug_ops:[('brightness', tensor([-0.2378])), ('contrast', tensor([0.6732])), ('saturation', tensor([-0.0763])), ('gaussian blur', tensor([-0.6311])), ('Rotate', tensor([-0.0688]))]
[2022-08-18 12:33:18,142] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 21, batch_idx: 1000, global_img_step: 112, aug_ops:[('brightness', tensor([-0.3173])), ('Hed', tensor([ 0.8506,  0.1514, -0.7535])), ('sharpen', tensor([0.1495])), ('TranslateX', tensor([-0.0646])), ('Equalize', tensor([-0.3173]))]
[2022-08-18 12:47:30,378] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 21, batch_idx: 2000, global_img_step: 113, aug_ops:[('Hed', tensor([ 0.8367, -0.1697,  0.1341])), ('Rotate', tensor([-0.1139])), ('TranslateX', tensor([-0.6621]))]
[2022-08-18 12:55:26,289] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 21	 Inner Train loss: 0.7192, acc=0.7275, lr=0.000010	
[2022-08-18 12:56:19,253] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 21	 Test loss: 0.6685, score: 0.7547
[2022-08-18 12:56:19,254] implicit-augment.py->main line:454 [INFO]22% (22/100)
[2022-08-18 12:56:20,248] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-1.8830, -2.1027, -2.8263, -3.4937, -4.5805, -2.4849, -0.6628, -2.9586,
        -2.4849, -2.0642, -2.3858,  0.2103, -3.8831, -1.6615, -2.8162])
[2022-08-18 12:56:20,254] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.0114, -0.4737,  0.0000, -0.4661, -0.4737,  0.0180,
        -0.4933,  0.4120])
[2022-08-18 12:56:20,471] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 22, batch_idx: 0, global_img_step: 114, aug_ops:[('sharpen', tensor([1.])), ('ShearX', tensor([0.0099]))]
[2022-08-18 12:56:20,471] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.046156	gLtNorm 0.1260 (0.1260)	gLvNorm 0.1165 (0.1165)	mvpNorm 0.3041 (0.3041)

[2022-08-18 13:18:36,234] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 22, batch_idx: 2500, global_img_step: 115, aug_ops:[('sharpen', tensor([0.2777])), ('ShearY', tensor([0.4476]))]
[2022-08-18 13:18:36,235] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.046156	gLtNorm 0.3589 (1.4955)	gLvNorm 0.2697 (0.4397)	mvpNorm 1.1386 (1.9463)

[2022-08-18 13:40:51,864] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 22, batch_idx: 5000, global_img_step: 116, aug_ops:[('Equalize', tensor([0.3955]))]
[2022-08-18 13:40:51,865] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.046156	gLtNorm 0.0892 (1.6066)	gLvNorm 0.0207 (0.4310)	mvpNorm 0.0902 (2.0524)

[2022-08-18 13:41:59,002] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 22, batch_idx: 0, global_img_step: 117, aug_ops:[('idenity', [1.0])]
[2022-08-18 13:56:07,825] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 22, batch_idx: 1000, global_img_step: 118, aug_ops:[('saturation', tensor([0.7628])), ('TranslateX', tensor([-1.]))]
[2022-08-18 14:10:12,466] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 22, batch_idx: 2000, global_img_step: 119, aug_ops:[('contrast', tensor([-0.0815])), ('Hed', tensor([-0.1628, -0.0102, -1.0000]))]
[2022-08-18 14:18:10,072] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 22	 Inner Train loss: 0.7138, acc=0.7297, lr=0.000010	
[2022-08-18 14:19:02,957] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 22	 Test loss: 0.6607, score: 0.7433
[2022-08-18 14:19:02,959] implicit-augment.py->main line:454 [INFO]23% (23/100)
[2022-08-18 14:19:03,937] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-1.4215, -1.6411, -3.2878, -3.9552, -5.0421, -2.4849, -0.6628, -2.9586,
        -2.4849, -2.5258, -1.9242,  0.6719, -4.3446, -2.1231, -2.3546])
[2022-08-18 14:19:03,942] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.0114, -0.4737,  0.0000, -0.4661, -0.4737,  0.4796,
        -0.4933,  0.4120])
[2022-08-18 14:19:04,221] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 23, batch_idx: 0, global_img_step: 120, aug_ops:[('saturation', tensor([0.4942])), ('Hsv', tensor([0.3125, 0.1853, 0.2952]))]
[2022-08-18 14:19:04,221] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.045705	gLtNorm 0.3552 (0.3552)	gLvNorm 0.0354 (0.0354)	mvpNorm 0.2558 (0.2558)

[2022-08-18 14:41:20,331] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 23, batch_idx: 2500, global_img_step: 121, aug_ops:[('saturation', tensor([0.1125])), ('sharpen', tensor([-0.2594]))]
[2022-08-18 14:41:20,332] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.045705	gLtNorm 0.0819 (0.8228)	gLvNorm 0.1066 (0.3496)	mvpNorm 0.2041 (1.1074)

[2022-08-18 15:03:31,262] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 23, batch_idx: 5000, global_img_step: 122, aug_ops:[('Equalize', tensor([1.]))]
[2022-08-18 15:03:31,263] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.045705	gLtNorm 0.2488 (0.8459)	gLvNorm 0.1064 (0.3522)	mvpNorm 0.1604 (1.1312)

[2022-08-18 15:04:41,433] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 23, batch_idx: 0, global_img_step: 123, aug_ops:[('elastic transform', tensor([0.7949])), ('TranslateY', tensor([0.0616])), ('ShearY', tensor([1.]))]
[2022-08-18 15:18:51,753] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 23, batch_idx: 1000, global_img_step: 124, aug_ops:[('sharpen', tensor([0.2721])), ('ShearX', tensor([-0.9185])), ('Equalize', tensor([-0.4186]))]
[2022-08-18 15:33:00,926] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 23, batch_idx: 2000, global_img_step: 125, aug_ops:[('brightness', tensor([-0.3424])), ('TranslateX', tensor([-0.2473])), ('ShearX', tensor([-0.2288]))]
[2022-08-18 15:40:56,184] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 23	 Inner Train loss: 0.7114, acc=0.7301, lr=0.000010	
[2022-08-18 15:41:49,246] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 23	 Test loss: 0.6773, score: 0.7328
[2022-08-18 15:41:49,248] implicit-augment.py->main line:454 [INFO]24% (24/100)
[2022-08-18 15:41:50,216] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-1.8785, -1.1852, -3.3902, -4.3840, -4.6325, -2.4849, -1.1199, -2.9586,
        -2.4849, -2.7016, -1.4672,  0.3862, -4.8008, -2.5765, -2.3248])
[2022-08-18 15:41:50,222] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.0000, -0.0114, -0.4737,  0.0000, -0.4661, -0.0167,  0.0660,
        -0.4933,  0.4120])
[2022-08-18 15:41:50,414] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 24, batch_idx: 0, global_img_step: 126, aug_ops:[('contrast', tensor([0.4608])), ('Equalize', tensor([-0.1789]))]
[2022-08-18 15:41:50,414] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.045230	gLtNorm 0.4583 (0.4583)	gLvNorm 1.6547 (1.6547)	mvpNorm 0.5753 (0.5753)

[2022-08-18 16:04:06,288] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 24, batch_idx: 2500, global_img_step: 127, aug_ops:[('saturation', tensor([-0.0450])), ('Hsv', tensor([ 0.1235,  1.0000, -0.2252]))]
[2022-08-18 16:04:06,289] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.045230	gLtNorm 9.2304 (0.8875)	gLvNorm 0.1961 (0.3680)	mvpNorm 11.9726 (1.2546)

[2022-08-18 16:26:23,881] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 24, batch_idx: 5000, global_img_step: 128, aug_ops:[('Hsv', tensor([-0.2364, -0.0396,  0.0008])), ('elastic transform', tensor([0.4371])), ('ShearY', tensor([0.3251]))]
[2022-08-18 16:26:23,882] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.045230	gLtNorm 3.8543 (0.9022)	gLvNorm 0.2142 (0.3688)	mvpNorm 5.5190 (1.2900)

[2022-08-18 16:27:32,431] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 24, batch_idx: 0, global_img_step: 129, aug_ops:[('gaussian blur', tensor([-0.1343])), ('Rotate', tensor([-0.4031])), ('ShearY', tensor([0.2266]))]
[2022-08-18 16:42:04,111] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 24, batch_idx: 1000, global_img_step: 130, aug_ops:[('brightness', tensor([-0.1118])), ('sharpen', tensor([0.3822])), ('TranslateY', tensor([0.2013])), ('Equalize', tensor([-0.1118]))]
[2022-08-18 16:56:41,107] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 24, batch_idx: 2000, global_img_step: 131, aug_ops:[('TranslateY', tensor([0.9803]))]
[2022-08-18 17:04:49,156] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 24	 Inner Train loss: 0.7073, acc=0.7317, lr=0.000010	
[2022-08-18 17:05:42,114] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 24	 Test loss: 0.6679, score: 0.7459
[2022-08-18 17:05:42,115] implicit-augment.py->main line:454 [INFO]25% (25/100)
[2022-08-18 17:05:43,179] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.3308, -1.6375, -2.9379, -3.9317, -4.1802, -2.4849, -0.6676, -2.9586,
        -2.4849, -2.2493, -1.0149,  0.8385, -4.3485, -2.1242, -2.7771])
[2022-08-18 17:05:43,185] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000,  0.0000,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.4521, -0.0114, -0.4737,  0.0000, -0.4661, -0.0167,  0.0660,
        -0.4933,  0.4120])
[2022-08-18 17:05:43,440] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 25, batch_idx: 0, global_img_step: 132, aug_ops:[('idenity', [1.0])]
[2022-08-18 17:05:43,440] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.044734	gLtNorm 0.0750 (0.0750)	gLvNorm 0.1011 (0.1011)	mvpNorm 0.1965 (0.1965)

[2022-08-18 17:28:21,148] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 25, batch_idx: 2500, global_img_step: 133, aug_ops:[('brightness', tensor([0.3925])), ('contrast', tensor([-0.6090])), ('Hsv', tensor([ 0.3218, -0.0994, -0.5701])), ('gaussian noise', tensor([0.3261])), ('ShearX', tensor([0.2038]))]
[2022-08-18 17:28:21,149] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.044734	gLtNorm 26.2675 (0.8602)	gLvNorm 0.1115 (0.3895)	mvpNorm 29.0960 (1.2206)

[2022-08-18 17:50:59,908] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 25, batch_idx: 5000, global_img_step: 134, aug_ops:[('brightness', tensor([-0.0325])), ('Rotate', tensor([0.4493])), ('TranslateX', tensor([0.1410])), ('ShearX', tensor([-0.5046]))]
[2022-08-18 17:50:59,910] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.044734	gLtNorm 0.0634 (1.0128)	gLvNorm 0.1085 (0.3860)	mvpNorm 0.0160 (1.3748)

[2022-08-18 17:52:07,868] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 25, batch_idx: 0, global_img_step: 135, aug_ops:[('brightness', tensor([0.4398])), ('Hsv', tensor([-0.3562,  1.0000,  0.3421])), ('Rotate', tensor([1.])), ('TranslateX', tensor([-0.8004])), ('TranslateY', tensor([0.4367]))]
[2022-08-18 18:06:42,532] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 25, batch_idx: 1000, global_img_step: 136, aug_ops:[('gaussian noise', tensor([0.4851]))]
[2022-08-18 18:21:13,221] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 25, batch_idx: 2000, global_img_step: 137, aug_ops:[('TranslateX', tensor([0.6465])), ('ShearY', tensor([0.1504])), ('Equalize', tensor([-0.4130]))]
[2022-08-18 18:29:24,363] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 25	 Inner Train loss: 0.7018, acc=0.7341, lr=0.000010	
[2022-08-18 18:30:16,956] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 25	 Test loss: 0.6595, score: 0.7425
[2022-08-18 18:30:16,958] implicit-augment.py->main line:454 [INFO]26% (26/100)
[2022-08-18 18:30:17,978] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.7782, -2.0848, -2.4905, -4.3791, -3.7329, -2.4849, -0.2202, -2.9586,
        -2.4849, -2.6966, -0.5675,  1.2858, -4.7959, -2.5716, -2.3297])
[2022-08-18 18:30:17,983] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.4521, -0.0114, -0.4737,  0.0000, -0.4661,  0.4307,  0.5133,
        -0.4933,  0.4120])
[2022-08-18 18:30:18,288] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 26, batch_idx: 0, global_img_step: 138, aug_ops:[('brightness', tensor([0.2942])), ('saturation', tensor([-0.7204])), ('ShearY', tensor([-0.1407]))]
[2022-08-18 18:30:18,289] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.044216	gLtNorm 0.1986 (0.1986)	gLvNorm 0.2206 (0.2206)	mvpNorm 0.7498 (0.7498)

[2022-08-18 18:53:41,593] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 26, batch_idx: 2500, global_img_step: 139, aug_ops:[('contrast', tensor([0.1418])), ('Hsv', tensor([ 0.2074, -0.7066,  0.4146])), ('TranslateY', tensor([-0.2328]))]
[2022-08-18 18:53:41,594] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.044216	gLtNorm 0.1000 (0.6327)	gLvNorm 0.1650 (0.4345)	mvpNorm 0.0930 (1.0300)

[2022-08-18 19:16:20,607] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 26, batch_idx: 5000, global_img_step: 140, aug_ops:[('gaussian noise', tensor([-0.2430])), ('Rotate', tensor([0.0928])), ('TranslateY', tensor([0.1103])), ('ShearX', tensor([0.2412])), ('Equalize', tensor([0.1154]))]
[2022-08-18 19:16:20,609] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.044216	gLtNorm 0.0605 (0.6403)	gLvNorm 0.1230 (0.4351)	mvpNorm 0.0723 (1.0502)

[2022-08-18 19:17:28,844] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 26, batch_idx: 0, global_img_step: 141, aug_ops:[('idenity', [1.0])]
[2022-08-18 19:32:02,682] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 26, batch_idx: 1000, global_img_step: 142, aug_ops:[('brightness', tensor([-0.1284])), ('saturation', tensor([0.0446])), ('TranslateX', tensor([0.7027])), ('TranslateY', tensor([0.0174]))]
[2022-08-18 19:46:33,444] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 26, batch_idx: 2000, global_img_step: 143, aug_ops:[('saturation', tensor([0.6389])), ('TranslateX', tensor([0.0301]))]
[2022-08-18 19:54:41,317] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 26	 Inner Train loss: 0.7043, acc=0.7326, lr=0.000010	
[2022-08-18 19:55:34,289] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 26	 Test loss: 0.6654, score: 0.7442
[2022-08-18 19:55:34,290] implicit-augment.py->main line:454 [INFO]27% (27/100)
[2022-08-18 19:55:35,284] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.2203, -1.6426, -2.0484, -3.9369, -3.2908, -2.4849, -0.6624, -2.9586,
        -2.4849, -3.1387, -0.1254,  0.8436, -4.3538, -2.1294, -2.7719])
[2022-08-18 19:55:35,290] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.8939, -0.0114, -0.4737,  0.0000, -0.4661,  0.4307,  0.0711,
        -0.4933,  0.4120])
[2022-08-18 19:55:35,542] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 27, batch_idx: 0, global_img_step: 144, aug_ops:[('Rotate', tensor([0.2252]))]
[2022-08-18 19:55:35,542] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.043677	gLtNorm 0.1116 (0.1116)	gLvNorm 0.2856 (0.2856)	mvpNorm 0.1940 (0.1940)

[2022-08-18 20:18:18,216] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 27, batch_idx: 2500, global_img_step: 145, aug_ops:[('Rotate', tensor([0.3355]))]
[2022-08-18 20:18:18,218] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.043677	gLtNorm 1.4845 (0.5134)	gLvNorm 0.0388 (0.3334)	mvpNorm 1.4048 (0.8180)

[2022-08-18 20:40:59,851] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 27, batch_idx: 5000, global_img_step: 146, aug_ops:[('contrast', tensor([0.2000])), ('ShearY', tensor([0.1790]))]
[2022-08-18 20:40:59,852] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.043677	gLtNorm 0.1293 (0.5332)	gLvNorm 0.0072 (0.3314)	mvpNorm 0.1553 (0.8483)

[2022-08-18 20:42:08,525] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 27, batch_idx: 0, global_img_step: 147, aug_ops:[('brightness', tensor([0.2077])), ('Hsv', tensor([-0.1999, -0.3207,  0.2585]))]
[2022-08-18 20:56:45,512] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 27, batch_idx: 1000, global_img_step: 148, aug_ops:[('ShearX', tensor([0.0142]))]
[2022-08-18 21:11:16,804] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 27, batch_idx: 2000, global_img_step: 149, aug_ops:[('TranslateX', tensor([-0.0678])), ('Equalize', tensor([-0.1148]))]
[2022-08-18 21:19:29,165] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 27	 Inner Train loss: 0.6993, acc=0.7352, lr=0.000010	
[2022-08-18 21:20:22,040] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 27	 Test loss: 0.6572, score: 0.7573
[2022-08-18 21:20:22,041] implicit-augment.py->main line:454 [INFO]28% (28/100)
[2022-08-18 21:20:23,064] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6570, -2.0794, -1.6116, -3.5001, -2.8542, -2.4849, -1.0990, -2.9586,
        -2.4849, -3.5754,  0.3114,  1.2804, -3.9172, -2.5661, -3.2087])
[2022-08-18 21:20:23,071] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.8939, -0.0114, -0.4737,  0.0000, -0.4661,  0.8674,  0.0711,
        -0.4933,  0.4120])
[2022-08-18 21:20:23,251] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 28, batch_idx: 0, global_img_step: 150, aug_ops:[('contrast', tensor([0.0286])), ('saturation', tensor([0.2948]))]
[2022-08-18 21:20:23,251] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.043118	gLtNorm 0.1900 (0.1900)	gLvNorm 0.0299 (0.0299)	mvpNorm 0.3154 (0.3154)

[2022-08-18 21:43:05,379] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 28, batch_idx: 2500, global_img_step: 151, aug_ops:[('sharpen', tensor([-0.3118])), ('gaussian noise', tensor([0.0587]))]
[2022-08-18 21:43:05,380] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.043118	gLtNorm 0.2431 (0.8707)	gLvNorm 0.0833 (0.3967)	mvpNorm 0.3278 (1.2830)

[2022-08-18 22:06:31,460] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 28, batch_idx: 5000, global_img_step: 152, aug_ops:[('gaussian blur', tensor([-0.3450])), ('TranslateY', tensor([-0.0839])), ('ShearY', tensor([0.0063]))]
[2022-08-18 22:06:31,461] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.043118	gLtNorm 3.9460 (0.9589)	gLvNorm 0.0420 (0.4162)	mvpNorm 4.0555 (1.3771)

[2022-08-18 22:07:41,430] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 28, batch_idx: 0, global_img_step: 153, aug_ops:[('Rotate', tensor([-0.0320])), ('TranslateY', tensor([0.4376]))]
[2022-08-18 22:22:13,794] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 28, batch_idx: 1000, global_img_step: 154, aug_ops:[('brightness', tensor([0.9365])), ('sharpen', tensor([0.2654])), ('ShearX', tensor([-0.1701]))]
[2022-08-18 22:36:51,284] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 28, batch_idx: 2000, global_img_step: 155, aug_ops:[('TranslateY', tensor([-0.1961])), ('ShearX', tensor([-0.1367]))]
[2022-08-18 22:44:59,535] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 28	 Inner Train loss: 0.6960, acc=0.7360, lr=0.000010	
[2022-08-18 22:45:52,571] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 28	 Test loss: 0.6607, score: 0.7454
[2022-08-18 22:45:52,572] implicit-augment.py->main line:454 [INFO]29% (29/100)
[2022-08-18 22:45:53,571] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0667, -2.5106, -2.0428, -3.9313, -2.4230, -2.4849, -0.6679, -2.9586,
        -2.4849, -4.0066, -0.1198,  0.8492, -3.4861, -2.9973, -2.7775])
[2022-08-18 22:45:53,577] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.8939, -0.0114, -0.4737,  0.0000, -0.4661,  0.8674, -0.3600,
        -0.4933,  0.4120])
[2022-08-18 22:45:53,818] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 29, batch_idx: 0, global_img_step: 156, aug_ops:[('Hed', tensor([ 0.2277, -0.6424,  0.0923])), ('TranslateY', tensor([0.0158])), ('Equalize', tensor([-0.1982]))]
[2022-08-18 22:45:53,818] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000010, hyper_lr=0.042538	gLtNorm 0.1453 (0.1453)	gLvNorm 0.1639 (0.1639)	mvpNorm 0.2058 (0.2058)

[2022-08-18 23:08:39,064] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 29, batch_idx: 2500, global_img_step: 157, aug_ops:[('brightness', tensor([0.1147])), ('TranslateX', tensor([0.2944])), ('TranslateY', tensor([-0.0196])), ('Equalize', tensor([0.1147]))]
[2022-08-18 23:08:39,065] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000010, hyper_lr=0.042538	gLtNorm 2.3037 (1.0492)	gLvNorm 0.1815 (0.3227)	mvpNorm 2.2347 (1.3686)

[2022-08-18 23:31:20,733] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 29, batch_idx: 5000, global_img_step: 158, aug_ops:[('brightness', tensor([0.7770])), ('saturation', tensor([0.1495])), ('Hsv', tensor([-0.2073, -0.1239,  1.0000])), ('Hed', tensor([-0.1423, -0.1320, -0.7765])), ('ShearY', tensor([0.3738]))]
[2022-08-18 23:31:20,734] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000010, hyper_lr=0.042538	gLtNorm 0.6935 (1.0792)	gLvNorm 0.0698 (0.3219)	mvpNorm 1.0442 (1.3760)

[2022-08-18 23:32:28,488] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 29, batch_idx: 0, global_img_step: 159, aug_ops:[('Hsv', tensor([ 0.0833, -0.0834, -0.7860])), ('TranslateX', tensor([-0.7585])), ('ShearX', tensor([-0.0284])), ('ShearY', tensor([0.6019])), ('Equalize', tensor([-0.3759]))]
[2022-08-18 23:47:06,305] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 29, batch_idx: 1000, global_img_step: 160, aug_ops:[('sharpen', tensor([-0.9040])), ('TranslateY', tensor([0.1278])), ('Equalize', tensor([-0.3489]))]
[2022-08-19 00:01:37,724] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 29, batch_idx: 2000, global_img_step: 161, aug_ops:[('Hsv', tensor([ 0.2603, -0.5617, -0.0535])), ('gaussian blur', tensor([-0.8913])), ('TranslateY', tensor([-0.0410]))]
[2022-08-19 00:09:51,457] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 29	 Inner Train loss: 0.6972, acc=0.7351, lr=0.000010	
[2022-08-19 00:10:44,504] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 29	 Test loss: 0.6645, score: 0.7358
[2022-08-19 00:10:44,506] implicit-augment.py->main line:454 [INFO]30% (30/100)
[2022-08-19 00:10:45,522] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6424, -2.9360, -2.4559, -3.5061, -1.9976, -2.4849, -0.2425, -2.9586,
        -2.4849, -3.5812,  0.3056,  1.2746, -3.0607, -2.5719, -3.2029])
[2022-08-19 00:10:45,525] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.4890, -0.4890,
        -0.4890,  0.8939, -0.0114, -0.4737,  0.0000, -0.0407,  1.2928,  0.0654,
        -0.4933,  0.4120])
[2022-08-19 00:10:45,821] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 30, batch_idx: 0, global_img_step: 162, aug_ops:[('Hsv', tensor([ 0.3704, -0.0754, -0.3247])), ('gaussian blur', tensor([-0.2215])), ('TranslateX', tensor([-0.1647]))]
[2022-08-19 00:10:45,822] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.041940	gLtNorm 0.1861 (0.1861)	gLvNorm 0.2680 (0.2680)	mvpNorm 0.2559 (0.2559)

[2022-08-19 00:33:23,916] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 30, batch_idx: 2500, global_img_step: 163, aug_ops:[('contrast', tensor([-0.9577]))]
[2022-08-19 00:33:23,917] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.041940	gLtNorm 0.1045 (1.4792)	gLvNorm 0.1561 (0.4476)	mvpNorm 0.0589 (1.8825)

[2022-08-19 00:56:08,498] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 30, batch_idx: 5000, global_img_step: 164, aug_ops:[('Hed', tensor([-0.5100, -0.0313, -0.6427])), ('TranslateX', tensor([-0.0346]))]
[2022-08-19 00:56:08,499] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.041940	gLtNorm 0.1234 (1.5055)	gLvNorm 0.0331 (0.4503)	mvpNorm 0.2718 (1.9259)

[2022-08-19 00:57:16,311] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 30, batch_idx: 0, global_img_step: 165, aug_ops:[('contrast', tensor([0.2132])), ('Hsv', tensor([ 0.0606, -0.0350, -0.0896])), ('Rotate', tensor([-1.]))]
[2022-08-19 01:11:50,719] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 30, batch_idx: 1000, global_img_step: 166, aug_ops:[('idenity', [1.0])]
[2022-08-19 01:26:27,122] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 30, batch_idx: 2000, global_img_step: 167, aug_ops:[('saturation', tensor([0.0011])), ('sharpen', tensor([0.0120]))]
[2022-08-19 01:34:36,615] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 30	 Inner Train loss: 0.6671, acc=0.7459, lr=0.000001	
[2022-08-19 01:35:29,585] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 30	 Test loss: 0.6415, score: 0.7646
[2022-08-19 01:35:29,587] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 30 with 0.7646 Dice score
[2022-08-19 01:35:29,993] implicit-augment.py->main line:454 [INFO]31% (31/100)
[2022-08-19 01:35:30,965] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0618, -3.3553, -2.0365, -3.9255, -2.4170, -2.4849,  0.1769, -2.9586,
        -2.4849, -3.1620, -0.1138,  0.8552, -2.6413, -2.1525, -2.7835])
[2022-08-19 01:35:30,971] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.8939,  0.4079, -0.4737,  0.0000, -0.0407,  1.2928, -0.3540,
        -0.4933,  0.4120])
[2022-08-19 01:35:31,209] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 31, batch_idx: 0, global_img_step: 168, aug_ops:[('Rotate', tensor([-1.])), ('ShearX', tensor([0.4826]))]
[2022-08-19 01:35:31,209] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.041323	gLtNorm 0.2820 (0.2820)	gLvNorm 0.3468 (0.3468)	mvpNorm 0.2369 (0.2369)

[2022-08-19 01:58:13,011] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 31, batch_idx: 2500, global_img_step: 169, aug_ops:[('TranslateY', tensor([-0.0075])), ('ShearY', tensor([0.1673]))]
[2022-08-19 01:58:13,012] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.041323	gLtNorm 0.0307 (0.6179)	gLvNorm 0.1334 (0.3120)	mvpNorm 0.0771 (0.9011)

[2022-08-19 02:20:58,231] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 31, batch_idx: 5000, global_img_step: 170, aug_ops:[('contrast', tensor([-0.4688])), ('gaussian blur', tensor([-0.2469])), ('TranslateY', tensor([0.2678])), ('ShearX', tensor([-0.0834])), ('Equalize', tensor([0.0758]))]
[2022-08-19 02:20:58,232] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.041323	gLtNorm 0.1073 (0.6717)	gLvNorm 0.3714 (0.3203)	mvpNorm 0.7711 (0.9704)

[2022-08-19 02:22:06,231] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 31, batch_idx: 0, global_img_step: 171, aug_ops:[('Hed', tensor([-0.1089,  0.1587, -0.0991]))]
[2022-08-19 02:36:39,522] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 31, batch_idx: 1000, global_img_step: 172, aug_ops:[('brightness', tensor([-0.2275])), ('Hed', tensor([-0.1027,  0.2350,  0.1192]))]
[2022-08-19 02:51:12,436] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 31, batch_idx: 2000, global_img_step: 173, aug_ops:[('Hed', tensor([ 1.0000, -0.2171, -0.2540]))]
[2022-08-19 02:59:26,258] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 31	 Inner Train loss: 0.6602, acc=0.7494, lr=0.000001	
[2022-08-19 03:00:19,201] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 31	 Test loss: 0.6411, score: 0.7619
[2022-08-19 03:00:19,202] implicit-augment.py->main line:454 [INFO]32% (32/100)
[2022-08-19 03:00:20,248] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6485, -3.7686, -1.6235, -4.3383, -2.8302, -2.4849, -0.2364, -2.9586,
        -2.4849, -3.5752, -0.5271,  0.4420, -2.2280, -2.5656, -3.1965])
[2022-08-19 03:00:20,257] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.8939,  0.4079, -0.4737,  0.0000, -0.0407,  1.2928, -0.7673,
        -0.4933,  0.4120])
[2022-08-19 03:00:20,408] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 32, batch_idx: 0, global_img_step: 174, aug_ops:[('brightness', tensor([-1.])), ('saturation', tensor([-0.2235])), ('gaussian blur', tensor([-0.1418])), ('ShearX', tensor([-1.]))]
[2022-08-19 03:00:20,409] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.040689	gLtNorm 2.8253 (2.8253)	gLvNorm 0.1160 (0.1160)	mvpNorm 3.5360 (3.5360)

[2022-08-19 03:23:00,555] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 32, batch_idx: 2500, global_img_step: 175, aug_ops:[('brightness', tensor([0.4485])), ('Hsv', tensor([ 1.0000, -0.2450, -0.5427])), ('sharpen', tensor([0.6340])), ('TranslateY', tensor([-0.4032]))]
[2022-08-19 03:23:00,557] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.040689	gLtNorm 0.0145 (0.7402)	gLvNorm 0.0071 (0.2867)	mvpNorm 0.0045 (1.0318)

[2022-08-19 03:45:43,912] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 32, batch_idx: 5000, global_img_step: 176, aug_ops:[('Hsv', tensor([0.0055, 0.0535, 0.2679])), ('Hed', tensor([0.2994, 0.3006, 0.5179])), ('TranslateY', tensor([-0.0381])), ('Equalize', tensor([0.1505]))]
[2022-08-19 03:45:43,913] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.040689	gLtNorm 0.0732 (0.6821)	gLvNorm 0.3446 (0.2833)	mvpNorm 0.5993 (0.9706)

[2022-08-19 03:46:51,583] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 32, batch_idx: 0, global_img_step: 177, aug_ops:[('Hed', tensor([-1.0000,  0.3061,  0.0451])), ('Rotate', tensor([1.])), ('Equalize', tensor([0.4496]))]
[2022-08-19 04:01:24,741] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 32, batch_idx: 1000, global_img_step: 178, aug_ops:[('saturation', tensor([-0.2164])), ('Hsv', tensor([ 0.1278, -0.0994, -0.4832])), ('TranslateX', tensor([-0.5598]))]
[2022-08-19 04:16:01,757] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 32, batch_idx: 2000, global_img_step: 179, aug_ops:[('elastic transform', tensor([0.0369])), ('TranslateY', tensor([0.1205]))]
[2022-08-19 04:24:11,233] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 32	 Inner Train loss: 0.6618, acc=0.7488, lr=0.000001	
[2022-08-19 04:25:04,129] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 32	 Test loss: 0.6402, score: 0.7617
[2022-08-19 04:25:04,130] implicit-augment.py->main line:454 [INFO]33% (33/100)
[2022-08-19 04:25:05,178] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.2417, -3.3617, -2.0304, -4.7451, -3.2371, -2.4849,  0.1705, -2.9586,
        -2.4849, -3.9821, -0.9339,  0.0351, -2.6349, -2.1587, -2.7896])
[2022-08-19 04:25:05,184] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.8939,  0.4079, -0.4737,  0.0000, -0.0407,  0.8859, -1.1742,
        -0.4933,  0.4120])
[2022-08-19 04:25:05,402] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 33, batch_idx: 0, global_img_step: 180, aug_ops:[('brightness', tensor([0.0986])), ('saturation', tensor([0.0352])), ('Hed', tensor([-0.4684, -0.0329, -0.0967])), ('sharpen', tensor([-0.6377])), ('TranslateX', tensor([-0.0590]))]
[2022-08-19 04:25:05,403] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.040037	gLtNorm 0.0973 (0.0973)	gLvNorm 0.0921 (0.0921)	mvpNorm 0.0805 (0.0805)

[2022-08-19 04:47:45,426] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 33, batch_idx: 2500, global_img_step: 181, aug_ops:[('contrast', tensor([0.9948])), ('TranslateX', tensor([-0.2210])), ('ShearX', tensor([1.])), ('Equalize', tensor([-0.1570]))]
[2022-08-19 04:47:45,428] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.040037	gLtNorm 0.0891 (0.5992)	gLvNorm 0.0629 (0.2674)	mvpNorm 0.0818 (0.8601)

[2022-08-19 05:10:28,525] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 33, batch_idx: 5000, global_img_step: 182, aug_ops:[('Hed', tensor([0.2461, 0.0537, 0.2802])), ('Rotate', tensor([0.5633])), ('TranslateX', tensor([-0.7507])), ('TranslateY', tensor([0.5272]))]
[2022-08-19 05:10:28,527] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.040037	gLtNorm 0.1385 (0.5758)	gLvNorm 0.0469 (0.2682)	mvpNorm 0.2443 (0.8514)

[2022-08-19 05:11:36,342] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 33, batch_idx: 0, global_img_step: 183, aug_ops:[('idenity', [1.0])]
[2022-08-19 05:26:09,059] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 33, batch_idx: 1000, global_img_step: 184, aug_ops:[('saturation', tensor([0.2106])), ('Hsv', tensor([ 1.0000, -0.2126,  0.5310])), ('TranslateX', tensor([0.9337]))]
[2022-08-19 05:40:42,967] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 33, batch_idx: 2000, global_img_step: 185, aug_ops:[('gaussian noise', tensor([0.3000]))]
[2022-08-19 05:48:54,756] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 33	 Inner Train loss: 0.6618, acc=0.7488, lr=0.000001	
[2022-08-19 05:49:47,705] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 33	 Test loss: 0.6374, score: 0.7675
[2022-08-19 05:49:47,707] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 33 with 0.7675 Dice score
[2022-08-19 05:49:48,119] implicit-augment.py->main line:454 [INFO]34% (34/100)
[2022-08-19 05:49:49,146] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.8413, -2.9613, -2.4308, -5.1455, -3.6375, -2.4849,  0.5709, -2.9586,
        -2.4849, -4.3824, -1.3343,  0.4355, -2.2346, -2.5591, -2.3893])
[2022-08-19 05:49:49,150] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939,  0.4079, -0.4737,  0.0000, -0.0407,  0.8859, -0.7738,
        -0.4933,  0.4120])
[2022-08-19 05:49:49,357] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 34, batch_idx: 0, global_img_step: 186, aug_ops:[('brightness', tensor([-0.2307])), ('Hsv', tensor([ 0.2376, -0.0212,  0.0296])), ('gaussian noise', tensor([0.1561])), ('TranslateX', tensor([-0.1146]))]
[2022-08-19 05:49:49,358] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.039369	gLtNorm 0.2964 (0.2964)	gLvNorm 0.0349 (0.0349)	mvpNorm 0.3571 (0.3571)

[2022-08-19 06:12:33,088] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 34, batch_idx: 2500, global_img_step: 187, aug_ops:[('ShearX', tensor([-0.7956]))]
[2022-08-19 06:12:33,090] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.039369	gLtNorm 0.2688 (0.9979)	gLvNorm 0.1149 (0.3293)	mvpNorm 0.1927 (1.3140)

[2022-08-19 06:35:14,465] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 34, batch_idx: 5000, global_img_step: 188, aug_ops:[('elastic transform', tensor([-0.3599])), ('Equalize', tensor([0.1079]))]
[2022-08-19 06:35:14,466] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.039369	gLtNorm 0.1001 (1.0358)	gLvNorm 0.0573 (0.3245)	mvpNorm 0.1046 (1.3461)

[2022-08-19 06:36:25,271] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 34, batch_idx: 0, global_img_step: 189, aug_ops:[('sharpen', tensor([0.2833])), ('Equalize', tensor([0.0615]))]
[2022-08-19 06:50:57,984] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 34, batch_idx: 1000, global_img_step: 190, aug_ops:[('contrast', tensor([0.8759])), ('Hsv', tensor([ 0.0104, -0.0144, -0.3768])), ('gaussian blur', tensor([0.1891])), ('sharpen', tensor([-0.6761]))]
[2022-08-19 07:05:31,626] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 34, batch_idx: 2000, global_img_step: 191, aug_ops:[('Hed', tensor([ 0.3764, -0.3703,  0.6941])), ('sharpen', tensor([-0.5786])), ('TranslateY', tensor([-0.3123]))]
[2022-08-19 07:13:42,976] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 34	 Inner Train loss: 0.6607, acc=0.7487, lr=0.000001	
[2022-08-19 07:14:35,989] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 34	 Test loss: 0.6401, score: 0.7671
[2022-08-19 07:14:35,990] implicit-augment.py->main line:454 [INFO]35% (35/100)
[2022-08-19 07:14:37,028] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.2349, -3.3550, -2.4308, -5.5391, -4.0311, -2.4849,  0.1773, -2.9586,
        -2.4849, -4.7750, -1.7280,  0.8291, -1.8409, -2.9526, -2.7829])
[2022-08-19 07:14:37,034] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939,  0.4079, -0.4737,  0.0000, -0.0407,  0.4922, -0.3801,
        -0.4933,  0.4120])
[2022-08-19 07:14:37,241] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 35, batch_idx: 0, global_img_step: 192, aug_ops:[('brightness', tensor([-0.3588])), ('TranslateY', tensor([0.8789]))]
[2022-08-19 07:14:37,242] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.038685	gLtNorm 0.7621 (0.7621)	gLvNorm 0.1903 (0.1903)	mvpNorm 1.5837 (1.5837)

[2022-08-19 07:37:22,184] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 35, batch_idx: 2500, global_img_step: 193, aug_ops:[('brightness', tensor([-0.2822])), ('saturation', tensor([0.0503])), ('gaussian blur', tensor([0.3564])), ('ShearX', tensor([-0.2543]))]
[2022-08-19 07:37:22,185] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.038685	gLtNorm 0.0121 (0.4681)	gLvNorm 0.0921 (0.2916)	mvpNorm 0.1082 (0.7680)

[2022-08-19 08:00:04,445] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 35, batch_idx: 5000, global_img_step: 194, aug_ops:[('idenity', [1.0])]
[2022-08-19 08:00:04,446] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.038685	gLtNorm 5.0685 (0.4379)	gLvNorm 0.0485 (0.2977)	mvpNorm 4.4367 (0.7440)

[2022-08-19 08:01:12,564] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 35, batch_idx: 0, global_img_step: 195, aug_ops:[('contrast', tensor([-0.1959])), ('saturation', tensor([0.2545])), ('Hsv', tensor([0.2228, 0.5293, 0.0171])), ('gaussian noise', tensor([0.1401])), ('Rotate', tensor([0.1650])), ('TranslateX', tensor([0.3927]))]
[2022-08-19 08:15:49,032] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 35, batch_idx: 1000, global_img_step: 196, aug_ops:[('TranslateY', tensor([-0.8942]))]
[2022-08-19 08:30:21,817] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 35, batch_idx: 2000, global_img_step: 197, aug_ops:[('Hsv', tensor([-0.3302,  0.8389, -0.0247]))]
[2022-08-19 08:38:31,642] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 35	 Inner Train loss: 0.6545, acc=0.7516, lr=0.000001	
[2022-08-19 08:39:24,778] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 35	 Test loss: 0.6454, score: 0.7673
[2022-08-19 08:39:24,780] implicit-augment.py->main line:454 [INFO]36% (36/100)
[2022-08-19 08:39:25,799] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6205, -2.9682, -2.0439, -5.9258, -3.6443, -2.4849, -0.2095, -2.9586,
        -2.4849, -5.1618, -1.3411,  0.4423, -1.4541, -3.3394, -2.3961])
[2022-08-19 08:39:25,805] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939,  0.0211, -0.4737,  0.0000, -0.0407,  0.8791, -0.7670,
        -0.4933,  0.4120])
[2022-08-19 08:39:26,027] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 36, batch_idx: 0, global_img_step: 198, aug_ops:[('TranslateX', tensor([0.2851])), ('ShearX', tensor([-0.6093])), ('Equalize', tensor([-0.0833]))]
[2022-08-19 08:39:26,028] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.037986	gLtNorm 0.0322 (0.0322)	gLvNorm 0.0422 (0.0422)	mvpNorm 0.1000 (0.1000)

[2022-08-19 09:02:12,863] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 36, batch_idx: 2500, global_img_step: 199, aug_ops:[('TranslateX', tensor([-0.3638])), ('Equalize', tensor([0.3789]))]
[2022-08-19 09:02:12,865] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.037986	gLtNorm 0.7332 (0.5337)	gLvNorm 0.0422 (0.2671)	mvpNorm 0.8817 (0.8094)

[2022-08-19 09:24:50,998] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 36, batch_idx: 5000, global_img_step: 200, aug_ops:[('saturation', tensor([0.0750]))]
[2022-08-19 09:24:50,999] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.037986	gLtNorm 0.0867 (0.5312)	gLvNorm 0.1940 (0.2675)	mvpNorm 0.4756 (0.8122)

[2022-08-19 09:26:04,791] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 36, batch_idx: 0, global_img_step: 201, aug_ops:[('saturation', tensor([-0.4531])), ('sharpen', tensor([0.0142]))]
[2022-08-19 09:40:38,969] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 36, batch_idx: 1000, global_img_step: 202, aug_ops:[('TranslateY', tensor([-0.3444]))]
[2022-08-19 09:55:14,926] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 36, batch_idx: 2000, global_img_step: 203, aug_ops:[('Rotate', tensor([0.2124])), ('ShearY', tensor([0.5756]))]
[2022-08-19 10:03:26,120] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 36	 Inner Train loss: 0.6562, acc=0.7508, lr=0.000001	
[2022-08-19 10:04:19,068] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 36	 Test loss: 0.6374, score: 0.7649
[2022-08-19 10:04:19,069] implicit-augment.py->main line:454 [INFO]37% (37/100)
[2022-08-19 10:04:20,090] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.2407, -3.3480, -1.6641, -6.3048, -3.2648, -2.4849, -0.5893, -2.5790,
        -2.4849, -4.7819, -0.9613,  0.8221, -1.0742, -2.9596, -2.0163])
[2022-08-19 10:04:20,096] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939, -0.3587, -0.0941,  0.0000, -0.0407,  0.8791, -0.7670,
        -0.4933,  0.4120])
[2022-08-19 10:04:20,301] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 37, batch_idx: 0, global_img_step: 204, aug_ops:[('saturation', tensor([-0.2225])), ('TranslateY', tensor([0.4703]))]
[2022-08-19 10:04:20,302] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.037273	gLtNorm 0.1160 (0.1160)	gLvNorm 0.0542 (0.0542)	mvpNorm 0.2101 (0.2101)

[2022-08-19 10:27:04,886] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 37, batch_idx: 2500, global_img_step: 205, aug_ops:[('Hed', tensor([ 0.5651, -0.2918,  0.1935])), ('Equalize', tensor([0.1612]))]
[2022-08-19 10:27:04,887] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.037273	gLtNorm 1.6941 (0.7162)	gLvNorm 0.2052 (0.2963)	mvpNorm 0.9703 (0.9947)

[2022-08-19 10:49:49,506] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 37, batch_idx: 5000, global_img_step: 206, aug_ops:[('Hed', tensor([ 0.4583, -0.0635, -1.0000]))]
[2022-08-19 10:49:49,507] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.037273	gLtNorm 0.5131 (0.6597)	gLvNorm 0.0644 (0.2857)	mvpNorm 0.9179 (0.9319)

[2022-08-19 10:50:57,840] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 37, batch_idx: 0, global_img_step: 207, aug_ops:[('idenity', [1.0])]
[2022-08-19 11:05:32,285] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 37, batch_idx: 1000, global_img_step: 208, aug_ops:[('brightness', tensor([-0.0739])), ('sharpen', tensor([0.3184])), ('Equalize', tensor([-0.0739]))]
[2022-08-19 11:20:07,555] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 37, batch_idx: 2000, global_img_step: 209, aug_ops:[('Hed', tensor([ 0.4180, -0.6063,  1.0000]))]
[2022-08-19 11:28:19,550] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 37	 Inner Train loss: 0.6583, acc=0.7499, lr=0.000001	
[2022-08-19 11:29:12,532] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 37	 Test loss: 0.6437, score: 0.7633
[2022-08-19 11:29:12,533] implicit-augment.py->main line:454 [INFO]38% (38/100)
[2022-08-19 11:29:13,549] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6128, -3.7208, -2.0368, -6.6769, -3.6375, -2.4849, -0.2166, -2.5790,
        -2.4849, -4.4092, -1.3340,  0.4494, -0.7015, -2.5868, -1.6435])
[2022-08-19 11:29:13,555] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939,  0.0141, -0.0941,  0.0000, -0.0407,  0.8791, -0.7670,
        -0.4933,  0.4120])
[2022-08-19 11:29:13,788] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 38, batch_idx: 0, global_img_step: 210, aug_ops:[('idenity', [1.0])]
[2022-08-19 11:29:13,788] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.036547	gLtNorm 0.0113 (0.0113)	gLvNorm 0.0554 (0.0554)	mvpNorm 0.1098 (0.1098)

[2022-08-19 11:51:56,118] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 38, batch_idx: 2500, global_img_step: 211, aug_ops:[('brightness', tensor([-0.6810])), ('contrast', tensor([-0.5522]))]
[2022-08-19 11:51:56,119] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.036547	gLtNorm 0.1592 (0.6060)	gLvNorm 0.0349 (0.2488)	mvpNorm 0.0656 (0.8627)

[2022-08-19 12:14:35,402] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 38, batch_idx: 5000, global_img_step: 212, aug_ops:[('contrast', tensor([0.4124])), ('Hsv', tensor([ 0.5215,  0.3998, -0.3876])), ('gaussian blur', tensor([-0.1413])), ('sharpen', tensor([-0.3015])), ('TranslateY', tensor([0.5374]))]
[2022-08-19 12:14:35,404] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.036547	gLtNorm 0.2517 (0.6030)	gLvNorm 0.0590 (0.2471)	mvpNorm 0.4663 (0.8611)

[2022-08-19 12:15:44,014] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 38, batch_idx: 0, global_img_step: 213, aug_ops:[('brightness', tensor([0.9556])), ('Hed', tensor([-0.0382, -0.5960,  0.2339])), ('gaussian noise', tensor([0.0849])), ('Equalize', tensor([0.9556]))]
[2022-08-19 12:30:25,236] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 38, batch_idx: 1000, global_img_step: 214, aug_ops:[('sharpen', tensor([0.3097]))]
[2022-08-19 12:44:59,894] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 38, batch_idx: 2000, global_img_step: 215, aug_ops:[('gaussian blur', tensor([-0.3503])), ('ShearX', tensor([-0.7438]))]
[2022-08-19 12:53:13,192] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 38	 Inner Train loss: 0.6539, acc=0.7516, lr=0.000001	
[2022-08-19 12:54:06,180] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 38	 Test loss: 0.6349, score: 0.7696
[2022-08-19 12:54:06,181] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 38 with 0.7696 Dice score
[2022-08-19 12:54:06,600] implicit-augment.py->main line:454 [INFO]39% (39/100)
[2022-08-19 12:54:07,583] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9781, -4.0862, -2.4023, -6.3115, -4.0030, -2.4849,  0.1489, -2.5790,
        -2.4849, -4.7743, -0.9685,  0.0839, -0.3361, -2.2214, -2.0090])
[2022-08-19 12:54:07,587] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939,  0.0141, -0.0941,  0.0000, -0.0407,  0.8791, -0.7670,
        -0.4933,  0.4120])
[2022-08-19 12:54:07,770] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 39, batch_idx: 0, global_img_step: 216, aug_ops:[('contrast', tensor([1.])), ('Hsv', tensor([-0.2782,  0.2423,  0.0011])), ('gaussian blur', tensor([0.2441])), ('ShearY', tensor([-0.9107])), ('Equalize', tensor([-0.0133]))]
[2022-08-19 12:54:07,771] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.035808	gLtNorm 0.0290 (0.0290)	gLvNorm 0.0893 (0.0893)	mvpNorm 0.1330 (0.1330)

[2022-08-19 13:16:52,719] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 39, batch_idx: 2500, global_img_step: 217, aug_ops:[('Hsv', tensor([0.0683, 0.9360, 0.1763])), ('TranslateY', tensor([-0.2828])), ('ShearX', tensor([-0.4808])), ('Equalize', tensor([-0.0100]))]
[2022-08-19 13:16:52,720] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.035808	gLtNorm 0.1215 (0.7250)	gLvNorm 1.6176 (0.2632)	mvpNorm 2.5786 (0.9801)

[2022-08-19 13:39:39,929] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 39, batch_idx: 5000, global_img_step: 218, aug_ops:[('Hsv', tensor([ 0.6741,  0.2382, -0.1051])), ('gaussian blur', tensor([-0.2163])), ('ShearX', tensor([0.9625]))]
[2022-08-19 13:39:39,930] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.035808	gLtNorm 1.6823 (0.6488)	gLvNorm 0.0227 (0.2650)	mvpNorm 1.8219 (0.9120)

[2022-08-19 13:40:47,713] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 39, batch_idx: 0, global_img_step: 219, aug_ops:[('contrast', tensor([0.0150])), ('Hsv', tensor([-0.0762,  0.0643, -0.1972])), ('sharpen', tensor([0.5186])), ('Rotate', tensor([0.5170])), ('TranslateY', tensor([-0.5444]))]
[2022-08-19 13:55:21,169] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 39, batch_idx: 1000, global_img_step: 220, aug_ops:[('Hsv', tensor([0.0635, 0.5839, 0.0612])), ('gaussian noise', tensor([-0.5211])), ('Rotate', tensor([-0.1529])), ('TranslateY', tensor([-0.0188]))]
[2022-08-19 14:09:55,242] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 39, batch_idx: 2000, global_img_step: 221, aug_ops:[('brightness', tensor([0.0198])), ('Hsv', tensor([-0.0691, -0.6784, -0.0341])), ('Rotate', tensor([-0.1637]))]
[2022-08-19 14:18:06,018] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 39	 Inner Train loss: 0.6510, acc=0.7531, lr=0.000001	
[2022-08-19 14:18:58,862] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 39	 Test loss: 0.6367, score: 0.7611
[2022-08-19 14:18:58,864] implicit-augment.py->main line:454 [INFO]40% (40/100)
[2022-08-19 14:18:59,905] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6208, -4.4443, -2.7603, -5.9649, -4.3559, -2.4849,  0.5067, -2.5790,
        -2.4849, -5.1324, -1.3266, -0.2741, -0.6941, -1.8633, -2.3669])
[2022-08-19 14:18:59,912] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939, -0.3431, -0.0941,  0.0000, -0.0407,  0.8791, -1.1250,
        -0.4933,  0.4120])
[2022-08-19 14:19:00,135] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 40, batch_idx: 0, global_img_step: 222, aug_ops:[('brightness', tensor([0.6373])), ('Hsv', tensor([0.5703, 0.0309, 0.0525])), ('Equalize', tensor([0.6373]))]
[2022-08-19 14:19:00,136] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.035057	gLtNorm 0.0056 (0.0056)	gLvNorm 0.0126 (0.0126)	mvpNorm 0.0084 (0.0084)

[2022-08-19 14:41:39,347] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 40, batch_idx: 2500, global_img_step: 223, aug_ops:[('contrast', tensor([-0.8132])), ('saturation', tensor([-0.1288])), ('Hsv', tensor([0.1958, 0.2721, 0.2907])), ('TranslateY', tensor([-0.0524]))]
[2022-08-19 14:41:39,348] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.035057	gLtNorm 66.9059 (0.7581)	gLvNorm 0.0564 (0.2511)	mvpNorm 69.4017 (1.0258)

[2022-08-19 15:04:27,922] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 40, batch_idx: 5000, global_img_step: 224, aug_ops:[('gaussian noise', tensor([-0.7678])), ('TranslateY', tensor([0.0448])), ('ShearX', tensor([-0.4947])), ('ShearY', tensor([0.2919]))]
[2022-08-19 15:04:27,923] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.035057	gLtNorm 0.0503 (0.7162)	gLvNorm 0.0526 (0.2492)	mvpNorm 0.1991 (0.9849)

[2022-08-19 15:05:36,157] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 40, batch_idx: 0, global_img_step: 225, aug_ops:[('contrast', tensor([0.0055])), ('Equalize', tensor([1.]))]
[2022-08-19 15:20:13,709] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 40, batch_idx: 1000, global_img_step: 226, aug_ops:[('saturation', tensor([0.2618])), ('Hsv', tensor([-0.0162,  0.0551, -0.1289])), ('sharpen', tensor([0.2224]))]
[2022-08-19 15:34:49,773] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 40, batch_idx: 2000, global_img_step: 227, aug_ops:[('brightness', tensor([-0.4763])), ('saturation', tensor([0.0684])), ('Hed', tensor([-1.0000,  0.6235, -0.0855]))]
[2022-08-19 15:43:01,390] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 40	 Inner Train loss: 0.6504, acc=0.7539, lr=0.000001	
[2022-08-19 15:43:54,439] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 40	 Test loss: 0.6364, score: 0.7613
[2022-08-19 15:43:54,440] implicit-augment.py->main line:454 [INFO]41% (41/100)
[2022-08-19 15:43:55,427] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9692, -4.7949, -3.1108, -6.3151, -4.7065, -2.4849,  0.1562, -2.5790,
        -2.4849, -5.4829, -0.9761, -0.6247, -0.3436, -1.5127, -2.0164])
[2022-08-19 15:43:55,433] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.9084,
        -0.9084,  0.4939, -0.3431, -0.0941,  0.0000, -0.0407,  0.8791, -1.1250,
        -0.4933,  0.4120])
[2022-08-19 15:43:55,690] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 41, batch_idx: 0, global_img_step: 228, aug_ops:[('brightness', tensor([-0.8270])), ('Rotate', tensor([-0.7460]))]
[2022-08-19 15:43:55,691] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.034296	gLtNorm 0.1898 (0.1898)	gLvNorm 0.2585 (0.2585)	mvpNorm 0.1578 (0.1578)

[2022-08-19 16:06:37,161] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 41, batch_idx: 2500, global_img_step: 229, aug_ops:[('Hsv', tensor([-0.6365,  0.2009,  0.0626])), ('TranslateX', tensor([-0.2650])), ('ShearY', tensor([-0.2991]))]
[2022-08-19 16:06:37,162] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.034296	gLtNorm 0.0697 (0.6576)	gLvNorm 0.1810 (0.2535)	mvpNorm 0.0573 (0.9125)

[2022-08-19 16:29:11,801] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 41, batch_idx: 5000, global_img_step: 230, aug_ops:[('sharpen', tensor([-0.1658])), ('gaussian noise', tensor([1.])), ('TranslateX', tensor([0.0528]))]
[2022-08-19 16:29:11,802] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.034296	gLtNorm 0.0020 (0.6601)	gLvNorm 0.2246 (0.2530)	mvpNorm 0.2289 (0.9041)

[2022-08-19 16:30:25,585] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 41, batch_idx: 0, global_img_step: 231, aug_ops:[('sharpen', tensor([0.6688])), ('ShearX', tensor([-0.0607]))]
[2022-08-19 16:44:57,607] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 41, batch_idx: 1000, global_img_step: 232, aug_ops:[('TranslateY', tensor([0.3728]))]
[2022-08-19 16:59:31,341] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 41, batch_idx: 2000, global_img_step: 233, aug_ops:[('brightness', tensor([0.0770])), ('Hed', tensor([ 0.2609, -0.6714, -0.0138])), ('elastic transform', tensor([-0.5708])), ('Rotate', tensor([-0.2599])), ('TranslateY', tensor([-0.6522]))]
[2022-08-19 17:07:39,776] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 41	 Inner Train loss: 0.6480, acc=0.7539, lr=0.000001	
[2022-08-19 17:08:32,619] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 41	 Test loss: 0.6374, score: 0.7707
[2022-08-19 17:08:32,620] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 41 with 0.7707 Dice score
[2022-08-19 17:08:33,035] implicit-augment.py->main line:454 [INFO]42% (42/100)
[2022-08-19 17:08:34,046] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.3121, -5.1378, -3.4516, -5.9729, -4.3636, -2.4849,  0.4991, -2.5790,
        -2.4849, -5.1400, -1.3190, -0.2817, -0.6865, -1.1697, -2.3592])
[2022-08-19 17:08:34,052] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000e+00, -4.4733e-01,  1.0705e-02, -4.9510e-01, -4.9509e-01,
        -4.9508e-01,  9.0842e-01, -9.0842e-01, -9.0841e-01,  4.9393e-01,
        -1.0975e-04, -9.4054e-02,  0.0000e+00, -4.0677e-02,  5.3614e-01,
        -7.8208e-01, -4.9334e-01,  7.5497e-01])
[2022-08-19 17:08:34,329] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 42, batch_idx: 0, global_img_step: 234, aug_ops:[('sharpen', tensor([0.0145]))]
[2022-08-19 17:08:34,329] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.033524	gLtNorm 0.4904 (0.4904)	gLvNorm 0.0291 (0.0291)	mvpNorm 0.6930 (0.6930)

[2022-08-19 17:31:16,255] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 42, batch_idx: 2500, global_img_step: 235, aug_ops:[('contrast', tensor([0.7800])), ('Hed', tensor([ 0.5302, -0.0254, -0.9207])), ('sharpen', tensor([1.])), ('ShearX', tensor([0.2368]))]
[2022-08-19 17:31:16,256] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.033524	gLtNorm 0.0355 (0.7465)	gLvNorm 0.1723 (0.2785)	mvpNorm 0.0846 (1.0186)

[2022-08-19 17:53:38,523] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 42, batch_idx: 5000, global_img_step: 236, aug_ops:[('contrast', tensor([-0.4402])), ('Hed', tensor([ 0.1108,  0.0837, -0.0492])), ('sharpen', tensor([-0.0833])), ('Rotate', tensor([-0.1579])), ('TranslateX', tensor([-0.9963]))]
[2022-08-19 17:53:38,525] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.033524	gLtNorm 0.0178 (0.7362)	gLvNorm 0.1323 (0.2754)	mvpNorm 0.0884 (1.0038)

[2022-08-19 17:54:45,513] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 42, batch_idx: 0, global_img_step: 237, aug_ops:[('idenity', [1.0])]
[2022-08-19 18:08:56,635] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 42, batch_idx: 1000, global_img_step: 238, aug_ops:[('Hsv', tensor([-0.2908, -0.4482,  0.3977])), ('gaussian blur', tensor([0.1291])), ('Rotate', tensor([0.0258])), ('TranslateY', tensor([0.4490]))]
[2022-08-19 18:23:22,609] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 42, batch_idx: 2000, global_img_step: 239, aug_ops:[('gaussian noise', tensor([-0.1280])), ('TranslateX', tensor([0.4433])), ('ShearX', tensor([0.7195]))]
[2022-08-19 18:31:30,181] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 42	 Inner Train loss: 0.6552, acc=0.7509, lr=0.000001	
[2022-08-19 18:32:23,161] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 42	 Test loss: 0.6373, score: 0.7690
[2022-08-19 18:32:23,162] implicit-augment.py->main line:454 [INFO]43% (43/100)
[2022-08-19 18:32:24,218] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9769, -4.8026, -3.7868, -5.6377, -4.6989, -2.4849,  0.4991, -2.5790,
        -2.4849, -4.8048, -0.9838, -0.6170, -0.3513, -1.5050, -2.6944])
[2022-08-19 18:32:24,224] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000e+00, -4.4733e-01,  1.0705e-02, -4.9510e-01, -4.9509e-01,
        -4.9508e-01,  9.0842e-01, -5.7323e-01, -1.2436e+00,  4.9393e-01,
        -1.0975e-04, -9.4054e-02,  0.0000e+00, -4.0677e-02,  8.7138e-01,
        -7.8208e-01, -4.9334e-01,  7.5497e-01])
[2022-08-19 18:32:24,493] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 43, batch_idx: 0, global_img_step: 240, aug_ops:[('sharpen', tensor([0.7751])), ('ShearX', tensor([0.3298])), ('Equalize', tensor([-0.2270]))]
[2022-08-19 18:32:24,494] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.032743	gLtNorm 0.0544 (0.0544)	gLvNorm 0.0432 (0.0432)	mvpNorm 0.1788 (0.1788)

[2022-08-19 18:55:30,761] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 43, batch_idx: 2500, global_img_step: 241, aug_ops:[('brightness', tensor([-0.5597])), ('saturation', tensor([-0.1573])), ('TranslateY', tensor([0.7499]))]
[2022-08-19 18:55:30,762] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.032743	gLtNorm 0.0140 (0.5772)	gLvNorm 0.2102 (0.2724)	mvpNorm 0.2966 (0.8435)

[2022-08-19 19:18:09,917] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 43, batch_idx: 5000, global_img_step: 242, aug_ops:[('sharpen', tensor([-1.])), ('Rotate', tensor([0.3968])), ('TranslateX', tensor([-1.])), ('TranslateY', tensor([0.5453])), ('Equalize', tensor([-0.4854]))]
[2022-08-19 19:18:09,918] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.032743	gLtNorm 0.1518 (0.5512)	gLvNorm 0.0906 (0.2710)	mvpNorm 0.4340 (0.8236)

[2022-08-19 19:19:16,598] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 43, batch_idx: 0, global_img_step: 243, aug_ops:[('brightness', tensor([0.0352])), ('gaussian blur', tensor([0.0261])), ('sharpen', tensor([-0.4773])), ('TranslateY', tensor([-0.0402])), ('Equalize', tensor([0.0352]))]
[2022-08-19 19:33:27,505] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 43, batch_idx: 1000, global_img_step: 244, aug_ops:[('Rotate', tensor([-0.3058])), ('TranslateX', tensor([-0.2252])), ('ShearY', tensor([0.2421])), ('Equalize', tensor([0.2573]))]
[2022-08-19 19:47:38,123] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 43, batch_idx: 2000, global_img_step: 245, aug_ops:[('ShearY', tensor([0.2882]))]
[2022-08-19 19:55:36,657] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 43	 Inner Train loss: 0.6505, acc=0.7527, lr=0.000001	
[2022-08-19 19:56:29,481] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 43	 Test loss: 0.6332, score: 0.7658
[2022-08-19 19:56:29,483] implicit-augment.py->main line:454 [INFO]44% (44/100)
[2022-08-19 19:56:30,497] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6495, -5.1300, -4.1143, -5.3102, -4.3715, -2.4849,  0.8266, -2.5790,
        -2.4849, -5.1322, -1.3112, -0.2896, -0.6787, -1.8324, -3.0218])
[2022-08-19 19:56:30,502] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939, -0.3275, -0.0941,  0.0000, -0.0407,  0.8714, -0.4547,
        -0.8208,  0.4275])
[2022-08-19 19:56:30,650] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 44, batch_idx: 0, global_img_step: 246, aug_ops:[('contrast', tensor([0.1821])), ('Hsv', tensor([ 0.1251, -0.1382, -1.0000])), ('TranslateY', tensor([0.0641])), ('ShearX', tensor([0.4497])), ('ShearY', tensor([-0.8054]))]
[2022-08-19 19:56:30,650] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.031953	gLtNorm 7.8015 (7.8015)	gLvNorm 0.1144 (0.1144)	mvpNorm 8.5164 (8.5164)

[2022-08-19 20:18:51,262] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 44, batch_idx: 2500, global_img_step: 247, aug_ops:[('Rotate', tensor([0.3606])), ('ShearY', tensor([0.3890]))]
[2022-08-19 20:18:51,263] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.031953	gLtNorm 0.0741 (0.4954)	gLvNorm 0.1032 (0.2172)	mvpNorm 0.1440 (0.7222)

[2022-08-19 20:41:13,285] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 44, batch_idx: 5000, global_img_step: 248, aug_ops:[('brightness', tensor([-0.0073])), ('saturation', tensor([-0.3554])), ('Hsv', tensor([ 0.1666, -0.1725,  0.0988]))]
[2022-08-19 20:41:13,286] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.031953	gLtNorm 0.0478 (0.4971)	gLvNorm 0.0649 (0.2200)	mvpNorm 0.0559 (0.7301)

[2022-08-19 20:42:20,812] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 44, batch_idx: 0, global_img_step: 249, aug_ops:[('brightness', tensor([-0.1604])), ('elastic transform', tensor([0.1947]))]
[2022-08-19 20:56:32,143] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 44, batch_idx: 1000, global_img_step: 250, aug_ops:[('gaussian blur', tensor([-0.2024])), ('TranslateX', tensor([0.3528])), ('Equalize', tensor([-0.3454]))]
[2022-08-19 21:10:45,006] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 44, batch_idx: 2000, global_img_step: 251, aug_ops:[('contrast', tensor([-0.1833])), ('gaussian noise', tensor([-0.1773])), ('ShearX', tensor([0.2338])), ('Equalize', tensor([0.0910]))]
[2022-08-19 21:18:39,697] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 44	 Inner Train loss: 0.6514, acc=0.7529, lr=0.000001	
[2022-08-19 21:19:32,428] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 44	 Test loss: 0.6351, score: 0.7692
[2022-08-19 21:19:32,429] implicit-augment.py->main line:454 [INFO]45% (45/100)
[2022-08-19 21:19:33,454] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.3326, -5.4495, -3.7947, -4.9914, -4.6910, -2.4849,  0.5071, -2.5790,
        -2.4849, -5.4516, -0.9917,  0.0300, -0.3592, -2.1519, -3.3413])
[2022-08-19 21:19:33,460] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939, -0.3275, -0.0941,  0.0000, -0.0407,  0.8714, -0.1351,
        -0.8208,  0.4275])
[2022-08-19 21:19:33,619] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 45, batch_idx: 0, global_img_step: 252, aug_ops:[('contrast', tensor([-0.0747])), ('Hed', tensor([-0.0159,  0.1373,  0.7756]))]
[2022-08-19 21:19:33,620] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.031156	gLtNorm 0.7692 (0.7692)	gLvNorm 0.0950 (0.0950)	mvpNorm 1.1905 (1.1905)

[2022-08-19 21:41:57,591] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 45, batch_idx: 2500, global_img_step: 253, aug_ops:[('contrast', tensor([-0.1412])), ('Equalize', tensor([-0.2664]))]
[2022-08-19 21:41:57,592] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.031156	gLtNorm 0.1100 (0.6574)	gLvNorm 0.2098 (0.2842)	mvpNorm 0.5875 (0.9456)

[2022-08-19 22:04:20,110] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 45, batch_idx: 5000, global_img_step: 254, aug_ops:[('Hsv', tensor([ 0.2162,  0.1191, -0.4550])), ('ShearY', tensor([-0.2410]))]
[2022-08-19 22:04:20,112] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.031156	gLtNorm 0.3484 (0.7236)	gLvNorm 0.0344 (0.2812)	mvpNorm 0.5156 (1.0112)

[2022-08-19 22:05:27,358] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 45, batch_idx: 0, global_img_step: 255, aug_ops:[('Hed', tensor([-1.0000,  0.4371,  0.3418]))]
[2022-08-19 22:19:39,963] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 45, batch_idx: 1000, global_img_step: 256, aug_ops:[('gaussian noise', tensor([0.3169])), ('Rotate', tensor([0.9727])), ('TranslateX', tensor([-0.3297]))]
[2022-08-19 22:33:49,995] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 45, batch_idx: 2000, global_img_step: 257, aug_ops:[('contrast', tensor([0.1414])), ('elastic transform', tensor([-0.6107]))]
[2022-08-19 22:41:49,826] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 45	 Inner Train loss: 0.6490, acc=0.7524, lr=0.000001	
[2022-08-19 22:42:42,641] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 45	 Test loss: 0.6361, score: 0.7712
[2022-08-19 22:42:42,642] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 45 with 0.7712 Dice score
[2022-08-19 22:42:43,045] implicit-augment.py->main line:454 [INFO]46% (46/100)
[2022-08-19 22:42:44,009] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.0211, -5.7610, -3.4832, -4.6799, -4.3795, -2.4849,  0.1955, -2.5790,
        -2.4849, -5.1403, -1.3032, -0.2816, -0.6708, -2.4635, -3.0299])
[2022-08-19 22:42:44,015] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939, -0.0160, -0.0941,  0.0000, -0.0407,  0.5598, -0.1351,
        -1.1323,  0.4275])
[2022-08-19 22:42:44,180] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 46, batch_idx: 0, global_img_step: 258, aug_ops:[('contrast', tensor([0.3036]))]
[2022-08-19 22:42:44,180] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.030352	gLtNorm 0.0114 (0.0114)	gLvNorm 0.2476 (0.2476)	mvpNorm 0.1907 (0.1907)

[2022-08-19 23:05:09,687] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 46, batch_idx: 2500, global_img_step: 259, aug_ops:[('sharpen', tensor([0.1680])), ('Equalize', tensor([-0.1580]))]
[2022-08-19 23:05:09,689] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.030352	gLtNorm 0.1557 (0.6891)	gLvNorm 0.0664 (0.3004)	mvpNorm 0.0809 (0.9768)

[2022-08-19 23:27:39,367] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 46, batch_idx: 5000, global_img_step: 260, aug_ops:[('sharpen', tensor([0.2149])), ('ShearX', tensor([0.1503]))]
[2022-08-19 23:27:39,368] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.030352	gLtNorm 0.0576 (0.7409)	gLvNorm 0.0691 (0.3105)	mvpNorm 0.0594 (1.0288)

[2022-08-19 23:28:46,882] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 46, batch_idx: 0, global_img_step: 261, aug_ops:[('TranslateX', tensor([-0.0674]))]
[2022-08-19 23:42:56,708] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 46, batch_idx: 1000, global_img_step: 262, aug_ops:[('TranslateX', tensor([-1.]))]
[2022-08-19 23:57:12,357] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 46, batch_idx: 2000, global_img_step: 263, aug_ops:[('ShearX', tensor([-0.1211]))]
[2022-08-20 00:05:10,206] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 46	 Inner Train loss: 0.6462, acc=0.7548, lr=0.000001	
[2022-08-20 00:06:02,720] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 46	 Test loss: 0.6339, score: 0.7648
[2022-08-20 00:06:02,722] implicit-augment.py->main line:454 [INFO]47% (47/100)
[2022-08-20 00:06:03,722] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-2.7176, -6.0646, -3.7867, -4.3764, -4.0760, -2.4849,  0.4990, -2.5790,
        -2.4849, -4.8368, -1.6067, -0.5851, -0.9627, -2.1600, -3.3334])
[2022-08-20 00:06:03,728] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.2875, -0.0941,  0.0000, -0.0407,  0.5598, -0.1351,
        -1.4358,  0.4275])
[2022-08-20 00:06:03,959] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 47, batch_idx: 0, global_img_step: 264, aug_ops:[('Hsv', tensor([-0.0850, -0.2011, -0.8912])), ('Equalize', tensor([1.]))]
[2022-08-20 00:06:03,960] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.029542	gLtNorm 0.0375 (0.0375)	gLvNorm 0.2784 (0.2784)	mvpNorm 0.4546 (0.4546)

[2022-08-20 00:28:18,275] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 47, batch_idx: 2500, global_img_step: 265, aug_ops:[('sharpen', tensor([-0.8408])), ('Rotate', tensor([-0.8214])), ('TranslateY', tensor([0.3221]))]
[2022-08-20 00:28:18,276] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.029542	gLtNorm 0.1204 (1.0050)	gLvNorm 0.0500 (0.2409)	mvpNorm 0.0899 (1.2566)

[2022-08-20 00:50:28,293] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 47, batch_idx: 5000, global_img_step: 266, aug_ops:[('contrast', tensor([-0.4250])), ('Hed', tensor([0.0457, 1.0000, 0.1956]))]
[2022-08-20 00:50:28,294] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.029542	gLtNorm 0.5854 (1.0377)	gLvNorm 0.5690 (0.2372)	mvpNorm 1.8981 (1.2929)

[2022-08-20 00:51:34,901] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 47, batch_idx: 0, global_img_step: 267, aug_ops:[('Equalize', tensor([-0.4405]))]
[2022-08-20 01:05:45,526] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 47, batch_idx: 1000, global_img_step: 268, aug_ops:[('Hsv', tensor([-0.2087, -0.4571, -0.2741])), ('Rotate', tensor([0.5766])), ('ShearY', tensor([0.4073]))]
[2022-08-20 01:19:55,569] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 47, batch_idx: 2000, global_img_step: 269, aug_ops:[('contrast', tensor([-0.3002])), ('saturation', tensor([-0.9440])), ('sharpen', tensor([0.0157]))]
[2022-08-20 01:27:51,372] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 47	 Inner Train loss: 0.6465, acc=0.7550, lr=0.000001	
[2022-08-20 01:28:43,731] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 47	 Test loss: 0.6351, score: 0.7620
[2022-08-20 01:28:43,732] implicit-augment.py->main line:454 [INFO]48% (48/100)
[2022-08-20 01:28:44,766] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.0129, -6.3600, -3.7867, -4.0810, -4.3711, -2.4849,  0.7945, -2.5790,
        -2.4849, -5.1321, -1.9022, -0.8805, -1.2581, -2.4554, -3.6288])
[2022-08-20 01:28:44,772] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.5829, -0.0941,  0.0000, -0.0407,  0.5598, -0.4305,
        -1.7312,  0.4275])
[2022-08-20 01:28:44,979] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 48, batch_idx: 0, global_img_step: 270, aug_ops:[('contrast', tensor([-0.3796])), ('Hed', tensor([ 0.4131, -0.0835,  0.4500])), ('ShearX', tensor([-0.7791])), ('ShearY', tensor([0.6219])), ('Equalize', tensor([0.1618]))]
[2022-08-20 01:28:44,980] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.028728	gLtNorm 0.0587 (0.0587)	gLvNorm 0.3207 (0.3207)	mvpNorm 0.6204 (0.6204)

[2022-08-20 01:51:02,251] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 48, batch_idx: 2500, global_img_step: 271, aug_ops:[('brightness', tensor([-0.1608])), ('ShearY', tensor([-0.0883])), ('Equalize', tensor([-0.1608]))]
[2022-08-20 01:51:02,252] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.028728	gLtNorm 0.0377 (1.1135)	gLvNorm 0.0445 (0.2746)	mvpNorm 0.0864 (1.3845)

[2022-08-20 02:13:21,904] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 48, batch_idx: 5000, global_img_step: 272, aug_ops:[('saturation', tensor([-0.1119])), ('sharpen', tensor([0.3401])), ('Rotate', tensor([0.4536])), ('TranslateY', tensor([0.3410])), ('ShearY', tensor([-0.2095]))]
[2022-08-20 02:13:21,906] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.028728	gLtNorm 0.2107 (1.1495)	gLvNorm 0.0776 (0.2843)	mvpNorm 0.1714 (1.4299)

[2022-08-20 02:14:28,821] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 48, batch_idx: 0, global_img_step: 273, aug_ops:[('Hsv', tensor([-5.4138e-04,  2.1523e-01,  5.9179e-01])), ('Hed', tensor([-0.3132,  1.0000,  0.0132])), ('sharpen', tensor([-0.1896]))]
[2022-08-20 02:28:39,356] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 48, batch_idx: 1000, global_img_step: 274, aug_ops:[('contrast', tensor([0.0859])), ('sharpen', tensor([-0.5182]))]
[2022-08-20 02:42:50,228] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 48, batch_idx: 2000, global_img_step: 275, aug_ops:[('saturation', tensor([0.0978])), ('Hed', tensor([-0.5165,  0.1691,  0.6291])), ('TranslateX', tensor([0.3703])), ('TranslateY', tensor([0.1082]))]
[2022-08-20 02:50:51,204] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 48	 Inner Train loss: 0.6506, acc=0.7526, lr=0.000001	
[2022-08-20 02:51:43,575] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 48	 Test loss: 0.6360, score: 0.7651
[2022-08-20 02:51:43,577] implicit-augment.py->main line:454 [INFO]49% (49/100)
[2022-08-20 02:51:44,593] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.3002, -6.6472, -4.0740, -4.3683, -4.6584, -2.4849,  0.5072, -2.5790,
        -2.4849, -4.8448, -1.6149, -0.5933, -0.9708, -2.1681, -3.3415])
[2022-08-20 02:51:44,600] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473,  0.0107, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.5829, -0.0941,  0.0000, -0.0407,  0.5598, -0.4305,
        -1.7312,  0.4275])
[2022-08-20 02:51:44,837] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 49, batch_idx: 0, global_img_step: 276, aug_ops:[('Hsv', tensor([0.0673, 0.0546, 0.2518])), ('TranslateX', tensor([-0.0443]))]
[2022-08-20 02:51:44,837] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.027909	gLtNorm 0.1389 (0.1389)	gLvNorm 0.0643 (0.0643)	mvpNorm 0.3708 (0.3708)

[2022-08-20 03:14:06,611] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 49, batch_idx: 2500, global_img_step: 277, aug_ops:[('contrast', tensor([0.1663])), ('Hsv', tensor([-0.0746,  0.0390,  0.2119])), ('Hed', tensor([-0.3078, -0.1598,  0.7580])), ('sharpen', tensor([-0.0480]))]
[2022-08-20 03:14:06,612] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.027909	gLtNorm 0.0276 (0.6791)	gLvNorm 0.2136 (0.2690)	mvpNorm 0.2070 (0.9012)

[2022-08-20 03:36:27,101] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 49, batch_idx: 5000, global_img_step: 278, aug_ops:[('gaussian blur', tensor([-0.4733])), ('elastic transform', tensor([0.4362])), ('TranslateX', tensor([-0.2667]))]
[2022-08-20 03:36:27,103] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.027909	gLtNorm 0.0655 (0.6491)	gLvNorm 0.0078 (0.2621)	mvpNorm 0.0414 (0.8823)

[2022-08-20 03:37:34,610] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 49, batch_idx: 0, global_img_step: 279, aug_ops:[('ShearX', tensor([-0.4049])), ('ShearY', tensor([-0.5715])), ('Equalize', tensor([-0.3288]))]
[2022-08-20 03:51:42,890] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 49, batch_idx: 1000, global_img_step: 280, aug_ops:[('Equalize', tensor([0.0640]))]
[2022-08-20 04:05:49,587] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 49, batch_idx: 2000, global_img_step: 281, aug_ops:[('Rotate', tensor([-0.5986])), ('ShearX', tensor([-0.1242])), ('Equalize', tensor([0.1016]))]
[2022-08-20 04:13:44,388] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 49	 Inner Train loss: 0.6492, acc=0.7530, lr=0.000001	
[2022-08-20 04:14:36,770] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 49	 Test loss: 0.6366, score: 0.7585
[2022-08-20 04:14:36,771] implicit-augment.py->main line:454 [INFO]50% (50/100)
[2022-08-20 04:14:37,764] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.4270, -6.9262, -3.7949, -4.0892, -4.9374, -2.4849,  0.7863, -2.5790,
        -2.4849, -5.1239, -1.3358, -0.3142, -1.2495, -2.4472, -3.6206])
[2022-08-20 04:14:37,770] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.8620, -0.0941,  0.0000, -0.3198,  0.5598, -0.4305,
        -1.7312,  0.4275])
[2022-08-20 04:14:37,909] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 50, batch_idx: 0, global_img_step: 282, aug_ops:[('brightness', tensor([-1.])), ('Hsv', tensor([-0.1212, -0.6485, -0.9938])), ('Equalize', tensor([-1.]))]
[2022-08-20 04:14:37,910] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.027087	gLtNorm 4.3111 (4.3111)	gLvNorm 1.9115 (1.9115)	mvpNorm 1.9420 (1.9420)

[2022-08-20 04:36:56,102] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 50, batch_idx: 2500, global_img_step: 283, aug_ops:[('contrast', tensor([0.0680])), ('saturation', tensor([0.4821])), ('Hsv', tensor([ 0.5237, -0.3763, -0.0363]))]
[2022-08-20 04:36:56,103] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.027087	gLtNorm 0.0550 (0.5950)	gLvNorm 0.0272 (0.1979)	mvpNorm 0.1132 (0.8176)

[2022-08-20 04:59:14,910] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 50, batch_idx: 5000, global_img_step: 284, aug_ops:[('saturation', tensor([0.0533])), ('Equalize', tensor([0.1371]))]
[2022-08-20 04:59:14,911] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.027087	gLtNorm 0.0407 (0.5745)	gLvNorm 0.0209 (0.2003)	mvpNorm 0.0563 (0.7929)

[2022-08-20 05:00:22,131] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 50, batch_idx: 0, global_img_step: 285, aug_ops:[('brightness', tensor([-1.])), ('saturation', tensor([-0.8986])), ('Hsv', tensor([-0.4500,  0.3493, -0.7825])), ('sharpen', tensor([0.3431])), ('ShearX', tensor([-0.3630]))]
[2022-08-20 05:14:35,605] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 50, batch_idx: 1000, global_img_step: 286, aug_ops:[('Hsv', tensor([-0.5069,  0.6801, -0.1318])), ('sharpen', tensor([0.4853])), ('Rotate', tensor([-0.7195])), ('ShearX', tensor([-0.6938]))]
[2022-08-20 05:28:42,785] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 50, batch_idx: 2000, global_img_step: 287, aug_ops:[('Hsv', tensor([-0.0235, -0.0022,  0.2725])), ('TranslateX', tensor([0.4045])), ('TranslateY', tensor([-1.])), ('Equalize', tensor([0.2299]))]
[2022-08-20 05:36:39,300] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 50	 Inner Train loss: 0.6492, acc=0.7534, lr=0.000001	
[2022-08-20 05:37:31,741] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 50	 Test loss: 0.6432, score: 0.7631
[2022-08-20 05:37:31,742] implicit-augment.py->main line:454 [INFO]51% (51/100)
[2022-08-20 05:37:32,748] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6979, -7.1970, -4.0658, -3.8184, -5.2082, -2.4849,  1.0572, -2.5790,
        -2.4849, -4.8531, -1.6067, -0.0433, -0.9786, -2.1763, -3.8915])
[2022-08-20 05:37:32,754] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.1329, -0.0941,  0.0000, -0.3198,  0.2889, -0.1597,
        -1.7312,  0.4275])
[2022-08-20 05:37:32,923] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 51, batch_idx: 0, global_img_step: 288, aug_ops:[('brightness', tensor([1.])), ('sharpen', tensor([1.])), ('TranslateX', tensor([1.])), ('TranslateY', tensor([-0.4443])), ('ShearX', tensor([1.])), ('Equalize', tensor([1.]))]
[2022-08-20 05:37:32,924] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.026263	gLtNorm 0.4478 (0.4478)	gLvNorm 0.0531 (0.0531)	mvpNorm 0.3283 (0.3283)

[2022-08-20 05:59:44,508] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 51, batch_idx: 2500, global_img_step: 289, aug_ops:[('contrast', tensor([0.0967])), ('saturation', tensor([0.4501]))]
[2022-08-20 05:59:44,509] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.026263	gLtNorm 0.0806 (0.3933)	gLvNorm 0.0084 (0.2616)	mvpNorm 0.0510 (0.6564)

[2022-08-20 06:22:03,827] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 51, batch_idx: 5000, global_img_step: 290, aug_ops:[('gaussian blur', tensor([1.])), ('Equalize', tensor([0.4450]))]
[2022-08-20 06:22:03,828] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.026263	gLtNorm 0.0277 (0.4520)	gLvNorm 0.1968 (0.2632)	mvpNorm 0.1434 (0.7210)

[2022-08-20 06:23:10,793] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 51, batch_idx: 0, global_img_step: 291, aug_ops:[('contrast', tensor([0.0167])), ('ShearX', tensor([0.6382]))]
[2022-08-20 06:37:22,122] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 51, batch_idx: 1000, global_img_step: 292, aug_ops:[('Hed', tensor([-0.2576, -0.8154,  0.5842])), ('Rotate', tensor([1.])), ('TranslateY', tensor([-1.]))]
[2022-08-20 06:51:35,140] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 51, batch_idx: 2000, global_img_step: 293, aug_ops:[('brightness', tensor([0.8550])), ('Rotate', tensor([-0.6886]))]
[2022-08-20 06:59:31,513] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 51	 Inner Train loss: 0.6448, acc=0.7543, lr=0.000001	
[2022-08-20 07:00:23,943] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 51	 Test loss: 0.6339, score: 0.7662
[2022-08-20 07:00:23,944] implicit-augment.py->main line:454 [INFO]52% (52/100)
[2022-08-20 07:00:24,986] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.4388, -7.4303, -4.3263, -3.5558, -5.4691, -2.4849,  1.3191, -2.5790,
        -2.4849, -5.1156, -1.8693, -0.3059, -0.7160, -1.9178, -3.6290])
[2022-08-20 07:00:24,991] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.3946, -0.0941,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.4686,  0.4275])
[2022-08-20 07:00:25,224] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 52, batch_idx: 0, global_img_step: 294, aug_ops:[('brightness', tensor([0.1721])), ('TranslateY', tensor([-0.5140]))]
[2022-08-20 07:00:25,225] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.025438	gLtNorm 0.0654 (0.0654)	gLvNorm 0.0596 (0.0596)	mvpNorm 0.1195 (0.1195)

[2022-08-20 07:22:45,230] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 52, batch_idx: 2500, global_img_step: 295, aug_ops:[('contrast', tensor([0.3236])), ('Hed', tensor([-0.2240,  0.1385, -1.0000])), ('TranslateY', tensor([0.7691])), ('Equalize', tensor([-0.6444]))]
[2022-08-20 07:22:45,231] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.025438	gLtNorm 0.0091 (0.7147)	gLvNorm 0.0926 (0.2439)	mvpNorm 0.0474 (0.9535)

[2022-08-20 07:45:03,156] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 52, batch_idx: 5000, global_img_step: 296, aug_ops:[('ShearY', tensor([1.])), ('Equalize', tensor([-0.7457]))]
[2022-08-20 07:45:03,157] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.025438	gLtNorm 0.0271 (0.7134)	gLvNorm 0.0506 (0.2584)	mvpNorm 0.0777 (0.9684)

[2022-08-20 07:46:10,067] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 52, batch_idx: 0, global_img_step: 297, aug_ops:[('saturation', tensor([-0.0615])), ('Hsv', tensor([-1.0000, -0.0349,  0.3116])), ('TranslateX', tensor([0.1680])), ('TranslateY', tensor([0.3916]))]
[2022-08-20 08:00:23,323] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 52, batch_idx: 1000, global_img_step: 298, aug_ops:[('idenity', [1.0])]
[2022-08-20 08:14:33,965] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 52, batch_idx: 2000, global_img_step: 299, aug_ops:[('elastic transform', tensor([0.2802])), ('TranslateY', tensor([-0.8684])), ('ShearX', tensor([0.4848])), ('Equalize', tensor([0.0892]))]
[2022-08-20 08:22:29,074] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 52	 Inner Train loss: 0.6423, acc=0.7562, lr=0.000001	
[2022-08-20 08:23:21,562] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 52	 Test loss: 0.6341, score: 0.7740
[2022-08-20 08:23:21,563] implicit-augment.py->main line:476 [INFO]SAVING trained model at epoch 52 with 0.7740 Dice score
[2022-08-20 08:23:21,966] implicit-augment.py->main line:454 [INFO]53% (53/100)
[2022-08-20 08:23:22,957] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6924, -7.6838, -4.5807, -3.8102, -5.7232, -2.4849,  1.0647, -2.5790,
        -2.4849, -5.3699, -1.6149, -0.5603, -0.9704, -1.6634, -3.3746])
[2022-08-20 08:23:22,963] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.6487, -0.0941,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.7230,  0.4275])
[2022-08-20 08:23:23,196] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 53, batch_idx: 0, global_img_step: 300, aug_ops:[('Equalize', tensor([0.1405]))]
[2022-08-20 08:23:23,197] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.024612	gLtNorm 8.6955 (8.6955)	gLvNorm 0.0173 (0.0173)	mvpNorm 9.0015 (9.0015)

[2022-08-20 08:45:35,462] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 53, batch_idx: 2500, global_img_step: 301, aug_ops:[('brightness', tensor([-1.])), ('Hed', tensor([-0.0076,  1.0000, -0.1021])), ('elastic transform', tensor([-0.2121])), ('Rotate', tensor([-0.5744]))]
[2022-08-20 08:45:35,464] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.024612	gLtNorm 2.7972 (0.7303)	gLvNorm 0.0472 (0.3140)	mvpNorm 3.0192 (1.0236)

[2022-08-20 09:07:59,737] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 53, batch_idx: 5000, global_img_step: 302, aug_ops:[('ShearX', tensor([0.3141])), ('ShearY', tensor([0.0347])), ('Equalize', tensor([-0.3083]))]
[2022-08-20 09:07:59,739] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.024612	gLtNorm 0.0735 (0.8923)	gLvNorm 0.1008 (0.3115)	mvpNorm 0.3268 (1.1798)

[2022-08-20 09:09:06,253] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 53, batch_idx: 0, global_img_step: 303, aug_ops:[('saturation', tensor([-0.0585])), ('Hed', tensor([ 0.2146,  0.2889, -0.7534])), ('ShearX', tensor([0.2707])), ('Equalize', tensor([-0.3882]))]
[2022-08-20 09:23:16,804] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 53, batch_idx: 1000, global_img_step: 304, aug_ops:[('Hed', tensor([ 0.4242, -0.0384,  0.0524])), ('sharpen', tensor([0.4244])), ('Rotate', tensor([-0.2675])), ('TranslateX', tensor([0.2349]))]
[2022-08-20 09:37:19,836] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 53, batch_idx: 2000, global_img_step: 305, aug_ops:[('contrast', tensor([-0.0610])), ('Hed', tensor([0.5804, 0.1676, 0.0205])), ('TranslateX', tensor([-0.6105])), ('TranslateY', tensor([-0.8222])), ('ShearY', tensor([-0.3640])), ('Equalize', tensor([0.2326]))]
[2022-08-20 09:45:17,517] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 53	 Inner Train loss: 0.6405, acc=0.7571, lr=0.000001	
[2022-08-20 09:46:10,101] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 53	 Test loss: 0.6347, score: 0.7671
[2022-08-20 09:46:10,103] implicit-augment.py->main line:454 [INFO]54% (54/100)
[2022-08-20 09:46:11,133] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9384, -7.9298, -4.8267, -3.5641, -5.4780, -2.4849,  1.3108, -2.5790,
        -2.4849, -5.1238, -1.8610, -0.8064, -1.2165, -1.9095, -3.6203])
[2022-08-20 09:46:11,139] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.6487, -0.0941,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.7230,  0.4275])
[2022-08-20 09:46:11,365] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 54, batch_idx: 0, global_img_step: 306, aug_ops:[('saturation', tensor([0.0204])), ('Hed', tensor([0.5701, 0.3194, 0.0470])), ('sharpen', tensor([-0.6350])), ('ShearX', tensor([-0.4203])), ('Equalize', tensor([0.4556]))]
[2022-08-20 09:46:11,365] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000001, hyper_lr=0.023787	gLtNorm 0.0139 (0.0139)	gLvNorm 0.4097 (0.4097)	mvpNorm 0.4593 (0.4593)

[2022-08-20 10:08:28,326] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 54, batch_idx: 2500, global_img_step: 307, aug_ops:[('brightness', tensor([0.0208])), ('contrast', tensor([-0.0914])), ('saturation', tensor([-0.1304])), ('gaussian noise', tensor([0.8390]))]
[2022-08-20 10:08:28,327] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000001, hyper_lr=0.023787	gLtNorm 0.0312 (0.6062)	gLvNorm 0.1993 (0.2654)	mvpNorm 0.2904 (0.8468)

[2022-08-20 10:30:43,482] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 54, batch_idx: 5000, global_img_step: 308, aug_ops:[('brightness', tensor([0.2131])), ('Hsv', tensor([ 0.2798, -0.0901, -0.3362])), ('TranslateX', tensor([1.]))]
[2022-08-20 10:30:43,483] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000001, hyper_lr=0.023787	gLtNorm 0.0131 (0.5386)	gLvNorm 0.0572 (0.2544)	mvpNorm 0.0496 (0.7743)

[2022-08-20 10:31:54,461] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 54, batch_idx: 0, global_img_step: 309, aug_ops:[('brightness', tensor([-0.1873])), ('gaussian noise', tensor([-0.1863])), ('ShearY', tensor([0.6984]))]
[2022-08-20 10:46:02,800] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 54, batch_idx: 1000, global_img_step: 310, aug_ops:[('contrast', tensor([0.6861])), ('Hed', tensor([ 0.0772, -0.1871, -0.8522])), ('TranslateY', tensor([0.2949]))]
[2022-08-20 11:00:16,653] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 54, batch_idx: 2000, global_img_step: 311, aug_ops:[('Hsv', tensor([ 0.1458, -0.0414,  0.5246])), ('TranslateX', tensor([-0.0930])), ('TranslateY', tensor([0.4236])), ('ShearY', tensor([-0.0461]))]
[2022-08-20 11:08:10,843] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 54	 Inner Train loss: 0.6443, acc=0.7547, lr=0.000001	
[2022-08-20 11:09:03,372] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 54	 Test loss: 0.6348, score: 0.7715
[2022-08-20 11:09:03,374] implicit-augment.py->main line:454 [INFO]55% (55/100)
[2022-08-20 11:09:04,365] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.1761, -7.6941, -5.0643, -3.3263, -5.2411, -2.4849,  1.5487, -2.5790,
        -2.4849, -4.8871, -2.0989, -1.0443, -0.9786, -2.1474, -3.8582])
[2022-08-20 11:09:04,368] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.4109, -0.0941,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.7230,  0.4275])
[2022-08-20 11:09:04,530] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 55, batch_idx: 0, global_img_step: 312, aug_ops:[('contrast', tensor([0.6912])), ('Hed', tensor([ 0.1257, -0.3092,  0.1710])), ('TranslateY', tensor([0.5325])), ('ShearY', tensor([-0.4188]))]
[2022-08-20 11:09:04,530] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.022963	gLtNorm 1.6704 (1.6704)	gLvNorm 0.1208 (0.1208)	mvpNorm 2.3260 (2.3260)

[2022-08-20 11:31:24,193] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 55, batch_idx: 2500, global_img_step: 313, aug_ops:[('Hsv', tensor([ 0.2339,  0.1453, -0.0255])), ('Hed', tensor([0.0844, 0.3328, 1.0000])), ('Equalize', tensor([0.1706]))]
[2022-08-20 11:31:24,195] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.022963	gLtNorm 0.3423 (0.6698)	gLvNorm 0.0092 (0.2802)	mvpNorm 0.3932 (0.9190)

[2022-08-20 11:53:44,031] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 55, batch_idx: 5000, global_img_step: 314, aug_ops:[('saturation', tensor([-0.1130])), ('elastic transform', tensor([-0.3483]))]
[2022-08-20 11:53:44,032] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.022963	gLtNorm 0.0122 (0.7026)	gLvNorm 0.0397 (0.2845)	mvpNorm 0.0323 (0.9662)

[2022-08-20 11:54:51,134] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 55, batch_idx: 0, global_img_step: 315, aug_ops:[('saturation', tensor([-0.0341])), ('gaussian blur', tensor([0.7212])), ('Rotate', tensor([0.1502]))]
[2022-08-20 12:09:01,239] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 55, batch_idx: 1000, global_img_step: 316, aug_ops:[('brightness', tensor([0.0098])), ('Hsv', tensor([-0.1438, -1.0000,  0.0167])), ('gaussian noise', tensor([0.1265])), ('TranslateY', tensor([-1.]))]
[2022-08-20 12:23:12,237] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 55, batch_idx: 2000, global_img_step: 317, aug_ops:[('saturation', tensor([0.1162])), ('TranslateX', tensor([0.2983])), ('Equalize', tensor([1.]))]
[2022-08-20 12:31:06,604] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 55	 Inner Train loss: 0.6405, acc=0.7570, lr=0.000000	
[2022-08-20 12:31:59,046] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 55	 Test loss: 0.6373, score: 0.7700
[2022-08-20 12:31:59,047] implicit-augment.py->main line:454 [INFO]56% (56/100)
[2022-08-20 12:32:00,037] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.4057, -7.9237, -4.8347, -3.0967, -5.4706, -2.4849,  1.7783, -2.5790,
        -2.4849, -4.6574, -2.3285, -0.8147, -0.7490, -2.3770, -4.0878])
[2022-08-20 12:32:00,042] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.4951, -0.4951, -0.4951,  0.9084, -0.5732,
        -1.2436,  0.4939,  1.1813, -0.0941,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.7230,  0.4275])
[2022-08-20 12:32:00,276] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 56, batch_idx: 0, global_img_step: 318, aug_ops:[('saturation', tensor([-0.1173])), ('elastic transform', tensor([0.0085])), ('Rotate', tensor([-0.4929])), ('TranslateY', tensor([-0.0148])), ('ShearX', tensor([0.0720]))]
[2022-08-20 12:32:00,276] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.022141	gLtNorm 0.0422 (0.0422)	gLvNorm 0.0403 (0.0403)	mvpNorm 0.0351 (0.0351)

[2022-08-20 12:54:19,887] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 56, batch_idx: 2500, global_img_step: 319, aug_ops:[('brightness', tensor([0.0334])), ('saturation', tensor([0.6049])), ('ShearY', tensor([-1.]))]
[2022-08-20 12:54:19,888] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.022141	gLtNorm 0.1719 (1.0047)	gLvNorm 0.0590 (0.2828)	mvpNorm 0.1057 (1.2819)

[2022-08-20 13:16:37,102] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 56, batch_idx: 5000, global_img_step: 320, aug_ops:[('ShearX', tensor([0.9255]))]
[2022-08-20 13:16:37,103] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.022141	gLtNorm 0.0122 (0.8938)	gLvNorm 0.0150 (0.2820)	mvpNorm 0.0029 (1.1701)

[2022-08-20 13:17:44,247] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 56, batch_idx: 0, global_img_step: 321, aug_ops:[('Hed', tensor([ 0.2431,  0.4813, -0.4376]))]
[2022-08-20 13:31:52,384] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 56, batch_idx: 1000, global_img_step: 322, aug_ops:[('Hed', tensor([0.0243, 0.2496, 0.4047])), ('Rotate', tensor([0.1402])), ('Equalize', tensor([-0.2508]))]
[2022-08-20 13:45:58,205] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 56, batch_idx: 2000, global_img_step: 323, aug_ops:[('Hsv', tensor([-0.2356,  0.0085, -0.0910])), ('sharpen', tensor([-0.2144])), ('elastic transform', tensor([0.5443]))]
[2022-08-20 13:53:56,498] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 56	 Inner Train loss: 0.6376, acc=0.7573, lr=0.000000	
[2022-08-20 13:54:48,901] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 56	 Test loss: 0.6344, score: 0.7644
[2022-08-20 13:54:48,902] implicit-augment.py->main line:454 [INFO]57% (57/100)
[2022-08-20 13:54:49,926] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.6270, -8.1451, -4.6133, -2.8753, -5.6920, -2.4849,  1.9997, -2.3576,
        -2.4849, -4.8789, -2.5499, -1.0361, -0.5276, -2.1556, -4.3092])
[2022-08-20 13:54:49,931] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.9599, -0.3155,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.5016,  0.4275])
[2022-08-20 13:54:50,190] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 57, batch_idx: 0, global_img_step: 324, aug_ops:[('idenity', [1.0])]
[2022-08-20 13:54:50,190] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.021322	gLtNorm 0.1956 (0.1956)	gLvNorm 0.5559 (0.5559)	mvpNorm 0.7882 (0.7882)

[2022-08-20 14:17:12,278] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 57, batch_idx: 2500, global_img_step: 325, aug_ops:[('TranslateY', tensor([0.0411])), ('ShearX', tensor([-0.0107]))]
[2022-08-20 14:17:12,280] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.021322	gLtNorm 0.0279 (0.5463)	gLvNorm 0.1188 (0.2313)	mvpNorm 0.0810 (0.7565)

[2022-08-20 14:39:28,981] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 57, batch_idx: 5000, global_img_step: 326, aug_ops:[('Hed', tensor([-0.3190, -0.3722, -0.0037])), ('sharpen', tensor([-1.])), ('elastic transform', tensor([0.0817])), ('Rotate', tensor([0.5413])), ('Equalize', tensor([0.4295]))]
[2022-08-20 14:39:28,982] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.021322	gLtNorm 0.0571 (0.5442)	gLvNorm 0.1613 (0.2281)	mvpNorm 0.2352 (0.7602)

[2022-08-20 14:40:36,367] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 57, batch_idx: 0, global_img_step: 327, aug_ops:[('saturation', tensor([0.3459])), ('sharpen', tensor([0.2854]))]
[2022-08-20 14:54:49,648] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 57, batch_idx: 1000, global_img_step: 328, aug_ops:[('idenity', [1.0])]
[2022-08-20 15:09:03,961] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 57, batch_idx: 2000, global_img_step: 329, aug_ops:[('saturation', tensor([0.8577]))]
[2022-08-20 15:17:01,228] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 57	 Inner Train loss: 0.6360, acc=0.7588, lr=0.000000	
[2022-08-20 15:17:53,655] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 57	 Test loss: 0.6339, score: 0.7695
[2022-08-20 15:17:53,656] implicit-augment.py->main line:454 [INFO]58% (58/100)
[2022-08-20 15:17:54,659] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.4138, -7.9321, -4.8246, -3.0883, -5.9052, -2.4849,  1.7865, -2.3576,
        -2.4849, -5.0921, -2.7631, -1.2493, -0.3144, -2.3688, -4.0983])
[2022-08-20 15:17:54,665] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.5732,
        -1.2436,  0.4939,  0.7467, -0.3155,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.2884,  0.4275])
[2022-08-20 15:17:54,925] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 58, batch_idx: 0, global_img_step: 330, aug_ops:[('Hsv', tensor([-0.1835,  0.4370,  0.1373])), ('ShearY', tensor([-0.2970]))]
[2022-08-20 15:17:54,926] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.020508	gLtNorm 0.0585 (0.0585)	gLvNorm 0.1158 (0.1158)	mvpNorm 0.2929 (0.2929)

[2022-08-20 15:40:15,167] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 58, batch_idx: 2500, global_img_step: 331, aug_ops:[('gaussian noise', tensor([-0.6476])), ('ShearX', tensor([-0.1252])), ('Equalize', tensor([-0.2079]))]
[2022-08-20 15:40:15,168] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.020508	gLtNorm 0.0384 (0.7595)	gLvNorm 0.0666 (0.2724)	mvpNorm 0.0995 (1.0196)

[2022-08-20 16:02:32,819] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 58, batch_idx: 5000, global_img_step: 332, aug_ops:[('contrast', tensor([0.1147])), ('Hsv', tensor([-0.3149, -0.0551,  0.2797]))]
[2022-08-20 16:02:32,821] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.020508	gLtNorm 0.1049 (0.7706)	gLvNorm 0.0605 (0.2750)	mvpNorm 0.0998 (1.0310)

[2022-08-20 16:03:39,713] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 58, batch_idx: 0, global_img_step: 333, aug_ops:[('Hed', tensor([ 0.4653,  0.3863, -0.4000]))]
[2022-08-20 16:17:50,827] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 58, batch_idx: 1000, global_img_step: 334, aug_ops:[('brightness', tensor([0.5590])), ('ShearX', tensor([-0.4111])), ('Equalize', tensor([0.5590]))]
[2022-08-20 16:32:00,458] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 58, batch_idx: 2000, global_img_step: 335, aug_ops:[('saturation', tensor([0.0256])), ('sharpen', tensor([-0.3845])), ('elastic transform', tensor([0.5142])), ('ShearX', tensor([-0.0221])), ('ShearY', tensor([0.2693]))]
[2022-08-20 16:39:59,237] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 58	 Inner Train loss: 0.6380, acc=0.7577, lr=0.000000	
[2022-08-20 16:40:51,719] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 58	 Test loss: 0.6332, score: 0.7701
[2022-08-20 16:40:51,720] implicit-augment.py->main line:454 [INFO]59% (59/100)
[2022-08-20 16:40:52,698] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.2118, -7.7284, -4.6196, -3.2933, -6.1102, -2.4849,  1.5814, -2.3576,
        -2.4849, -4.8870, -2.9682, -1.0442, -0.5195, -2.5739, -4.3034])
[2022-08-20 16:40:52,703] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.4939,  0.5416, -0.3155,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.2884,  0.4275])
[2022-08-20 16:40:52,865] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 59, batch_idx: 0, global_img_step: 336, aug_ops:[('brightness', tensor([1.])), ('ShearY', tensor([-0.6065])), ('Equalize', tensor([1.]))]
[2022-08-20 16:40:52,866] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.019698	gLtNorm 4.9124 (4.9124)	gLvNorm 0.0532 (0.0532)	mvpNorm 5.5219 (5.5219)

[2022-08-20 17:03:19,398] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 59, batch_idx: 2500, global_img_step: 337, aug_ops:[('gaussian blur', tensor([0.2170]))]
[2022-08-20 17:03:19,399] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.019698	gLtNorm 8.4837 (0.8505)	gLvNorm 0.0050 (0.2800)	mvpNorm 8.5749 (1.1266)

[2022-08-20 17:25:53,706] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 59, batch_idx: 5000, global_img_step: 338, aug_ops:[('gaussian blur', tensor([-0.6620])), ('sharpen', tensor([-0.1308])), ('Rotate', tensor([0.5718])), ('TranslateX', tensor([0.1170])), ('ShearX', tensor([0.4979])), ('Equalize', tensor([-0.1021]))]
[2022-08-20 17:25:53,708] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.019698	gLtNorm 0.0387 (0.8120)	gLvNorm 0.1400 (0.2832)	mvpNorm 0.1828 (1.0896)

[2022-08-20 17:27:00,912] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 59, batch_idx: 0, global_img_step: 339, aug_ops:[('Hsv', tensor([-0.3056,  0.2004, -0.2779])), ('ShearX', tensor([-0.0459])), ('ShearY', tensor([-0.1626])), ('Equalize', tensor([-0.1610]))]
[2022-08-20 17:41:16,434] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 59, batch_idx: 1000, global_img_step: 340, aug_ops:[('saturation', tensor([-0.2190]))]
[2022-08-20 17:56:52,195] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 59, batch_idx: 2000, global_img_step: 341, aug_ops:[('Equalize', tensor([-0.0691]))]
[2022-08-20 18:05:25,391] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 59	 Inner Train loss: 0.6397, acc=0.7571, lr=0.000000	
[2022-08-20 18:06:18,079] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 59	 Test loss: 0.6364, score: 0.7692
[2022-08-20 18:06:18,080] implicit-augment.py->main line:454 [INFO]60% (60/100)
[2022-08-20 18:06:19,148] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0148, -7.9254, -4.8162, -3.4903, -5.9133, -2.4849,  1.3845, -2.3576,
        -2.4849, -5.0840, -3.1652, -1.2412, -0.7164, -2.7709, -4.1064])
[2022-08-20 18:06:19,154] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7386, -0.3155,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.2884,  0.4275])
[2022-08-20 18:06:19,495] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 60, batch_idx: 0, global_img_step: 342, aug_ops:[('TranslateY', tensor([-0.0435]))]
[2022-08-20 18:06:19,496] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.018894	gLtNorm 0.0372 (0.0372)	gLvNorm 0.0171 (0.0171)	mvpNorm 0.0388 (0.0388)

[2022-08-20 18:28:34,714] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 60, batch_idx: 2500, global_img_step: 343, aug_ops:[('gaussian noise', tensor([-0.0467])), ('Rotate', tensor([-0.1499]))]
[2022-08-20 18:28:34,716] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.018894	gLtNorm 0.5221 (0.8361)	gLvNorm 0.8361 (0.2939)	mvpNorm 0.0459 (1.1349)

[2022-08-20 18:50:52,226] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 60, batch_idx: 5000, global_img_step: 344, aug_ops:[('TranslateX', tensor([0.0224])), ('ShearX', tensor([-0.0636]))]
[2022-08-20 18:50:52,227] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.018894	gLtNorm 0.0512 (0.7832)	gLvNorm 0.1324 (0.2902)	mvpNorm 0.1296 (1.0732)

[2022-08-20 18:51:59,159] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 60, batch_idx: 0, global_img_step: 345, aug_ops:[('sharpen', tensor([0.7037])), ('Rotate', tensor([0.5948])), ('TranslateX', tensor([0.5610])), ('ShearX', tensor([-0.4883])), ('ShearY', tensor([-0.1363]))]
[2022-08-20 19:06:05,985] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 60, batch_idx: 1000, global_img_step: 346, aug_ops:[('TranslateX', tensor([-0.2437])), ('ShearY', tensor([0.5019])), ('Equalize', tensor([-0.0983]))]
[2022-08-20 19:20:15,708] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 60, batch_idx: 2000, global_img_step: 347, aug_ops:[('brightness', tensor([-0.1711])), ('contrast', tensor([0.1088]))]
[2022-08-20 19:28:13,330] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 60	 Inner Train loss: 0.6437, acc=0.7555, lr=0.000000	
[2022-08-20 19:29:05,848] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 60	 Test loss: 0.6345, score: 0.7684
[2022-08-20 19:29:05,849] implicit-augment.py->main line:454 [INFO]61% (61/100)
[2022-08-20 19:29:06,886] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.2038, -7.7366, -4.6275, -3.3014, -6.1022, -2.4849,  1.5734, -2.3576,
        -2.4849, -5.2729, -3.3541, -1.4301, -0.9054, -2.9598, -4.2952])
[2022-08-20 19:29:06,892] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5496, -0.3155,  0.0000, -0.3198,  0.2889, -0.4223,
        -1.2884,  0.4275])
[2022-08-20 19:29:07,241] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 61, batch_idx: 0, global_img_step: 348, aug_ops:[('sharpen', tensor([-0.4308]))]
[2022-08-20 19:29:07,242] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.018097	gLtNorm 0.1772 (0.1772)	gLvNorm 0.0451 (0.0451)	mvpNorm 0.1371 (0.1371)

[2022-08-20 19:51:26,432] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 61, batch_idx: 2500, global_img_step: 349, aug_ops:[('Hsv', tensor([-1.0000, -0.4815, -0.2733])), ('TranslateX', tensor([0.0539])), ('ShearY', tensor([-0.3324]))]
[2022-08-20 19:51:26,433] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.018097	gLtNorm 0.1187 (0.5705)	gLvNorm 0.0472 (0.2506)	mvpNorm 0.3085 (0.8264)

[2022-08-20 20:13:46,946] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 61, batch_idx: 5000, global_img_step: 350, aug_ops:[('elastic transform', tensor([-0.9867])), ('Rotate', tensor([0.9434])), ('TranslateX', tensor([-0.0163]))]
[2022-08-20 20:13:46,947] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.018097	gLtNorm 0.0914 (0.5830)	gLvNorm 0.1098 (0.2458)	mvpNorm 0.1384 (0.8283)

[2022-08-20 20:14:53,967] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 61, batch_idx: 0, global_img_step: 351, aug_ops:[('brightness', tensor([0.0316])), ('contrast', tensor([-0.3169])), ('Rotate', tensor([0.2080])), ('ShearX', tensor([-0.0376]))]
[2022-08-20 20:29:05,729] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 61, batch_idx: 1000, global_img_step: 352, aug_ops:[('Rotate', tensor([-0.5803])), ('Equalize', tensor([1.]))]
[2022-08-20 20:43:14,532] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 61, batch_idx: 2000, global_img_step: 353, aug_ops:[('idenity', [1.0])]
[2022-08-20 20:51:18,160] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 61	 Inner Train loss: 0.6399, acc=0.7576, lr=0.000000	
[2022-08-20 20:52:10,635] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 61	 Test loss: 0.6343, score: 0.7659
[2022-08-20 20:52:10,636] implicit-augment.py->main line:454 [INFO]62% (62/100)
[2022-08-20 20:52:11,722] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0228, -7.5560, -4.8075, -3.1204, -5.9213, -2.4849,  1.3924, -2.3576,
        -2.4849, -5.4538, -3.5351, -1.2492, -0.7244, -3.1408, -4.1142])
[2022-08-20 20:52:11,728] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7306, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-20 20:52:12,046] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 62, batch_idx: 0, global_img_step: 354, aug_ops:[('saturation', tensor([0.0910])), ('Hed', tensor([1.0000, 0.1530, 0.2146])), ('ShearY', tensor([-0.0576])), ('Equalize', tensor([-0.1869]))]
[2022-08-20 20:52:12,047] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.017307	gLtNorm 0.0338 (0.0338)	gLvNorm 0.1139 (0.1139)	mvpNorm 0.2556 (0.2556)

[2022-08-20 21:15:26,747] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 62, batch_idx: 2500, global_img_step: 355, aug_ops:[('contrast', tensor([0.0298])), ('gaussian blur', tensor([0.0430]))]
[2022-08-20 21:15:26,748] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.017307	gLtNorm 0.4117 (0.4434)	gLvNorm 0.5866 (0.2241)	mvpNorm 1.0850 (0.6717)

[2022-08-20 21:38:27,806] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 62, batch_idx: 5000, global_img_step: 356, aug_ops:[('contrast', tensor([1.])), ('ShearX', tensor([0.1878])), ('Equalize', tensor([-0.0013]))]
[2022-08-20 21:38:27,807] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.017307	gLtNorm 0.1212 (0.4517)	gLvNorm 0.0645 (0.2253)	mvpNorm 0.2995 (0.6828)

[2022-08-20 21:39:39,243] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 62, batch_idx: 0, global_img_step: 357, aug_ops:[('gaussian noise', tensor([0.1330])), ('TranslateY', tensor([0.1442])), ('Equalize', tensor([-0.1615]))]
[2022-08-20 21:54:23,661] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 62, batch_idx: 1000, global_img_step: 358, aug_ops:[('saturation', tensor([0.3490])), ('Hed', tensor([-0.2902, -0.3709,  0.4375])), ('TranslateX', tensor([-1.])), ('ShearY', tensor([-0.1561]))]
[2022-08-20 22:11:00,154] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 62, batch_idx: 2000, global_img_step: 359, aug_ops:[('Hsv', tensor([-0.0070,  0.1687, -0.2443])), ('Equalize', tensor([-0.4207]))]
[2022-08-20 22:20:47,350] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 62	 Inner Train loss: 0.6347, acc=0.7593, lr=0.000000	
[2022-08-20 22:21:41,069] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 62	 Test loss: 0.6376, score: 0.7709
[2022-08-20 22:21:41,070] implicit-augment.py->main line:454 [INFO]63% (63/100)
[2022-08-20 22:21:43,070] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8498, -7.3830, -4.6344, -2.9474, -5.7482, -2.4849,  1.5655, -2.3576,
        -2.4849, -5.6265, -3.3620, -1.0761, -0.8975, -2.9677, -4.2873])
[2022-08-20 22:21:43,130] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([ 0.0000, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5575, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-20 22:21:44,176] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 63, batch_idx: 0, global_img_step: 360, aug_ops:[('idenity', [1.0])]
[2022-08-20 22:21:44,177] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.016526	gLtNorm 0.0380 (0.0380)	gLvNorm 0.0024 (0.0024)	mvpNorm 0.0477 (0.0477)

[2022-08-20 22:51:00,555] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 63, batch_idx: 2500, global_img_step: 361, aug_ops:[('saturation', tensor([0.7214])), ('Hed', tensor([ 0.0502, -0.5615,  0.6987])), ('TranslateX', tensor([-0.0192])), ('ShearY', tensor([-0.0644]))]
[2022-08-20 22:51:00,556] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.016526	gLtNorm 0.0537 (0.5250)	gLvNorm 0.0757 (0.2841)	mvpNorm 0.1013 (0.8162)

[2022-08-20 23:20:43,934] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 63, batch_idx: 5000, global_img_step: 362, aug_ops:[('ShearY', tensor([-1.]))]
[2022-08-20 23:20:43,936] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.016526	gLtNorm 0.0844 (0.5806)	gLvNorm 0.1241 (0.2850)	mvpNorm 0.3619 (0.8735)

[2022-08-20 23:22:03,972] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 63, batch_idx: 0, global_img_step: 363, aug_ops:[('brightness', tensor([0.2241])), ('contrast', tensor([0.1321])), ('ShearX', tensor([-0.0913]))]
[2022-08-20 23:38:07,087] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 63, batch_idx: 1000, global_img_step: 364, aug_ops:[('Hed', tensor([-0.8400, -0.2850,  0.1828])), ('gaussian noise', tensor([0.0955])), ('ShearY', tensor([-0.3261]))]
[2022-08-20 23:53:09,659] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 63, batch_idx: 2000, global_img_step: 365, aug_ops:[('brightness', tensor([-0.2603])), ('contrast', tensor([1.])), ('Hsv', tensor([-0.1287,  0.1804,  1.0000])), ('sharpen', tensor([0.0323])), ('Rotate', tensor([0.9587])), ('TranslateY', tensor([0.1599]))]
[2022-08-21 00:01:05,836] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 63	 Inner Train loss: 0.6343, acc=0.7594, lr=0.000000	
[2022-08-21 00:01:58,324] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 63	 Test loss: 0.6335, score: 0.7723
[2022-08-21 00:01:58,326] implicit-augment.py->main line:454 [INFO]64% (64/100)
[2022-08-21 00:01:59,380] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0150, -7.2178, -4.4692, -3.1126, -5.5830, -2.4849,  1.4002, -2.3576,
        -2.4849, -5.4612, -3.1968, -1.2414, -0.7322, -3.1330, -4.1220])
[2022-08-21 00:01:59,384] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5575, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-21 00:01:59,573] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 64, batch_idx: 0, global_img_step: 366, aug_ops:[('ShearY', tensor([1.]))]
[2022-08-21 00:01:59,573] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.015754	gLtNorm 0.0552 (0.0552)	gLvNorm 0.2315 (0.2315)	mvpNorm 0.4755 (0.4755)

[2022-08-21 00:24:17,302] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 64, batch_idx: 2500, global_img_step: 367, aug_ops:[('saturation', tensor([-0.2018])), ('Hed', tensor([ 0.5336, -0.0980,  0.6715])), ('sharpen', tensor([0.3410])), ('Equalize', tensor([-0.1746]))]
[2022-08-21 00:24:17,303] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.015754	gLtNorm 0.0208 (0.5413)	gLvNorm 0.0181 (0.2725)	mvpNorm 0.0418 (0.8033)

[2022-08-21 00:46:39,006] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 64, batch_idx: 5000, global_img_step: 368, aug_ops:[('sharpen', tensor([0.3882]))]
[2022-08-21 00:46:39,007] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.015754	gLtNorm 0.0318 (0.5364)	gLvNorm 0.0367 (0.2737)	mvpNorm 0.1141 (0.8027)

[2022-08-21 00:47:46,412] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 64, batch_idx: 0, global_img_step: 369, aug_ops:[('Hed', tensor([ 1.0000, -0.9596,  0.1093])), ('TranslateX', tensor([0.2911])), ('ShearX', tensor([0.3460]))]
[2022-08-21 01:01:53,659] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 64, batch_idx: 1000, global_img_step: 370, aug_ops:[('Hsv', tensor([-1.0000, -0.0112,  0.0313])), ('Rotate', tensor([0.0740])), ('TranslateX', tensor([0.0923])), ('TranslateY', tensor([-0.0969])), ('ShearX', tensor([0.3973])), ('ShearY', tensor([-0.0112])), ('Equalize', tensor([0.1360]))]
[2022-08-21 01:16:04,457] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 64, batch_idx: 2000, global_img_step: 371, aug_ops:[('Hed', tensor([-0.0018, -0.3157, -0.0989]))]
[2022-08-21 01:24:00,345] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 64	 Inner Train loss: 0.6404, acc=0.7565, lr=0.000000	
[2022-08-21 01:24:53,226] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 64	 Test loss: 0.6325, score: 0.7694
[2022-08-21 01:24:53,227] implicit-augment.py->main line:454 [INFO]65% (65/100)
[2022-08-21 01:24:54,282] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8575, -7.0603, -4.3116, -3.2702, -5.7405, -2.4849,  1.5577, -2.3576,
        -2.4849, -5.6187, -3.3543, -1.3989, -0.5747, -3.2905, -4.2796])
[2022-08-21 01:24:54,287] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5575, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-21 01:24:54,507] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 65, batch_idx: 0, global_img_step: 372, aug_ops:[('brightness', tensor([-0.1394])), ('gaussian noise', tensor([-0.5818])), ('ShearY', tensor([0.1977]))]
[2022-08-21 01:24:54,508] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.014993	gLtNorm 0.2869 (0.2869)	gLvNorm 0.0872 (0.0872)	mvpNorm 0.1579 (0.1579)

[2022-08-21 01:47:14,945] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 65, batch_idx: 2500, global_img_step: 373, aug_ops:[('Rotate', tensor([0.6104])), ('TranslateX', tensor([0.2518]))]
[2022-08-21 01:47:14,946] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.014993	gLtNorm 0.0369 (0.6783)	gLvNorm 0.1153 (0.2577)	mvpNorm 0.2777 (0.9133)

[2022-08-21 02:09:35,381] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 65, batch_idx: 5000, global_img_step: 374, aug_ops:[('saturation', tensor([0.1433])), ('Hed', tensor([-0.3926,  0.4030,  0.4231])), ('TranslateX', tensor([-0.7404]))]
[2022-08-21 02:09:35,382] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.014993	gLtNorm 0.0631 (0.7201)	gLvNorm 0.2044 (0.2578)	mvpNorm 0.4562 (0.9673)

[2022-08-21 02:10:42,522] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 65, batch_idx: 0, global_img_step: 375, aug_ops:[('Rotate', tensor([-0.6237])), ('TranslateY', tensor([1.]))]
[2022-08-21 02:24:57,978] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 65, batch_idx: 1000, global_img_step: 376, aug_ops:[('Hed', tensor([ 0.4771,  0.1838, -0.0224])), ('Equalize', tensor([0.3052]))]
[2022-08-21 02:39:09,521] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 65, batch_idx: 2000, global_img_step: 377, aug_ops:[('idenity', [1.0])]
[2022-08-21 02:47:06,290] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 65	 Inner Train loss: 0.6396, acc=0.7565, lr=0.000000	
[2022-08-21 02:47:59,109] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 65	 Test loss: 0.6309, score: 0.7683
[2022-08-21 02:47:59,110] implicit-augment.py->main line:454 [INFO]66% (66/100)
[2022-08-21 02:48:00,133] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0074, -6.9103, -4.1617, -3.1202, -5.8904, -2.4849,  1.7077, -2.3576,
        -2.4849, -5.7687, -3.2044, -1.5488, -0.4248, -3.1406, -4.4295])
[2022-08-21 02:48:00,138] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.4076, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-21 02:48:00,325] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 66, batch_idx: 0, global_img_step: 378, aug_ops:[('TranslateY', tensor([1.])), ('ShearY', tensor([1.]))]
[2022-08-21 02:48:00,325] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.014242	gLtNorm 0.0179 (0.0179)	gLvNorm 0.0067 (0.0067)	mvpNorm 0.0041 (0.0041)

[2022-08-21 03:10:23,812] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 66, batch_idx: 2500, global_img_step: 379, aug_ops:[('contrast', tensor([0.0542])), ('Hsv', tensor([-0.2577,  0.0216, -0.0091])), ('sharpen', tensor([-0.3061])), ('gaussian noise', tensor([1.])), ('TranslateX', tensor([0.4239])), ('Equalize', tensor([-0.2898]))]
[2022-08-21 03:10:23,813] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.014242	gLtNorm 0.0192 (0.6061)	gLvNorm 0.0457 (0.2333)	mvpNorm 0.0351 (0.8295)

[2022-08-21 03:32:49,473] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 66, batch_idx: 5000, global_img_step: 380, aug_ops:[('ShearY', tensor([-0.1994]))]
[2022-08-21 03:32:49,474] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.014242	gLtNorm 0.0249 (0.6057)	gLvNorm 0.1622 (0.2364)	mvpNorm 0.1068 (0.8319)

[2022-08-21 03:33:57,001] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 66, batch_idx: 0, global_img_step: 381, aug_ops:[('saturation', tensor([0.1056])), ('Hsv', tensor([ 0.0725, -0.1413,  0.4648])), ('ShearX', tensor([0.2398]))]
[2022-08-21 03:48:08,367] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 66, batch_idx: 1000, global_img_step: 382, aug_ops:[('Hsv', tensor([-0.0017, -0.0144,  0.2095])), ('TranslateY', tensor([0.2488])), ('ShearY', tensor([0.1381])), ('Equalize', tensor([0.0426]))]
[2022-08-21 04:02:55,361] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 66, batch_idx: 2000, global_img_step: 383, aug_ops:[('sharpen', tensor([0.2347])), ('ShearX', tensor([-0.2555])), ('Equalize', tensor([0.4806]))]
[2022-08-21 04:10:53,872] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 66	 Inner Train loss: 0.6364, acc=0.7586, lr=0.000000	
[2022-08-21 04:11:46,626] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 66	 Test loss: 0.6330, score: 0.7693
[2022-08-21 04:11:46,628] implicit-augment.py->main line:454 [INFO]67% (67/100)
[2022-08-21 04:11:47,604] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8651, -7.0527, -4.3040, -2.9778, -5.7502, -2.4849,  1.5655, -2.3576,
        -2.4849, -5.9111, -3.0620, -1.6912, -0.2823, -3.2830, -4.2871])
[2022-08-21 04:11:47,610] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5500, -0.3155,  0.0000, -0.3198,  0.2889, -0.2413,
        -1.2884,  0.4275])
[2022-08-21 04:11:47,834] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 67, batch_idx: 0, global_img_step: 384, aug_ops:[('Rotate', tensor([0.0870])), ('TranslateY', tensor([-0.1429])), ('Equalize', tensor([0.3610]))]
[2022-08-21 04:11:47,835] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.013503	gLtNorm 0.0151 (0.0151)	gLvNorm 1.5896 (1.5896)	mvpNorm 1.6697 (1.6697)

[2022-08-21 04:34:10,950] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 67, batch_idx: 2500, global_img_step: 385, aug_ops:[('saturation', tensor([-0.0977])), ('Rotate', tensor([0.0277])), ('Equalize', tensor([0.2715]))]
[2022-08-21 04:34:10,951] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.013503	gLtNorm 0.0071 (0.5695)	gLvNorm 0.0455 (0.2483)	mvpNorm 0.0554 (0.8093)

[2022-08-21 04:56:26,969] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 67, batch_idx: 5000, global_img_step: 386, aug_ops:[('Hed', tensor([-0.2126,  0.4757,  0.3502])), ('Rotate', tensor([-0.0565]))]
[2022-08-21 04:56:26,971] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.013503	gLtNorm 0.0156 (0.5877)	gLvNorm 0.0159 (0.2501)	mvpNorm 0.0504 (0.8329)

[2022-08-21 04:57:33,868] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 67, batch_idx: 0, global_img_step: 387, aug_ops:[('sharpen', tensor([0.3679])), ('TranslateX', tensor([-0.2027])), ('ShearX', tensor([-0.2462]))]
[2022-08-21 05:11:46,078] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 67, batch_idx: 1000, global_img_step: 388, aug_ops:[('Hed', tensor([-0.0671, -0.4794,  0.4607]))]
[2022-08-21 05:25:53,181] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 67, batch_idx: 2000, global_img_step: 389, aug_ops:[('Hed', tensor([ 0.0938,  0.1464, -0.0662])), ('elastic transform', tensor([0.3787])), ('TranslateY', tensor([0.2254])), ('ShearX', tensor([-0.0630]))]
[2022-08-21 05:33:47,662] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 67	 Inner Train loss: 0.6372, acc=0.7573, lr=0.000000	
[2022-08-21 05:34:40,452] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 67	 Test loss: 0.6357, score: 0.7716
[2022-08-21 05:34:40,454] implicit-augment.py->main line:454 [INFO]68% (68/100)
[2022-08-21 05:34:41,458] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.7301, -6.9177, -4.1690, -3.1128, -5.6152, -2.4849,  1.4304, -2.3576,
        -2.4849, -5.7760, -3.1970, -1.8263, -0.4174, -3.1479, -4.1521])
[2022-08-21 05:34:41,463] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.5500, -0.3155,  0.0000, -0.3198,  0.2889, -0.3764,
        -1.2884,  0.4275])
[2022-08-21 05:34:41,703] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 68, batch_idx: 0, global_img_step: 390, aug_ops:[('TranslateX', tensor([-0.2055]))]
[2022-08-21 05:34:41,704] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.012777	gLtNorm 0.0373 (0.0373)	gLvNorm 0.2262 (0.2262)	mvpNorm 0.2114 (0.2114)

[2022-08-21 05:56:58,841] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 68, batch_idx: 2500, global_img_step: 391, aug_ops:[('saturation', tensor([-0.5401])), ('Hsv', tensor([-0.4835,  0.0091,  0.3674])), ('Hed', tensor([-0.5597, -0.1515,  0.2889])), ('Rotate', tensor([-0.3564]))]
[2022-08-21 05:56:58,843] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.012777	gLtNorm 0.2281 (0.7462)	gLvNorm 0.1220 (0.2724)	mvpNorm 0.6614 (1.0038)

[2022-08-21 06:19:15,839] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 68, batch_idx: 5000, global_img_step: 392, aug_ops:[('brightness', tensor([-1.])), ('saturation', tensor([0.0157])), ('Hsv', tensor([-0.1336, -0.2898, -0.0396]))]
[2022-08-21 06:19:15,840] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.012777	gLtNorm 0.6259 (0.7179)	gLvNorm 0.0117 (0.2723)	mvpNorm 0.7335 (0.9775)

[2022-08-21 06:20:22,971] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 68, batch_idx: 0, global_img_step: 393, aug_ops:[('contrast', tensor([-0.1187])), ('ShearY', tensor([-1.])), ('Equalize', tensor([0.2266]))]
[2022-08-21 06:34:37,150] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 68, batch_idx: 1000, global_img_step: 394, aug_ops:[('brightness', tensor([0.1934])), ('TranslateY', tensor([-1.])), ('ShearX', tensor([0.9943])), ('Equalize', tensor([0.1934]))]
[2022-08-21 06:48:47,069] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 68, batch_idx: 2000, global_img_step: 395, aug_ops:[('contrast', tensor([0.8308])), ('TranslateY', tensor([1.])), ('Equalize', tensor([0.1047]))]
[2022-08-21 06:56:45,358] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 68	 Inner Train loss: 0.6357, acc=0.7585, lr=0.000000	
[2022-08-21 06:57:38,152] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 68	 Test loss: 0.6346, score: 0.7663
[2022-08-21 06:57:38,154] implicit-augment.py->main line:454 [INFO]69% (69/100)
[2022-08-21 06:57:39,155] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8578, -7.0133, -4.2968, -2.9851, -5.4874, -2.4849,  1.5582, -2.3576,
        -2.4849, -5.6483, -3.0692, -1.9540, -0.2896, -3.0202, -4.2798])
[2022-08-21 06:57:39,161] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.6778, -0.3155,  0.0000, -0.3198,  0.2889, -0.3764,
        -1.1606,  0.5553])
[2022-08-21 06:57:39,347] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 69, batch_idx: 0, global_img_step: 396, aug_ops:[('Hed', tensor([0.6144, 0.5628, 0.4932])), ('gaussian noise', tensor([0.6920])), ('ShearY', tensor([-0.6556]))]
[2022-08-21 06:57:39,347] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.012064	gLtNorm 0.0589 (0.0589)	gLvNorm 0.0936 (0.0936)	mvpNorm 0.2460 (0.2460)

[2022-08-21 07:19:57,264] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 69, batch_idx: 2500, global_img_step: 397, aug_ops:[('brightness', tensor([-0.4334])), ('contrast', tensor([0.4871])), ('Hsv', tensor([-0.0083,  0.0387, -1.0000])), ('Rotate', tensor([0.2362])), ('TranslateX', tensor([0.0699]))]
[2022-08-21 07:19:57,265] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.012064	gLtNorm 3.9501 (0.5323)	gLvNorm 0.0792 (0.2290)	mvpNorm 4.7174 (0.7682)

[2022-08-21 07:42:18,178] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 69, batch_idx: 5000, global_img_step: 398, aug_ops:[('brightness', tensor([0.9017])), ('Rotate', tensor([-0.0304]))]
[2022-08-21 07:42:18,179] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.012064	gLtNorm 12.8646 (0.5402)	gLvNorm 0.0805 (0.2354)	mvpNorm 12.5744 (0.7819)

[2022-08-21 07:43:25,097] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 69, batch_idx: 0, global_img_step: 399, aug_ops:[('contrast', tensor([-0.1283])), ('saturation', tensor([0.9543])), ('Rotate', tensor([0.1880])), ('TranslateY', tensor([-1.])), ('ShearY', tensor([-0.1093]))]
[2022-08-21 07:57:31,274] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 69, batch_idx: 1000, global_img_step: 400, aug_ops:[('contrast', tensor([1.])), ('Hsv', tensor([-0.7206, -0.3651, -0.0547])), ('TranslateX', tensor([0.3950])), ('TranslateY', tensor([-1.]))]
[2022-08-21 08:11:43,654] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 69, batch_idx: 2000, global_img_step: 401, aug_ops:[('TranslateY', tensor([-0.1440]))]
[2022-08-21 08:19:38,743] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 69	 Inner Train loss: 0.6386, acc=0.7576, lr=0.000000	
[2022-08-21 08:20:31,738] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 69	 Test loss: 0.6310, score: 0.7650
[2022-08-21 08:20:31,739] implicit-augment.py->main line:454 [INFO]70% (70/100)
[2022-08-21 08:20:32,729] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9781, -7.1339, -4.2968, -2.8644, -5.3668, -2.4849,  1.6788, -2.3576,
        -2.4849, -5.5276, -3.1899, -1.8334, -0.4102, -3.1408, -4.4003])
[2022-08-21 08:20:32,735] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7984, -0.3155,  0.0000, -0.3198,  0.2889, -0.3764,
        -1.2812,  0.5553])
[2022-08-21 08:20:33,046] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 70, batch_idx: 0, global_img_step: 402, aug_ops:[('elastic transform', tensor([0.0708])), ('TranslateY', tensor([-0.4804]))]
[2022-08-21 08:20:33,047] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.011365	gLtNorm 0.0671 (0.0671)	gLvNorm 0.0466 (0.0466)	mvpNorm 0.1537 (0.1537)

[2022-08-21 08:42:53,224] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 70, batch_idx: 2500, global_img_step: 403, aug_ops:[('contrast', tensor([-0.2397]))]
[2022-08-21 08:42:53,226] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.011365	gLtNorm 0.0252 (0.4842)	gLvNorm 0.0569 (0.2032)	mvpNorm 0.1436 (0.6785)

[2022-08-21 09:05:12,942] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 70, batch_idx: 5000, global_img_step: 404, aug_ops:[('brightness', tensor([0.2913])), ('Equalize', tensor([0.2913]))]
[2022-08-21 09:05:12,943] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.011365	gLtNorm 0.1380 (0.4967)	gLvNorm 0.0557 (0.2026)	mvpNorm 0.0679 (0.6959)

[2022-08-21 09:06:20,397] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 70, batch_idx: 0, global_img_step: 405, aug_ops:[('Hed', tensor([ 0.0448,  1.0000, -0.1294])), ('Equalize', tensor([-0.1924]))]
[2022-08-21 09:20:29,513] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 70, batch_idx: 1000, global_img_step: 406, aug_ops:[('contrast', tensor([-0.0326])), ('sharpen', tensor([0.8255])), ('elastic transform', tensor([-0.9980])), ('Equalize', tensor([0.0846]))]
[2022-08-21 09:34:38,007] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 70, batch_idx: 2000, global_img_step: 407, aug_ops:[('TranslateY', tensor([0.6271])), ('ShearY', tensor([-0.1763]))]
[2022-08-21 09:42:37,622] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 70	 Inner Train loss: 0.6411, acc=0.7559, lr=0.000000	
[2022-08-21 09:43:30,395] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 70	 Test loss: 0.6368, score: 0.7682
[2022-08-21 09:43:30,397] implicit-augment.py->main line:454 [INFO]71% (71/100)
[2022-08-21 09:43:31,367] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8649, -7.2473, -4.4104, -2.9781, -5.2532, -2.4849,  1.7925, -2.3576,
        -2.4849, -5.4140, -3.3035, -1.9471, -0.2966, -3.2545, -4.2871])
[2022-08-21 09:43:31,373] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7984, -0.3155,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.1676,  0.5553])
[2022-08-21 09:43:31,556] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 71, batch_idx: 0, global_img_step: 408, aug_ops:[('contrast', tensor([0.4813])), ('Hsv', tensor([0.1913, 0.3664, 0.9243])), ('Rotate', tensor([-1.])), ('TranslateY', tensor([0.6739])), ('ShearY', tensor([-0.0147])), ('Equalize', tensor([0.1452]))]
[2022-08-21 09:43:31,557] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.010681	gLtNorm 0.2914 (0.2914)	gLvNorm 0.0110 (0.0110)	mvpNorm 0.2519 (0.2519)

[2022-08-21 10:05:49,188] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 71, batch_idx: 2500, global_img_step: 409, aug_ops:[('sharpen', tensor([0.2022])), ('TranslateX', tensor([0.7749]))]
[2022-08-21 10:05:49,190] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.010681	gLtNorm 0.0244 (0.6216)	gLvNorm 0.0762 (0.2355)	mvpNorm 0.0818 (0.8809)

[2022-08-21 10:28:03,195] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 71, batch_idx: 5000, global_img_step: 410, aug_ops:[('brightness', tensor([0.5369])), ('saturation', tensor([0.2665])), ('TranslateY', tensor([-0.2075]))]
[2022-08-21 10:28:03,196] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.010681	gLtNorm 0.0809 (0.6068)	gLvNorm 0.0322 (0.2353)	mvpNorm 0.1701 (0.8570)

[2022-08-21 10:29:14,116] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 71, batch_idx: 0, global_img_step: 411, aug_ops:[('idenity', [1.0])]
[2022-08-21 10:43:23,584] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 71, batch_idx: 1000, global_img_step: 412, aug_ops:[('brightness', tensor([0.6766])), ('TranslateX', tensor([-0.3212]))]
[2022-08-21 10:57:34,120] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 71, batch_idx: 2000, global_img_step: 413, aug_ops:[('ShearY', tensor([-0.3432]))]
[2022-08-21 11:05:29,571] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 71	 Inner Train loss: 0.6353, acc=0.7583, lr=0.000000	
[2022-08-21 11:06:22,533] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 71	 Test loss: 0.6305, score: 0.7713
[2022-08-21 11:06:22,535] implicit-augment.py->main line:454 [INFO]72% (72/100)
[2022-08-21 11:06:23,503] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.7581, -7.3534, -4.3036, -3.0849, -5.3600, -2.4849,  1.8993, -2.3576,
        -2.4849, -5.5208, -3.4099, -1.8402, -0.4034, -3.1476, -4.3939])
[2022-08-21 11:06:23,509] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7984, -0.3155,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.2744,  0.5553])
[2022-08-21 11:06:23,776] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 72, batch_idx: 0, global_img_step: 414, aug_ops:[('Hed', tensor([ 0.3607, -0.6476, -0.1906])), ('Rotate', tensor([-1.])), ('Equalize', tensor([0.2504]))]
[2022-08-21 11:06:23,776] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.010013	gLtNorm 0.0715 (0.0715)	gLvNorm 0.0483 (0.0483)	mvpNorm 0.0719 (0.0719)

[2022-08-21 11:28:42,030] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 72, batch_idx: 2500, global_img_step: 415, aug_ops:[('brightness', tensor([1.])), ('sharpen', tensor([-0.0240])), ('TranslateY', tensor([0.2941]))]
[2022-08-21 11:28:42,031] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.010013	gLtNorm 0.0491 (0.8198)	gLvNorm 0.0736 (0.2635)	mvpNorm 0.1570 (1.0496)

[2022-08-21 11:51:00,361] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 72, batch_idx: 5000, global_img_step: 416, aug_ops:[('contrast', tensor([-1.])), ('Hed', tensor([ 0.8802,  1.0000, -0.6901])), ('sharpen', tensor([-0.8126])), ('ShearY', tensor([-0.2814]))]
[2022-08-21 11:51:00,362] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.010013	gLtNorm 0.4425 (0.7790)	gLvNorm 0.0397 (0.2601)	mvpNorm 0.4407 (1.0192)

[2022-08-21 11:52:07,780] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 72, batch_idx: 0, global_img_step: 417, aug_ops:[('brightness', tensor([-0.0648])), ('contrast', tensor([0.9746])), ('Rotate', tensor([1.]))]
[2022-08-21 12:06:18,455] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 72, batch_idx: 1000, global_img_step: 418, aug_ops:[('Hed', tensor([ 0.0946, -0.1661,  1.0000])), ('ShearX', tensor([-0.0973]))]
[2022-08-21 12:20:28,093] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 72, batch_idx: 2000, global_img_step: 419, aug_ops:[('brightness', tensor([0.2629])), ('contrast', tensor([-0.0607])), ('saturation', tensor([-0.1946])), ('sharpen', tensor([-0.0589])), ('gaussian noise', tensor([0.5354])), ('ShearY', tensor([-0.1642]))]
[2022-08-21 12:28:25,865] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 72	 Inner Train loss: 0.6360, acc=0.7577, lr=0.000000	
[2022-08-21 12:29:18,658] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 72	 Test loss: 0.6323, score: 0.7687
[2022-08-21 12:29:18,659] implicit-augment.py->main line:454 [INFO]73% (73/100)
[2022-08-21 12:29:19,657] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.6588, -7.4534, -4.4036, -3.0413, -5.2619, -2.4849,  1.7992, -2.3576,
        -2.4849, -5.4207, -3.5100, -1.9404, -0.5035, -3.2478, -4.2938])
[2022-08-21 12:29:19,663] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.8984, -0.3155,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3745,  0.5553])
[2022-08-21 12:29:19,903] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 73, batch_idx: 0, global_img_step: 420, aug_ops:[('Rotate', tensor([-0.7451]))]
[2022-08-21 12:29:19,904] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.009361	gLtNorm 0.2691 (0.2691)	gLvNorm 0.0215 (0.0215)	mvpNorm 0.2836 (0.2836)

[2022-08-21 12:51:40,408] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 73, batch_idx: 2500, global_img_step: 421, aug_ops:[('Hed', tensor([ 0.4080, -0.3498,  0.1608])), ('TranslateX', tensor([-0.2569])), ('ShearY', tensor([-0.0104]))]
[2022-08-21 12:51:40,409] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.009361	gLtNorm 0.2852 (0.5105)	gLvNorm 0.0588 (0.2333)	mvpNorm 0.1467 (0.7332)

[2022-08-21 13:13:56,629] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 73, batch_idx: 5000, global_img_step: 422, aug_ops:[('saturation', tensor([0.0057])), ('Hsv', tensor([0.1057, 0.4330, 0.1488])), ('gaussian noise', tensor([0.1779])), ('TranslateY', tensor([0.5640]))]
[2022-08-21 13:13:56,630] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.009361	gLtNorm 0.3008 (0.5415)	gLvNorm 0.0214 (0.2352)	mvpNorm 0.4062 (0.7681)

[2022-08-21 13:15:03,701] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 73, batch_idx: 0, global_img_step: 423, aug_ops:[('elastic transform', tensor([-0.2095])), ('ShearY', tensor([1.]))]
[2022-08-21 13:29:17,078] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 73, batch_idx: 1000, global_img_step: 424, aug_ops:[('brightness', tensor([0.7259])), ('sharpen', tensor([0.0630])), ('Rotate', tensor([-0.6453])), ('ShearY', tensor([0.4570]))]
[2022-08-21 13:43:25,467] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 73, batch_idx: 2000, global_img_step: 425, aug_ops:[('brightness', tensor([-1.])), ('sharpen', tensor([0.0598])), ('TranslateY', tensor([-1.]))]
[2022-08-21 13:51:22,951] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 73	 Inner Train loss: 0.6375, acc=0.7574, lr=0.000000	
[2022-08-21 13:52:15,899] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 73	 Test loss: 0.6335, score: 0.7655
[2022-08-21 13:52:15,900] implicit-augment.py->main line:454 [INFO]74% (74/100)
[2022-08-21 13:52:16,910] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.7521, -7.3598, -4.4972, -2.9477, -5.1687, -2.4849,  1.8928, -2.3576,
        -2.4849, -5.3271, -3.6032, -1.8468, -0.5971, -3.3414, -4.3874])
[2022-08-21 13:52:16,914] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.8048, -0.3155,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.4681,  0.5553])
[2022-08-21 13:52:17,213] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 74, batch_idx: 0, global_img_step: 426, aug_ops:[('saturation', tensor([0.3059])), ('Hsv', tensor([-0.0938,  0.8407,  0.4084])), ('Hed', tensor([-0.2557, -0.6691, -0.2045])), ('Equalize', tensor([-0.5266]))]
[2022-08-21 13:52:17,214] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.008727	gLtNorm 0.7987 (0.7987)	gLvNorm 0.0908 (0.0908)	mvpNorm 0.5053 (0.5053)

[2022-08-21 14:14:36,328] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 74, batch_idx: 2500, global_img_step: 427, aug_ops:[('saturation', tensor([-0.4817])), ('Hsv', tensor([ 0.0474,  0.0930, -0.0669])), ('gaussian noise', tensor([0.7019])), ('TranslateX', tensor([0.1081]))]
[2022-08-21 14:14:36,329] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.008727	gLtNorm 0.1943 (0.7914)	gLvNorm 0.8209 (0.2130)	mvpNorm 1.4121 (1.0196)

[2022-08-21 14:36:54,660] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 74, batch_idx: 5000, global_img_step: 428, aug_ops:[('Hed', tensor([-0.6893,  0.5296,  0.3831])), ('sharpen', tensor([0.0212])), ('elastic transform', tensor([0.6073]))]
[2022-08-21 14:36:54,662] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.008727	gLtNorm 0.1559 (0.8128)	gLvNorm 0.0191 (0.2097)	mvpNorm 0.1265 (1.0371)

[2022-08-21 14:38:01,769] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 74, batch_idx: 0, global_img_step: 429, aug_ops:[('sharpen', tensor([-0.0273]))]
[2022-08-21 14:52:09,052] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 74, batch_idx: 1000, global_img_step: 430, aug_ops:[('saturation', tensor([-0.3331])), ('Hsv', tensor([0.3829, 1.0000, 0.0506])), ('TranslateY', tensor([0.2375]))]
[2022-08-21 15:06:17,740] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 74, batch_idx: 2000, global_img_step: 431, aug_ops:[('brightness', tensor([-0.5058])), ('sharpen', tensor([0.1176])), ('TranslateX', tensor([0.1600])), ('ShearY', tensor([-0.1867]))]
[2022-08-21 15:14:11,869] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 74	 Inner Train loss: 0.6369, acc=0.7577, lr=0.000000	
[2022-08-21 15:15:04,790] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 74	 Test loss: 0.6317, score: 0.7734
[2022-08-21 15:15:04,791] implicit-augment.py->main line:454 [INFO]75% (75/100)
[2022-08-21 15:15:05,781] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8394, -7.4471, -4.5844, -3.0350, -5.0814, -2.4849,  1.8055, -2.3576,
        -2.4849, -5.2398, -3.5160, -1.7595, -0.6844, -3.2541, -4.3002])
[2022-08-21 15:15:05,786] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.1653, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.8921, -0.3155,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.4681,  0.5553])
[2022-08-21 15:15:05,994] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 75, batch_idx: 0, global_img_step: 432, aug_ops:[('contrast', tensor([0.0346])), ('saturation', tensor([0.2137])), ('Hsv', tensor([-1.0000, -0.2865,  0.4219])), ('Hed', tensor([ 0.1801, -0.4144, -0.7334])), ('Rotate', tensor([-0.2183])), ('ShearX', tensor([1.])), ('Equalize', tensor([0.4360]))]
[2022-08-21 15:15:05,995] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.008110	gLtNorm 0.1373 (0.1373)	gLvNorm 0.0198 (0.0198)	mvpNorm 0.0642 (0.0642)

[2022-08-21 15:37:24,005] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 75, batch_idx: 2500, global_img_step: 433, aug_ops:[('Hsv', tensor([-0.5767, -0.2506,  0.6224])), ('Equalize', tensor([0.1014]))]
[2022-08-21 15:37:24,007] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.008110	gLtNorm 5.4214 (0.6051)	gLvNorm 0.0937 (0.2719)	mvpNorm 5.6833 (0.8849)

[2022-08-21 15:59:42,186] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 75, batch_idx: 5000, global_img_step: 434, aug_ops:[('contrast', tensor([0.1264])), ('elastic transform', tensor([-0.1694])), ('ShearY', tensor([-0.0863]))]
[2022-08-21 15:59:42,187] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.008110	gLtNorm 0.0616 (0.6407)	gLvNorm 0.1489 (0.2681)	mvpNorm 0.0306 (0.9138)

[2022-08-21 16:00:49,168] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 75, batch_idx: 0, global_img_step: 435, aug_ops:[('Hed', tensor([ 7.3580e-01,  2.4352e-05, -9.6601e-01])), ('TranslateY', tensor([0.1916]))]
[2022-08-21 16:14:59,561] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 75, batch_idx: 1000, global_img_step: 436, aug_ops:[('Hsv', tensor([ 0.0152, -0.5137, -0.4467])), ('Rotate', tensor([-0.9511])), ('TranslateX', tensor([0.1143]))]
[2022-08-21 16:29:07,418] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 75, batch_idx: 2000, global_img_step: 437, aug_ops:[('Hsv', tensor([0.6588, 0.6538, 0.2946])), ('Hed', tensor([-0.0637,  0.1054,  0.1818])), ('gaussian blur', tensor([1.])), ('gaussian noise', tensor([-0.0470]))]
[2022-08-21 16:37:06,184] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 75	 Inner Train loss: 0.6364, acc=0.7574, lr=0.000000	
[2022-08-21 16:37:59,224] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 75	 Test loss: 0.6306, score: 0.7658
[2022-08-21 16:37:59,225] implicit-augment.py->main line:454 [INFO]76% (76/100)
[2022-08-21 16:38:00,196] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9205, -7.3660, -4.5033, -3.1161, -5.1625, -2.4849,  1.7244, -2.2765,
        -2.4849, -5.3209, -3.4351, -1.8406, -0.7655, -3.1730, -4.2191])
[2022-08-21 16:38:00,201] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.8110, -0.3966,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.4681,  0.5553])
[2022-08-21 16:38:00,420] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 76, batch_idx: 0, global_img_step: 438, aug_ops:[('gaussian noise', tensor([0.3950])), ('Rotate', tensor([0.5346]))]
[2022-08-21 16:38:00,421] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.007512	gLtNorm 0.0220 (0.0220)	gLvNorm 0.0486 (0.0486)	mvpNorm 0.0851 (0.0851)

[2022-08-21 17:00:18,527] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 76, batch_idx: 2500, global_img_step: 439, aug_ops:[('sharpen', tensor([-0.0410])), ('Equalize', tensor([-0.2959]))]
[2022-08-21 17:00:18,529] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.007512	gLtNorm 0.1245 (0.6060)	gLvNorm 0.0541 (0.2116)	mvpNorm 0.1942 (0.8184)

[2022-08-21 17:22:34,580] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 76, batch_idx: 5000, global_img_step: 440, aug_ops:[('saturation', tensor([0.0404])), ('Hsv', tensor([-0.1889, -0.0017, -0.1280])), ('sharpen', tensor([-0.6915])), ('Equalize', tensor([0.2016]))]
[2022-08-21 17:22:34,582] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.007512	gLtNorm 0.0734 (0.6395)	gLvNorm 0.0415 (0.2087)	mvpNorm 0.1345 (0.8507)

[2022-08-21 17:23:42,234] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 76, batch_idx: 0, global_img_step: 441, aug_ops:[('saturation', tensor([1.])), ('ShearX', tensor([-0.0058])), ('Equalize', tensor([0.4384]))]
[2022-08-21 17:37:52,738] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 76, batch_idx: 1000, global_img_step: 442, aug_ops:[('Equalize', tensor([0.2329]))]
[2022-08-21 17:52:01,116] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 76, batch_idx: 2000, global_img_step: 443, aug_ops:[('TranslateX', tensor([-0.4089]))]
[2022-08-21 17:59:56,775] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 76	 Inner Train loss: 0.6356, acc=0.7582, lr=0.000000	
[2022-08-21 18:00:49,727] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 76	 Test loss: 0.6343, score: 0.7724
[2022-08-21 18:00:49,727] implicit-augment.py->main line:454 [INFO]77% (77/100)
[2022-08-21 18:00:50,669] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8462, -7.4411, -4.4282, -3.0410, -5.0874, -2.4849,  1.6493, -2.2765,
        -2.4849, -5.2458, -3.3600, -1.7655, -0.6904, -3.2481, -4.2941])
[2022-08-21 18:00:50,675] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.7359, -0.3966,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3930,  0.5553])
[2022-08-21 18:00:50,955] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 77, batch_idx: 0, global_img_step: 444, aug_ops:[('Hsv', tensor([-0.0037, -0.2557, -0.7994])), ('elastic transform', tensor([0.2888]))]
[2022-08-21 18:00:50,956] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.006932	gLtNorm 0.1434 (0.1434)	gLvNorm 1.6664 (1.6664)	mvpNorm 1.4249 (1.4249)

[2022-08-21 18:23:12,119] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 77, batch_idx: 2500, global_img_step: 445, aug_ops:[('Rotate', tensor([0.8160])), ('TranslateX', tensor([0.1017])), ('Equalize', tensor([0.4289]))]
[2022-08-21 18:23:12,120] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.006932	gLtNorm 0.0624 (0.8214)	gLvNorm 0.0563 (0.2829)	mvpNorm 0.0123 (1.0926)

[2022-08-21 18:45:24,710] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 77, batch_idx: 5000, global_img_step: 446, aug_ops:[('elastic transform', tensor([0.1855])), ('TranslateX', tensor([0.2959]))]
[2022-08-21 18:45:24,711] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.006932	gLtNorm 0.0471 (0.7950)	gLvNorm 0.0281 (0.2806)	mvpNorm 0.0392 (1.0616)

[2022-08-21 18:46:31,883] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 77, batch_idx: 0, global_img_step: 447, aug_ops:[('ShearY', tensor([-0.2151])), ('Equalize', tensor([-0.1969]))]
[2022-08-21 19:00:38,674] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 77, batch_idx: 1000, global_img_step: 448, aug_ops:[('brightness', tensor([-0.5537]))]
[2022-08-21 19:14:46,326] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 77, batch_idx: 2000, global_img_step: 449, aug_ops:[('brightness', tensor([0.4386]))]
[2022-08-21 19:22:41,515] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 77	 Inner Train loss: 0.6352, acc=0.7582, lr=0.000000	
[2022-08-21 19:23:34,490] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 77	 Test loss: 0.6343, score: 0.7702
[2022-08-21 19:23:34,491] implicit-augment.py->main line:454 [INFO]78% (78/100)
[2022-08-21 19:23:35,543] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9112, -7.5103, -4.4972, -2.9716, -5.1564, -2.4849,  1.5800, -2.2072,
        -2.4849, -5.3151, -3.2906, -1.6962, -0.6211, -3.1788, -4.3634])
[2022-08-21 19:23:35,550] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2989,  0.6666, -0.3272,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3237,  0.5553])
[2022-08-21 19:23:35,820] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 78, batch_idx: 0, global_img_step: 450, aug_ops:[('contrast', tensor([-0.8526])), ('Rotate', tensor([0.0396])), ('TranslateX', tensor([-0.4869])), ('ShearY', tensor([-0.0026]))]
[2022-08-21 19:23:35,821] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.006373	gLtNorm 0.0697 (0.0697)	gLvNorm 0.0255 (0.0255)	mvpNorm 0.1318 (0.1318)

[2022-08-21 19:45:52,804] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 78, batch_idx: 2500, global_img_step: 451, aug_ops:[('TranslateY', tensor([-0.6804]))]
[2022-08-21 19:45:52,806] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.006373	gLtNorm 0.0649 (0.7085)	gLvNorm 0.4832 (0.2493)	mvpNorm 0.3594 (0.9684)

[2022-08-21 20:08:12,092] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 78, batch_idx: 5000, global_img_step: 452, aug_ops:[('elastic transform', tensor([-0.2623])), ('TranslateX', tensor([-0.5252]))]
[2022-08-21 20:08:12,093] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.006373	gLtNorm 0.0086 (0.7383)	gLvNorm 0.9686 (0.2485)	mvpNorm 1.1386 (0.9887)

[2022-08-21 20:09:19,500] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 78, batch_idx: 0, global_img_step: 453, aug_ops:[('brightness', tensor([-0.0042])), ('contrast', tensor([-0.0442]))]
[2022-08-21 20:23:30,034] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 78, batch_idx: 1000, global_img_step: 454, aug_ops:[('sharpen', tensor([-0.2494]))]
[2022-08-21 20:37:40,880] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 78, batch_idx: 2000, global_img_step: 455, aug_ops:[('brightness', tensor([-0.3077]))]
[2022-08-21 20:45:39,942] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 78	 Inner Train loss: 0.6345, acc=0.7584, lr=0.000000	
[2022-08-21 20:46:32,858] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 78	 Test loss: 0.6296, score: 0.7677
[2022-08-21 20:46:32,860] implicit-augment.py->main line:454 [INFO]79% (79/100)
[2022-08-21 20:46:33,854] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9749, -7.4491, -4.4334, -2.9079, -5.0927, -2.4849,  1.6437, -2.2072,
        -2.4849, -5.2514, -3.2269, -1.7599, -0.5573, -3.2425, -4.4271])
[2022-08-21 20:46:33,860] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.6029, -0.3272,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3237,  0.5553])
[2022-08-21 20:46:34,047] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 79, batch_idx: 0, global_img_step: 456, aug_ops:[('saturation', tensor([0.3020])), ('Hsv', tensor([ 0.8235, -0.1837, -0.4795])), ('sharpen', tensor([-0.2099])), ('elastic transform', tensor([-0.3260])), ('TranslateY', tensor([-1.])), ('ShearX', tensor([0.4064]))]
[2022-08-21 20:46:34,047] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.005834	gLtNorm 0.0662 (0.0662)	gLvNorm 0.0652 (0.0652)	mvpNorm 0.1957 (0.1957)

[2022-08-21 21:08:54,284] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 79, batch_idx: 2500, global_img_step: 457, aug_ops:[('sharpen', tensor([0.0338]))]
[2022-08-21 21:08:54,285] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.005834	gLtNorm 0.0379 (0.4982)	gLvNorm 0.4367 (0.2129)	mvpNorm 0.3887 (0.7055)

[2022-08-21 21:31:12,257] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 79, batch_idx: 5000, global_img_step: 458, aug_ops:[('contrast', tensor([-0.5107])), ('Rotate', tensor([-0.0358])), ('ShearY', tensor([-0.4431]))]
[2022-08-21 21:31:12,259] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.005834	gLtNorm 0.0636 (0.4435)	gLvNorm 0.0128 (0.2107)	mvpNorm 0.0424 (0.6522)

[2022-08-21 21:32:19,091] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 79, batch_idx: 0, global_img_step: 459, aug_ops:[('Hsv', tensor([0.1396, 0.9857, 0.1514])), ('sharpen', tensor([-0.1189])), ('Equalize', tensor([-1.]))]
[2022-08-21 21:46:30,518] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 79, batch_idx: 1000, global_img_step: 460, aug_ops:[('brightness', tensor([-0.2323])), ('contrast', tensor([-0.5981])), ('gaussian blur', tensor([-0.1156])), ('sharpen', tensor([0.4793])), ('ShearX', tensor([-0.1662]))]
[2022-08-21 22:00:40,287] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 79, batch_idx: 2000, global_img_step: 461, aug_ops:[('saturation', tensor([0.3949])), ('sharpen', tensor([-0.8953]))]
[2022-08-21 22:08:34,814] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 79	 Inner Train loss: 0.6333, acc=0.7596, lr=0.000000	
[2022-08-21 22:09:27,747] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 79	 Test loss: 0.6372, score: 0.7721
[2022-08-21 22:09:27,748] implicit-augment.py->main line:454 [INFO]80% (80/100)
[2022-08-21 22:09:28,794] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-4.0332, -7.3908, -4.3751, -2.8496, -5.1502, -2.4849,  1.7021, -2.2072,
        -2.4849, -5.3097, -3.2853, -1.7017, -0.4990, -3.3009, -4.4854])
[2022-08-21 22:09:28,800] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.5445, -0.3272,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3237,  0.5553])
[2022-08-21 22:09:29,009] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 80, batch_idx: 0, global_img_step: 462, aug_ops:[('ShearX', tensor([1.])), ('Equalize', tensor([-0.2220]))]
[2022-08-21 22:09:29,009] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.005316	gLtNorm 0.0723 (0.0723)	gLvNorm 0.0357 (0.0357)	mvpNorm 0.1371 (0.1371)

[2022-08-21 22:31:48,000] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 80, batch_idx: 2500, global_img_step: 463, aug_ops:[('Rotate', tensor([-0.2024])), ('TranslateX', tensor([-1.]))]
[2022-08-21 22:31:48,001] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.005316	gLtNorm 0.2651 (0.6065)	gLvNorm 0.0369 (0.2875)	mvpNorm 0.1402 (0.8840)

[2022-08-21 22:54:04,714] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 80, batch_idx: 5000, global_img_step: 464, aug_ops:[('Hed', tensor([ 0.2451, -0.7483, -0.0466])), ('Equalize', tensor([0.0125]))]
[2022-08-21 22:54:04,715] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.005316	gLtNorm 0.0237 (0.5991)	gLvNorm 0.0397 (0.2849)	mvpNorm 0.0987 (0.8756)

[2022-08-21 22:55:11,621] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 80, batch_idx: 0, global_img_step: 465, aug_ops:[('brightness', tensor([-0.3825])), ('saturation', tensor([-0.0153]))]
[2022-08-21 23:09:22,395] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 80, batch_idx: 1000, global_img_step: 466, aug_ops:[('brightness', tensor([1.])), ('Hed', tensor([-0.1222,  0.0687, -0.5059])), ('TranslateY', tensor([-0.3636])), ('ShearX', tensor([0.3674]))]
[2022-08-21 23:23:31,710] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 80, batch_idx: 2000, global_img_step: 467, aug_ops:[('contrast', tensor([0.5038])), ('sharpen', tensor([-0.3962])), ('Equalize', tensor([-0.6394]))]
[2022-08-21 23:31:28,344] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 80	 Inner Train loss: 0.6355, acc=0.7598, lr=0.000000	
[2022-08-21 23:32:21,303] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 80	 Test loss: 0.6361, score: 0.7715
[2022-08-21 23:32:21,304] implicit-augment.py->main line:454 [INFO]81% (81/100)
[2022-08-21 23:32:22,437] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9801, -7.3376, -4.4282, -2.7964, -5.1981, -2.4849,  1.7552, -2.2072,
        -2.4849, -5.3628, -3.3384, -1.7549, -0.5522, -3.2477, -4.5386])
[2022-08-21 23:32:22,440] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7165, -0.7165, -0.2737,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.4914, -0.3272,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3237,  0.5553])
[2022-08-21 23:32:22,733] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 81, batch_idx: 0, global_img_step: 468, aug_ops:[('contrast', tensor([0.0225])), ('TranslateX', tensor([-0.2089])), ('ShearX', tensor([0.3804])), ('Equalize', tensor([-0.0348]))]
[2022-08-21 23:32:22,734] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.004820	gLtNorm 0.0511 (0.0511)	gLvNorm 0.5395 (0.5395)	mvpNorm 0.8752 (0.8752)

[2022-08-21 23:54:36,981] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 81, batch_idx: 2500, global_img_step: 469, aug_ops:[('brightness', tensor([0.6329])), ('saturation', tensor([0.8489])), ('Hed', tensor([0.0539, 0.5533, 0.0039])), ('sharpen', tensor([-0.7237])), ('gaussian noise', tensor([-0.2961])), ('Rotate', tensor([-0.3744])), ('ShearX', tensor([0.5186]))]
[2022-08-21 23:54:36,982] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.004820	gLtNorm 1.2764 (0.4733)	gLvNorm 0.0415 (0.2641)	mvpNorm 0.9910 (0.7596)

[2022-08-22 00:16:57,617] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 81, batch_idx: 5000, global_img_step: 470, aug_ops:[('sharpen', tensor([0.1591])), ('Rotate', tensor([-0.0630]))]
[2022-08-22 00:16:57,619] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.004820	gLtNorm 0.0126 (0.4677)	gLvNorm 0.0843 (0.2625)	mvpNorm 0.0672 (0.7458)

[2022-08-22 00:18:04,797] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 81, batch_idx: 0, global_img_step: 471, aug_ops:[('Hsv', tensor([-0.4510,  0.0336,  0.1792])), ('Hed', tensor([ 0.4472, -0.5916, -1.0000]))]
[2022-08-22 00:32:13,150] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 81, batch_idx: 1000, global_img_step: 472, aug_ops:[('brightness', tensor([0.2094])), ('sharpen', tensor([-0.2904])), ('TranslateX', tensor([-0.0008])), ('ShearX', tensor([-0.2729])), ('ShearY', tensor([0.7325]))]
[2022-08-22 00:46:27,963] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 81, batch_idx: 2000, global_img_step: 473, aug_ops:[('TranslateX', tensor([-0.3171])), ('TranslateY', tensor([-0.3671])), ('Equalize', tensor([-0.1356]))]
[2022-08-22 00:54:25,682] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 81	 Inner Train loss: 0.6306, acc=0.7605, lr=0.000000	
[2022-08-22 00:55:18,556] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 81	 Test loss: 0.6394, score: 0.7652
[2022-08-22 00:55:18,557] implicit-augment.py->main line:454 [INFO]82% (82/100)
[2022-08-22 00:55:19,530] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9320, -7.2895, -4.4763, -2.8446, -5.2463, -2.4849,  1.7071, -2.2072,
        -2.4849, -5.3146, -3.2902, -1.8031, -0.5040, -3.2959, -4.4904])
[2022-08-22 00:55:19,535] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.5396, -0.3272,  0.0000, -0.3198,  0.2889, -0.4900,
        -1.3237,  0.5553])
[2022-08-22 00:55:19,707] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 82, batch_idx: 0, global_img_step: 474, aug_ops:[('brightness', tensor([-0.3660])), ('ShearY', tensor([0.4020]))]
[2022-08-22 00:55:19,708] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.004345	gLtNorm 0.0431 (0.0431)	gLvNorm 0.1001 (0.1001)	mvpNorm 0.2474 (0.2474)

[2022-08-22 01:17:37,547] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 82, batch_idx: 2500, global_img_step: 475, aug_ops:[('Hsv', tensor([ 0.3563, -0.0990,  0.5422])), ('Rotate', tensor([0.1188])), ('TranslateY', tensor([-0.2851]))]
[2022-08-22 01:17:37,549] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.004345	gLtNorm 0.0296 (0.5586)	gLvNorm 0.0589 (0.2425)	mvpNorm 0.1062 (0.8195)

[2022-08-22 01:40:35,533] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 82, batch_idx: 5000, global_img_step: 476, aug_ops:[('contrast', tensor([-0.1875])), ('sharpen', tensor([0.5005])), ('TranslateY', tensor([-1.]))]
[2022-08-22 01:40:35,535] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.004345	gLtNorm 0.0111 (0.5159)	gLvNorm 0.0145 (0.2419)	mvpNorm 0.0389 (0.7752)

[2022-08-22 01:41:42,864] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 82, batch_idx: 0, global_img_step: 477, aug_ops:[('brightness', tensor([1.])), ('sharpen', tensor([-0.3446])), ('gaussian noise', tensor([0.2524]))]
[2022-08-22 01:55:50,842] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 82, batch_idx: 1000, global_img_step: 478, aug_ops:[('brightness', tensor([-0.5990])), ('Hsv', tensor([-0.6126, -0.7000,  0.0734])), ('Rotate', tensor([-1.])), ('TranslateX', tensor([0.4879])), ('Equalize', tensor([-0.5990]))]
[2022-08-22 02:10:03,100] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 82, batch_idx: 2000, global_img_step: 479, aug_ops:[('saturation', tensor([0.1673])), ('gaussian noise', tensor([-0.4120])), ('ShearY', tensor([0.2428]))]
[2022-08-22 02:17:59,395] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 82	 Inner Train loss: 0.6361, acc=0.7581, lr=0.000000	
[2022-08-22 02:18:52,234] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 82	 Test loss: 0.6320, score: 0.7687
[2022-08-22 02:18:52,235] implicit-augment.py->main line:454 [INFO]83% (83/100)
[2022-08-22 02:18:53,235] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8886, -7.3330, -4.4329, -2.8012, -5.2897, -2.4849,  1.7071, -2.2072,
        -2.4849, -5.3581, -3.2468, -1.7596, -0.4605, -3.3394, -4.4469])
[2022-08-22 02:18:53,239] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.5396, -0.3272,  0.0000, -0.3198,  0.2889, -0.4466,
        -1.2802,  0.5553])
[2022-08-22 02:18:53,444] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 83, batch_idx: 0, global_img_step: 480, aug_ops:[('brightness', tensor([-0.3485])), ('sharpen', tensor([0.5894])), ('TranslateX', tensor([-0.2287])), ('ShearX', tensor([0.2343])), ('ShearY', tensor([0.7465]))]
[2022-08-22 02:18:53,445] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.003894	gLtNorm 0.6279 (0.6279)	gLvNorm 0.1030 (0.1030)	mvpNorm 1.1929 (1.1929)

[2022-08-22 02:41:17,061] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 83, batch_idx: 2500, global_img_step: 481, aug_ops:[('contrast', tensor([0.2163])), ('Hsv', tensor([ 0.1614, -0.1223, -0.9211])), ('Hed', tensor([-0.1292,  0.9273,  1.0000])), ('sharpen', tensor([0.5763])), ('gaussian noise', tensor([-0.1527])), ('ShearY', tensor([0.2925]))]
[2022-08-22 02:41:17,063] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.003894	gLtNorm 0.2164 (0.5281)	gLvNorm 0.0857 (0.2094)	mvpNorm 0.0479 (0.7314)

[2022-08-22 03:03:41,904] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 83, batch_idx: 5000, global_img_step: 482, aug_ops:[('brightness', tensor([0.9262])), ('contrast', tensor([-0.1624])), ('sharpen', tensor([-0.7861])), ('ShearX', tensor([0.7064])), ('Equalize', tensor([0.9262]))]
[2022-08-22 03:03:41,905] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.003894	gLtNorm 0.0569 (0.5324)	gLvNorm 0.0253 (0.2126)	mvpNorm 0.0900 (0.7312)

[2022-08-22 03:04:49,575] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 83, batch_idx: 0, global_img_step: 483, aug_ops:[('Equalize', tensor([-0.6901]))]
[2022-08-22 03:19:02,163] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 83, batch_idx: 1000, global_img_step: 484, aug_ops:[('Hsv', tensor([ 0.3731,  0.0345, -0.5193])), ('TranslateX', tensor([0.0752]))]
[2022-08-22 03:33:09,988] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 83, batch_idx: 2000, global_img_step: 485, aug_ops:[('gaussian noise', tensor([-0.1046])), ('TranslateX', tensor([-0.6477])), ('TranslateY', tensor([0.2850])), ('ShearY', tensor([0.5681])), ('Equalize', tensor([-0.0863]))]
[2022-08-22 03:41:08,260] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 83	 Inner Train loss: 0.6318, acc=0.7602, lr=0.000000	
[2022-08-22 03:42:01,079] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 83	 Test loss: 0.6351, score: 0.7593
[2022-08-22 03:42:01,080] implicit-augment.py->main line:454 [INFO]84% (84/100)
[2022-08-22 03:42:02,052] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8513, -7.2940, -4.3940, -2.8401, -5.2508, -2.4849,  1.6681, -2.2072,
        -2.4849, -5.3970, -3.2857, -1.7207, -0.4995, -3.3783, -4.4080])
[2022-08-22 03:42:02,058] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.5006, -0.3272,  0.0000, -0.3198,  0.2889, -0.4076,
        -1.2802,  0.5553])
[2022-08-22 03:42:02,328] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 84, batch_idx: 0, global_img_step: 486, aug_ops:[('elastic transform', tensor([-0.3029]))]
[2022-08-22 03:42:02,328] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.003465	gLtNorm 0.1786 (0.1786)	gLvNorm 0.1908 (0.1908)	mvpNorm 0.7218 (0.7218)

[2022-08-22 04:04:26,700] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 84, batch_idx: 2500, global_img_step: 487, aug_ops:[('sharpen', tensor([0.5384])), ('Rotate', tensor([-0.1298])), ('Equalize', tensor([-0.2600]))]
[2022-08-22 04:04:26,702] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.003465	gLtNorm 0.0848 (0.4187)	gLvNorm 0.0725 (0.1974)	mvpNorm 0.1981 (0.6259)

[2022-08-22 04:26:51,176] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 84, batch_idx: 5000, global_img_step: 488, aug_ops:[('Rotate', tensor([-0.7453]))]
[2022-08-22 04:26:51,177] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.003465	gLtNorm 0.1020 (0.4234)	gLvNorm 0.0458 (0.1945)	mvpNorm 0.0136 (0.6256)

[2022-08-22 04:27:58,692] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 84, batch_idx: 0, global_img_step: 489, aug_ops:[('saturation', tensor([-0.9090])), ('TranslateY', tensor([-0.7564]))]
[2022-08-22 04:42:08,134] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 84, batch_idx: 1000, global_img_step: 490, aug_ops:[('TranslateY', tensor([-0.1624])), ('ShearX', tensor([0.4705]))]
[2022-08-22 04:56:19,279] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 84, batch_idx: 2000, global_img_step: 491, aug_ops:[('Hsv', tensor([0.8128, 0.4733, 1.0000])), ('sharpen', tensor([0.5234]))]
[2022-08-22 05:04:14,970] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 84	 Inner Train loss: 0.6354, acc=0.7583, lr=0.000000	
[2022-08-22 05:05:07,900] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 84	 Test loss: 0.6368, score: 0.7692
[2022-08-22 05:05:07,901] implicit-augment.py->main line:454 [INFO]85% (85/100)
[2022-08-22 05:05:08,918] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8167, -7.2594, -4.3593, -2.8747, -5.2820, -2.4849,  1.6335, -2.2072,
        -2.4849, -5.3624, -3.2511, -1.7553, -0.5341, -3.4130, -4.3734])
[2022-08-22 05:05:08,924] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.4660, -0.3272,  0.0000, -0.3198,  0.2889, -0.4076,
        -1.2802,  0.5553])
[2022-08-22 05:05:09,221] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 85, batch_idx: 0, global_img_step: 492, aug_ops:[('Rotate', tensor([-0.0629]))]
[2022-08-22 05:05:09,222] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.003060	gLtNorm 0.0367 (0.0367)	gLvNorm 0.0503 (0.0503)	mvpNorm 0.1182 (0.1182)

[2022-08-22 05:27:30,191] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 85, batch_idx: 2500, global_img_step: 493, aug_ops:[('contrast', tensor([0.7520]))]
[2022-08-22 05:27:30,192] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.003060	gLtNorm 0.0592 (0.7315)	gLvNorm 0.0204 (0.2778)	mvpNorm 0.0397 (1.0337)

[2022-08-22 05:50:10,431] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 85, batch_idx: 5000, global_img_step: 494, aug_ops:[('Rotate', tensor([-0.1798])), ('TranslateX', tensor([0.0201])), ('TranslateY', tensor([0.2781])), ('ShearX', tensor([0.5123])), ('Equalize', tensor([-0.1334]))]
[2022-08-22 05:50:10,432] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.003060	gLtNorm 0.0224 (0.7294)	gLvNorm 0.0078 (0.2759)	mvpNorm 0.0074 (1.0212)

[2022-08-22 05:51:17,805] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 85, batch_idx: 0, global_img_step: 495, aug_ops:[('brightness', tensor([0.2108]))]
[2022-08-22 06:05:29,805] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 85, batch_idx: 1000, global_img_step: 496, aug_ops:[('contrast', tensor([-0.0437])), ('saturation', tensor([-1.])), ('Hsv', tensor([-0.1157, -0.0805, -0.7162])), ('sharpen', tensor([-0.9231])), ('Rotate', tensor([0.4301])), ('TranslateY', tensor([-0.3906])), ('ShearX', tensor([0.1789])), ('Equalize', tensor([0.1215]))]
[2022-08-22 06:19:40,882] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 85, batch_idx: 2000, global_img_step: 497, aug_ops:[('brightness', tensor([0.6664])), ('TranslateY', tensor([-0.4300])), ('Equalize', tensor([0.6664]))]
[2022-08-22 06:27:36,613] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 85	 Inner Train loss: 0.6304, acc=0.7608, lr=0.000000	
[2022-08-22 06:28:29,338] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 85	 Test loss: 0.6370, score: 0.7686
[2022-08-22 06:28:29,339] implicit-augment.py->main line:454 [INFO]86% (86/100)
[2022-08-22 06:28:30,349] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8473, -7.2900, -4.3899, -2.8441, -5.2514, -2.4849,  1.6641, -2.2072,
        -2.4849, -5.3930, -3.2817, -1.7859, -0.5035, -3.4436, -4.4040])
[2022-08-22 06:28:30,354] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2352,  0.4354, -0.3272,  0.0000, -0.3198,  0.2889, -0.4076,
        -1.2802,  0.5553])
[2022-08-22 06:28:30,533] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 86, batch_idx: 0, global_img_step: 498, aug_ops:[('TranslateX', tensor([-0.9281])), ('TranslateY', tensor([-1.]))]
[2022-08-22 06:28:30,534] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.002679	gLtNorm 0.0253 (0.0253)	gLvNorm 5.3117 (5.3117)	mvpNorm 5.7966 (5.7966)

[2022-08-22 06:50:44,903] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 86, batch_idx: 2500, global_img_step: 499, aug_ops:[('contrast', tensor([0.6360])), ('Rotate', tensor([0.2970]))]
[2022-08-22 06:50:44,905] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.002679	gLtNorm 0.0225 (0.4824)	gLvNorm 0.0089 (0.2477)	mvpNorm 0.0116 (0.7307)

[2022-08-22 07:13:04,796] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 86, batch_idx: 5000, global_img_step: 500, aug_ops:[('brightness', tensor([-0.2982])), ('saturation', tensor([0.2678])), ('Hsv', tensor([-0.4711, -0.9657, -0.2561])), ('Hed', tensor([-0.0955,  0.2397,  0.1569]))]
[2022-08-22 07:13:04,797] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.002679	gLtNorm 0.2871 (0.5084)	gLvNorm 0.0604 (0.2412)	mvpNorm 0.3613 (0.7520)

[2022-08-22 07:14:11,744] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 86, batch_idx: 0, global_img_step: 501, aug_ops:[('Hed', tensor([0.4335, 0.9585, 0.4615])), ('Rotate', tensor([-1.])), ('Equalize', tensor([0.1767]))]
[2022-08-22 07:28:24,423] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 86, batch_idx: 1000, global_img_step: 502, aug_ops:[('Hed', tensor([-0.2289,  0.5183, -0.4103])), ('Rotate', tensor([-0.0380])), ('TranslateY', tensor([0.5819]))]
[2022-08-22 07:42:34,561] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 86, batch_idx: 2000, global_img_step: 503, aug_ops:[('saturation', tensor([-0.1833])), ('Hsv', tensor([-0.4772,  0.0404, -0.0395])), ('sharpen', tensor([0.1736])), ('Rotate', tensor([-0.4642])), ('TranslateX', tensor([0.8412]))]
[2022-08-22 07:50:31,400] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 86	 Inner Train loss: 0.6340, acc=0.7589, lr=0.000000	
[2022-08-22 07:51:24,284] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 86	 Test loss: 0.6301, score: 0.7701
[2022-08-22 07:51:24,285] implicit-augment.py->main line:454 [INFO]87% (87/100)
[2022-08-22 07:51:25,317] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8741, -7.3168, -4.3631, -2.8709, -5.2782, -2.4849,  1.6373, -2.2072,
        -2.4849, -5.3662, -3.2549, -1.7592, -0.4767, -3.4168, -4.4308])
[2022-08-22 07:51:25,323] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4354, -0.3272,  0.0000, -0.3198,  0.2889, -0.4076,
        -1.2802,  0.5821])
[2022-08-22 07:51:25,590] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 87, batch_idx: 0, global_img_step: 504, aug_ops:[('saturation', tensor([0.7186]))]
[2022-08-22 07:51:25,591] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.002323	gLtNorm 0.1091 (0.1091)	gLvNorm 0.0458 (0.0458)	mvpNorm 0.2569 (0.2569)

[2022-08-22 08:13:47,678] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 87, batch_idx: 2500, global_img_step: 505, aug_ops:[('contrast', tensor([0.0329])), ('ShearX', tensor([0.3313])), ('Equalize', tensor([-1.]))]
[2022-08-22 08:13:47,680] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.002323	gLtNorm 0.0207 (0.6330)	gLvNorm 0.5133 (0.2587)	mvpNorm 0.6820 (0.8886)

[2022-08-22 08:36:07,584] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 87, batch_idx: 5000, global_img_step: 506, aug_ops:[('saturation', tensor([-0.0310])), ('Hed', tensor([-0.4899,  0.4736,  0.1950])), ('ShearY', tensor([0.4984]))]
[2022-08-22 08:36:07,585] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.002323	gLtNorm 0.0181 (0.6710)	gLvNorm 0.0322 (0.2594)	mvpNorm 0.0607 (0.9260)

[2022-08-22 08:37:14,858] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 87, batch_idx: 0, global_img_step: 507, aug_ops:[('ShearX', tensor([-1.]))]
[2022-08-22 08:51:24,501] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 87, batch_idx: 1000, global_img_step: 508, aug_ops:[('contrast', tensor([0.8850])), ('saturation', tensor([0.1003])), ('TranslateY', tensor([0.0121]))]
[2022-08-22 09:05:36,441] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 87, batch_idx: 2000, global_img_step: 509, aug_ops:[('brightness', tensor([-0.4068])), ('Hsv', tensor([0.1574, 0.1976, 1.0000])), ('gaussian blur', tensor([0.1654])), ('TranslateX', tensor([-0.4018]))]
[2022-08-22 09:13:31,485] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 87	 Inner Train loss: 0.6360, acc=0.7583, lr=0.000000	
[2022-08-22 09:14:24,403] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 87	 Test loss: 0.6329, score: 0.7702
[2022-08-22 09:14:24,405] implicit-augment.py->main line:454 [INFO]88% (88/100)
[2022-08-22 09:14:25,412] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.8971, -7.3400, -4.3862, -2.8941, -5.3014, -2.4849,  1.6143, -2.2072,
        -2.4849, -5.3894, -3.2317, -1.7824, -0.4535, -3.4400, -4.4076])
[2022-08-22 09:14:25,418] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7647, -0.7647, -0.3219,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4586, -0.3272,  0.0000, -0.3198,  0.2889, -0.4309,
        -1.2802,  0.5821])
[2022-08-22 09:14:25,657] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 88, batch_idx: 0, global_img_step: 510, aug_ops:[('Equalize', tensor([0.3237]))]
[2022-08-22 09:14:25,658] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.001991	gLtNorm 0.0577 (0.0577)	gLvNorm 0.0773 (0.0773)	mvpNorm 0.2280 (0.2280)

[2022-08-22 09:36:46,146] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 88, batch_idx: 2500, global_img_step: 511, aug_ops:[('sharpen', tensor([0.4909])), ('gaussian noise', tensor([-0.4309])), ('Equalize', tensor([0.0031]))]
[2022-08-22 09:36:46,147] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.001991	gLtNorm 0.0082 (0.7162)	gLvNorm 0.0224 (0.2472)	mvpNorm 0.0109 (0.9476)

[2022-08-22 09:59:32,110] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 88, batch_idx: 5000, global_img_step: 512, aug_ops:[('brightness', tensor([-0.0054])), ('contrast', tensor([-0.2907])), ('gaussian blur', tensor([0.4093])), ('ShearX', tensor([0.4508])), ('ShearY', tensor([0.7252])), ('Equalize', tensor([-0.0054]))]
[2022-08-22 09:59:32,111] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.001991	gLtNorm 0.6034 (0.6990)	gLvNorm 0.3369 (0.2472)	mvpNorm 1.5522 (0.9360)

[2022-08-22 10:00:39,968] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 88, batch_idx: 0, global_img_step: 513, aug_ops:[('Hed', tensor([-0.0744,  0.2273, -1.0000])), ('elastic transform', tensor([0.7491]))]
[2022-08-22 10:14:59,095] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 88, batch_idx: 1000, global_img_step: 514, aug_ops:[('Hsv', tensor([-0.2262, -0.1793,  0.1990])), ('sharpen', tensor([0.4693])), ('TranslateX', tensor([0.6943])), ('ShearX', tensor([0.4342]))]
[2022-08-22 10:29:16,282] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 88, batch_idx: 2000, global_img_step: 515, aug_ops:[('brightness', tensor([-0.1154])), ('TranslateX', tensor([-0.2502]))]
[2022-08-22 10:37:21,252] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 88	 Inner Train loss: 0.6349, acc=0.7584, lr=0.000000	
[2022-08-22 10:38:14,016] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 88	 Test loss: 0.6357, score: 0.7696
[2022-08-22 10:38:14,017] implicit-augment.py->main line:454 [INFO]89% (89/100)
[2022-08-22 10:38:15,039] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9171, -7.3598, -4.4061, -2.9140, -5.3213, -2.4849,  1.6342, -2.2072,
        -2.4849, -5.3695, -3.2516, -1.7625, -0.4734, -3.4201, -4.4275])
[2022-08-22 10:38:15,045] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7448, -0.7448, -0.3020,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4785, -0.3272,  0.0000, -0.3198,  0.2889, -0.4309,
        -1.2802,  0.5821])
[2022-08-22 10:38:15,268] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 89, batch_idx: 0, global_img_step: 516, aug_ops:[('Hed', tensor([ 0.2665, -0.3611,  0.4105])), ('gaussian blur', tensor([0.1446])), ('TranslateX', tensor([-0.0681])), ('ShearX', tensor([-0.5549])), ('Equalize', tensor([-0.2327]))]
[2022-08-22 10:38:15,269] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.001684	gLtNorm 0.0157 (0.0157)	gLvNorm 0.4675 (0.4675)	mvpNorm 0.6245 (0.6245)

[2022-08-22 11:00:47,557] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 89, batch_idx: 2500, global_img_step: 517, aug_ops:[('ShearY', tensor([0.1884]))]
[2022-08-22 11:00:47,558] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.001684	gLtNorm 0.0762 (0.5555)	gLvNorm 0.0396 (0.2628)	mvpNorm 0.1769 (0.8377)

[2022-08-22 11:23:15,976] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 89, batch_idx: 5000, global_img_step: 518, aug_ops:[('saturation', tensor([0.1975])), ('TranslateY', tensor([1.])), ('ShearX', tensor([0.1413]))]
[2022-08-22 11:23:15,977] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.001684	gLtNorm 0.3426 (0.5279)	gLvNorm 0.0342 (0.2631)	mvpNorm 0.3072 (0.8025)

[2022-08-22 11:24:24,426] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 89, batch_idx: 0, global_img_step: 519, aug_ops:[('saturation', tensor([0.7650])), ('TranslateX', tensor([-0.9942]))]
[2022-08-22 11:38:38,037] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 89, batch_idx: 1000, global_img_step: 520, aug_ops:[('brightness', tensor([0.4158])), ('Hed', tensor([0.9266, 0.2694, 0.0898])), ('sharpen', tensor([-0.5105])), ('elastic transform', tensor([-0.1783])), ('ShearY', tensor([-0.3608])), ('Equalize', tensor([0.4158]))]
[2022-08-22 11:52:53,707] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 89, batch_idx: 2000, global_img_step: 521, aug_ops:[('brightness', tensor([-0.0543])), ('Hsv', tensor([-0.7148, -0.5401, -0.3950])), ('gaussian blur', tensor([0.2308])), ('sharpen', tensor([-0.4457])), ('Rotate', tensor([0.2263])), ('TranslateX', tensor([0.0915])), ('TranslateY', tensor([0.1376])), ('Equalize', tensor([-0.0543]))]
[2022-08-22 12:00:49,903] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 89	 Inner Train loss: 0.6339, acc=0.7594, lr=0.000000	
[2022-08-22 12:01:42,783] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 89	 Test loss: 0.6340, score: 0.7694
[2022-08-22 12:01:42,785] implicit-augment.py->main line:454 [INFO]90% (90/100)
[2022-08-22 12:01:43,806] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9339, -7.3429, -4.3893, -2.9309, -5.3044, -2.4849,  1.6174, -2.2072,
        -2.4849, -5.3526, -3.2684, -1.7793, -0.4566, -3.4369, -4.4106])
[2022-08-22 12:01:43,812] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4617, -0.3272,  0.0000, -0.3198,  0.2889, -0.4309,
        -1.2802,  0.5653])
[2022-08-22 12:01:44,089] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 90, batch_idx: 0, global_img_step: 522, aug_ops:[('saturation', tensor([0.2114])), ('Hsv', tensor([0.0468, 0.7076, 0.2392])), ('Hed', tensor([-0.1834,  0.0304, -0.1230])), ('ShearX', tensor([0.3669]))]
[2022-08-22 12:01:44,090] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.001403	gLtNorm 0.7460 (0.7460)	gLvNorm 0.2397 (0.2397)	mvpNorm 1.6478 (1.6478)

[2022-08-22 12:24:08,799] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 90, batch_idx: 2500, global_img_step: 523, aug_ops:[('sharpen', tensor([0.1111])), ('Rotate', tensor([-1.])), ('TranslateX', tensor([-0.0501])), ('TranslateY', tensor([-0.3987])), ('ShearX', tensor([0.1847]))]
[2022-08-22 12:24:08,800] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.001403	gLtNorm 0.0229 (0.5878)	gLvNorm 0.1634 (0.2426)	mvpNorm 0.1868 (0.8321)

[2022-08-22 12:46:36,974] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 90, batch_idx: 5000, global_img_step: 524, aug_ops:[('contrast', tensor([0.0343])), ('Rotate', tensor([0.1098])), ('TranslateY', tensor([0.1531]))]
[2022-08-22 12:46:36,975] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.001403	gLtNorm 1.7790 (0.6076)	gLvNorm 0.0039 (0.2414)	mvpNorm 1.7756 (0.8560)

[2022-08-22 12:47:44,762] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 90, batch_idx: 0, global_img_step: 525, aug_ops:[('saturation', tensor([-0.0807])), ('elastic transform', tensor([0.3133])), ('Equalize', tensor([-0.5505]))]
[2022-08-22 13:02:02,605] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 90, batch_idx: 1000, global_img_step: 526, aug_ops:[('Rotate', tensor([0.2241]))]
[2022-08-22 13:16:12,349] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 90, batch_idx: 2000, global_img_step: 527, aug_ops:[('brightness', tensor([-0.0977])), ('ShearY', tensor([-0.9003])), ('Equalize', tensor([-0.0977]))]
[2022-08-22 13:24:09,667] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 90	 Inner Train loss: 0.6358, acc=0.7584, lr=0.000000	
[2022-08-22 13:25:02,429] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 90	 Test loss: 0.6356, score: 0.7714
[2022-08-22 13:25:02,429] implicit-augment.py->main line:454 [INFO]91% (91/100)
[2022-08-22 13:25:03,586] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9479, -7.3289, -4.3753, -2.9449, -5.3185, -2.4849,  1.6314, -2.2072,
        -2.4849, -5.3387, -3.2544, -1.7933, -0.4425, -3.4229, -4.4247])
[2022-08-22 13:25:03,594] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4476, -0.3272,  0.0000, -0.3198,  0.2889, -0.4309,
        -1.2662,  0.5653])
[2022-08-22 13:25:03,829] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 91, batch_idx: 0, global_img_step: 528, aug_ops:[('brightness', tensor([-0.4926])), ('Hsv', tensor([-0.2327, -0.1026,  0.0654])), ('Hed', tensor([0.1575, 0.2581, 0.1074])), ('sharpen', tensor([-0.0370]))]
[2022-08-22 13:25:03,829] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.001148	gLtNorm 0.1207 (0.1207)	gLvNorm 0.7636 (0.7636)	mvpNorm 1.4241 (1.4241)

[2022-08-22 13:47:26,458] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 91, batch_idx: 2500, global_img_step: 529, aug_ops:[('contrast', tensor([-0.2948])), ('saturation', tensor([0.2724])), ('Rotate', tensor([0.0344])), ('TranslateX', tensor([-0.5631]))]
[2022-08-22 13:47:26,459] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.001148	gLtNorm 0.0152 (0.8184)	gLvNorm 0.1862 (0.2674)	mvpNorm 0.1137 (1.0827)

[2022-08-22 14:10:27,028] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 91, batch_idx: 5000, global_img_step: 530, aug_ops:[('saturation', tensor([0.6551])), ('Hsv', tensor([-0.9877, -1.0000, -1.0000])), ('elastic transform', tensor([-0.4189]))]
[2022-08-22 14:10:27,029] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.001148	gLtNorm 21.0559 (0.7544)	gLvNorm 0.7456 (0.2641)	mvpNorm 21.2824 (1.0115)

[2022-08-22 14:11:34,387] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 91, batch_idx: 0, global_img_step: 531, aug_ops:[('contrast', tensor([0.3559])), ('elastic transform', tensor([0.3984])), ('TranslateY', tensor([0.7408]))]
[2022-08-22 14:25:50,197] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 91, batch_idx: 1000, global_img_step: 532, aug_ops:[('idenity', [1.0])]
[2022-08-22 14:40:06,986] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 91, batch_idx: 2000, global_img_step: 533, aug_ops:[('Equalize', tensor([-0.3223]))]
[2022-08-22 14:48:03,880] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 91	 Inner Train loss: 0.6362, acc=0.7576, lr=0.000000	
[2022-08-22 14:48:56,602] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 91	 Test loss: 0.6410, score: 0.7689
[2022-08-22 14:48:56,604] implicit-augment.py->main line:454 [INFO]92% (92/100)
[2022-08-22 14:48:57,685] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9364, -7.3403, -4.3868, -2.9334, -5.3299, -2.4849,  1.6429, -2.2072,
        -2.4849, -5.3502, -3.2659, -1.7819, -0.4310, -3.4344, -4.4361])
[2022-08-22 14:48:57,690] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4591, -0.3272,  0.0000, -0.3198,  0.2889, -0.4309,
        -1.2547,  0.5653])
[2022-08-22 14:48:57,842] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 92, batch_idx: 0, global_img_step: 534, aug_ops:[('Hsv', tensor([-0.3442, -0.3476, -0.4552])), ('Hed', tensor([-0.9012,  0.2167, -0.3890])), ('elastic transform', tensor([0.0238])), ('TranslateY', tensor([-0.4916]))]
[2022-08-22 14:48:57,842] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000919	gLtNorm 0.0336 (0.0336)	gLvNorm 0.0067 (0.0067)	mvpNorm 0.0631 (0.0631)

[2022-08-22 15:11:33,308] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 92, batch_idx: 2500, global_img_step: 535, aug_ops:[('brightness', tensor([-0.0035])), ('contrast', tensor([1.])), ('Hed', tensor([ 1.0000, -0.4021,  0.1320])), ('ShearY', tensor([0.4079]))]
[2022-08-22 15:11:33,309] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000919	gLtNorm 0.1195 (0.5087)	gLvNorm 0.0817 (0.2335)	mvpNorm 0.3284 (0.7307)

[2022-08-22 15:34:19,220] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 92, batch_idx: 5000, global_img_step: 536, aug_ops:[('Equalize', tensor([-0.4559]))]
[2022-08-22 15:34:19,222] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000919	gLtNorm 0.0258 (0.5268)	gLvNorm 0.2457 (0.2366)	mvpNorm 0.3467 (0.7628)

[2022-08-22 15:35:27,391] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 92, batch_idx: 0, global_img_step: 537, aug_ops:[('brightness', tensor([-0.1173])), ('Hsv', tensor([-0.0681, -0.4783, -0.3461])), ('Hed', tensor([ 1.0000, -0.0517,  0.9496])), ('TranslateX', tensor([0.3521]))]
[2022-08-22 15:49:53,346] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 92, batch_idx: 1000, global_img_step: 538, aug_ops:[('Hsv', tensor([ 0.6993, -0.0037, -0.1934]))]
[2022-08-22 16:04:21,184] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 92, batch_idx: 2000, global_img_step: 539, aug_ops:[('idenity', [1.0])]
[2022-08-22 16:12:26,585] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 92	 Inner Train loss: 0.6357, acc=0.7580, lr=0.000000	
[2022-08-22 16:13:19,411] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 92	 Test loss: 0.6377, score: 0.7726
[2022-08-22 16:13:19,411] implicit-augment.py->main line:454 [INFO]93% (93/100)
[2022-08-22 16:13:20,409] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9273, -7.3495, -4.3959, -2.9426, -5.3208, -2.4849,  1.6337, -2.2072,
        -2.4849, -5.3594, -3.2751, -1.7911, -0.4402, -3.4252, -4.4269])
[2022-08-22 16:13:20,413] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4683, -0.3272,  0.0000, -0.3290,  0.2889, -0.4309,
        -1.2547,  0.5653])
[2022-08-22 16:13:20,680] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 93, batch_idx: 0, global_img_step: 540, aug_ops:[('Hed', tensor([-0.5706,  0.1331, -0.4239]))]
[2022-08-22 16:13:20,681] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000716	gLtNorm 1.4377 (1.4377)	gLvNorm 0.0704 (0.0704)	mvpNorm 2.0578 (2.0578)

[2022-08-22 16:36:03,173] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 93, batch_idx: 2500, global_img_step: 541, aug_ops:[('brightness', tensor([-0.6847])), ('sharpen', tensor([-0.5440])), ('TranslateY', tensor([0.8424])), ('ShearY', tensor([0.0321]))]
[2022-08-22 16:36:03,174] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000716	gLtNorm 0.0603 (0.5660)	gLvNorm 0.1730 (0.2731)	mvpNorm 0.1202 (0.8270)

[2022-08-22 16:58:46,663] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 93, batch_idx: 5000, global_img_step: 542, aug_ops:[('saturation', tensor([-0.0595])), ('gaussian noise', tensor([0.7682])), ('Rotate', tensor([-0.5022])), ('ShearY', tensor([-0.1438]))]
[2022-08-22 16:58:46,664] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000716	gLtNorm 0.5269 (0.5574)	gLvNorm 0.6241 (0.2693)	mvpNorm 0.0936 (0.8185)

[2022-08-22 16:59:55,077] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 93, batch_idx: 0, global_img_step: 543, aug_ops:[('brightness', tensor([-0.8376])), ('ShearX', tensor([-1.])), ('ShearY', tensor([0.6123]))]
[2022-08-22 17:15:04,914] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 93, batch_idx: 1000, global_img_step: 544, aug_ops:[('brightness', tensor([0.2461])), ('Equalize', tensor([0.2461]))]
[2022-08-22 17:29:26,675] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 93, batch_idx: 2000, global_img_step: 545, aug_ops:[('Hsv', tensor([ 0.3465,  0.5385, -0.7059])), ('gaussian noise', tensor([0.2262])), ('ShearX', tensor([0.3625])), ('Equalize', tensor([0.3944]))]
[2022-08-22 17:37:34,292] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 93	 Inner Train loss: 0.6294, acc=0.7609, lr=0.000000	
[2022-08-22 17:38:27,040] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 93	 Test loss: 0.6347, score: 0.7698
[2022-08-22 17:38:27,041] implicit-augment.py->main line:454 [INFO]94% (94/100)
[2022-08-22 17:38:28,088] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9344, -7.3424, -4.3888, -2.9497, -5.3279, -2.4849,  1.6266, -2.2072,
        -2.4849, -5.3665, -3.2679, -1.7839, -0.4331, -3.4323, -4.4198])
[2022-08-22 17:38:28,094] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2612,  0.4755, -0.3272,  0.0000, -0.3290,  0.2889, -0.4309,
        -1.2547,  0.5653])
[2022-08-22 17:38:28,318] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 94, batch_idx: 0, global_img_step: 546, aug_ops:[('sharpen', tensor([-0.2465])), ('TranslateX', tensor([-0.1385])), ('ShearY', tensor([-0.6012]))]
[2022-08-22 17:38:28,319] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000540	gLtNorm 0.0840 (0.0840)	gLvNorm 0.0837 (0.0837)	mvpNorm 0.1527 (0.1527)

[2022-08-22 18:01:08,340] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 94, batch_idx: 2500, global_img_step: 547, aug_ops:[('Hsv', tensor([-0.1262,  0.2588, -0.0036])), ('sharpen', tensor([1.])), ('ShearY', tensor([1.]))]
[2022-08-22 18:01:08,342] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000540	gLtNorm 0.1148 (0.5839)	gLvNorm 0.5874 (0.2555)	mvpNorm 0.2479 (0.8297)

[2022-08-22 18:23:47,246] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 94, batch_idx: 5000, global_img_step: 548, aug_ops:[('contrast', tensor([-0.0772])), ('elastic transform', tensor([0.1631])), ('Equalize', tensor([-0.0814]))]
[2022-08-22 18:23:47,247] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000540	gLtNorm 0.0718 (0.5282)	gLvNorm 0.0704 (0.2573)	mvpNorm 0.0186 (0.7739)

[2022-08-22 18:24:54,924] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 94, batch_idx: 0, global_img_step: 549, aug_ops:[('ShearY', tensor([0.1267])), ('Equalize', tensor([0.1815]))]
[2022-08-22 18:39:18,039] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 94, batch_idx: 1000, global_img_step: 550, aug_ops:[('contrast', tensor([-0.1129])), ('sharpen', tensor([0.7251])), ('Equalize', tensor([-0.3606]))]
[2022-08-22 18:53:33,025] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 94, batch_idx: 2000, global_img_step: 551, aug_ops:[('Hsv', tensor([-1.0000, -0.7515, -0.3071])), ('elastic transform', tensor([0.1753])), ('ShearX', tensor([1.]))]
[2022-08-22 19:01:26,047] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 94	 Inner Train loss: 0.6309, acc=0.7600, lr=0.000000	
[2022-08-22 19:02:18,732] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 94	 Test loss: 0.6338, score: 0.7730
[2022-08-22 19:02:18,733] implicit-augment.py->main line:454 [INFO]95% (95/100)
[2022-08-22 19:02:19,756] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9290, -7.3370, -4.3834, -2.9551, -5.3333, -2.4849,  1.6320, -2.2072,
        -2.4849, -5.3719, -3.2733, -1.7893, -0.4385, -3.4269, -4.4252])
[2022-08-22 19:02:19,763] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2666,  0.4701, -0.3272,  0.0000, -0.3290,  0.2889, -0.4363,
        -1.2601,  0.5653])
[2022-08-22 19:02:19,999] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 95, batch_idx: 0, global_img_step: 552, aug_ops:[('saturation', tensor([-0.0330])), ('Hsv', tensor([-0.0104,  0.0291, -0.1285])), ('ShearX', tensor([-0.3615]))]
[2022-08-22 19:02:19,999] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000391	gLtNorm 0.1860 (0.1860)	gLvNorm 1.6188 (1.6188)	mvpNorm 2.3838 (2.3838)

[2022-08-22 19:24:35,541] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 95, batch_idx: 2500, global_img_step: 553, aug_ops:[('brightness', tensor([-0.0571])), ('TranslateX', tensor([0.2017])), ('ShearY', tensor([0.7593]))]
[2022-08-22 19:24:35,542] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000391	gLtNorm 0.0403 (0.9038)	gLvNorm 0.0391 (0.3291)	mvpNorm 0.0031 (1.1951)

[2022-08-22 19:46:50,649] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 95, batch_idx: 5000, global_img_step: 554, aug_ops:[('saturation', tensor([-0.1449])), ('Hsv', tensor([0.8354, 0.5975, 0.0278])), ('Rotate', tensor([0.2461])), ('TranslateY', tensor([-0.1640]))]
[2022-08-22 19:46:50,651] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000391	gLtNorm 0.5027 (0.9235)	gLvNorm 0.0100 (0.3312)	mvpNorm 0.5771 (1.2191)

[2022-08-22 19:47:57,785] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 95, batch_idx: 0, global_img_step: 555, aug_ops:[('brightness', tensor([0.0836])), ('Hed', tensor([ 0.5441,  0.0090, -0.8050])), ('elastic transform', tensor([0.8162])), ('Equalize', tensor([0.0836]))]
[2022-08-22 20:01:57,800] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 95, batch_idx: 1000, global_img_step: 556, aug_ops:[('sharpen', tensor([-0.7541])), ('Equalize', tensor([0.2257]))]
[2022-08-22 20:15:58,805] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 95, batch_idx: 2000, global_img_step: 557, aug_ops:[('ShearY', tensor([-0.1594]))]
[2022-08-22 20:23:51,031] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 95	 Inner Train loss: 0.6388, acc=0.7575, lr=0.000000	
[2022-08-22 20:24:43,806] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 95	 Test loss: 0.6317, score: 0.7669
[2022-08-22 20:24:43,808] implicit-augment.py->main line:454 [INFO]96% (96/100)
[2022-08-22 20:24:44,842] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9329, -7.3331, -4.3795, -2.9591, -5.3294, -2.4849,  1.6359, -2.2072,
        -2.4849, -5.3680, -3.2694, -1.7854, -0.4424, -3.4230, -4.4291])
[2022-08-22 20:24:44,848] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2666,  0.4662, -0.3272,  0.0000, -0.3290,  0.2889, -0.4323,
        -1.2640,  0.5653])
[2022-08-22 20:24:45,168] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 96, batch_idx: 0, global_img_step: 558, aug_ops:[('brightness', tensor([-0.8704]))]
[2022-08-22 20:24:45,169] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000268	gLtNorm 0.0473 (0.0473)	gLvNorm 1.4796 (1.4796)	mvpNorm 1.5588 (1.5588)

[2022-08-22 20:47:01,545] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 96, batch_idx: 2500, global_img_step: 559, aug_ops:[('sharpen', tensor([-0.0107])), ('Equalize', tensor([-0.2631]))]
[2022-08-22 20:47:01,546] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000268	gLtNorm 0.0805 (0.5017)	gLvNorm 0.2713 (0.2224)	mvpNorm 0.1506 (0.7163)

[2022-08-22 21:09:16,795] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 96, batch_idx: 5000, global_img_step: 560, aug_ops:[('saturation', tensor([-0.0992])), ('ShearY', tensor([-0.1568]))]
[2022-08-22 21:09:16,796] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000268	gLtNorm 0.0290 (0.4686)	gLvNorm 0.0250 (0.2242)	mvpNorm 0.0020 (0.6806)

[2022-08-22 21:10:24,295] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 96, batch_idx: 0, global_img_step: 561, aug_ops:[('sharpen', tensor([-0.6604])), ('Rotate', tensor([-0.1265])), ('ShearX', tensor([0.6275]))]
[2022-08-22 21:24:25,233] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 96, batch_idx: 1000, global_img_step: 562, aug_ops:[('contrast', tensor([-0.0950])), ('sharpen', tensor([-0.2077])), ('Rotate', tensor([0.2463])), ('ShearY', tensor([-0.5958]))]
[2022-08-22 21:38:25,216] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 96, batch_idx: 2000, global_img_step: 563, aug_ops:[('brightness', tensor([0.0639])), ('TranslateY', tensor([-0.1749])), ('ShearX', tensor([0.8685])), ('ShearY', tensor([-0.3098]))]
[2022-08-22 21:46:15,522] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 96	 Inner Train loss: 0.6352, acc=0.7580, lr=0.000000	
[2022-08-22 21:47:08,086] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 96	 Test loss: 0.6353, score: 0.7720
[2022-08-22 21:47:08,087] implicit-augment.py->main line:454 [INFO]97% (97/100)
[2022-08-22 21:47:09,086] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9302, -7.3304, -4.3768, -2.9617, -5.3321, -2.4849,  1.6332, -2.2072,
        -2.4849, -5.3707, -3.2667, -1.7881, -0.4451, -3.4203, -4.4264])
[2022-08-22 21:47:09,092] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2666,  0.4635, -0.3272,  0.0000, -0.3290,  0.2889, -0.4323,
        -1.2640,  0.5653])
[2022-08-22 21:47:09,345] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 97, batch_idx: 0, global_img_step: 564, aug_ops:[('Hsv', tensor([ 0.1396,  0.0141, -0.2941])), ('TranslateY', tensor([-0.0620])), ('ShearY', tensor([-0.1432]))]
[2022-08-22 21:47:09,346] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000173	gLtNorm 0.0041 (0.0041)	gLvNorm 0.0281 (0.0281)	mvpNorm 0.0202 (0.0202)

[2022-08-22 22:09:33,548] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 97, batch_idx: 2500, global_img_step: 565, aug_ops:[('saturation', tensor([-0.6118])), ('Hed', tensor([0.0648, 0.3054, 0.2114]))]
[2022-08-22 22:09:33,550] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000173	gLtNorm 0.0762 (0.5265)	gLvNorm 0.1560 (0.2621)	mvpNorm 0.0886 (0.7718)

[2022-08-22 22:31:45,530] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 97, batch_idx: 5000, global_img_step: 566, aug_ops:[('Rotate', tensor([0.5525]))]
[2022-08-22 22:31:45,531] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000173	gLtNorm 0.1866 (0.5120)	gLvNorm 0.1564 (0.2667)	mvpNorm 0.0099 (0.7595)

[2022-08-22 22:32:52,841] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 97, batch_idx: 0, global_img_step: 567, aug_ops:[('contrast', tensor([0.2628])), ('sharpen', tensor([-0.0171])), ('Rotate', tensor([-0.6339])), ('Equalize', tensor([0.1002]))]
[2022-08-22 22:46:53,443] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 97, batch_idx: 1000, global_img_step: 568, aug_ops:[('Hsv', tensor([0.0453, 0.4567, 0.5309])), ('sharpen', tensor([-0.8192])), ('TranslateY', tensor([0.0441]))]
[2022-08-22 23:00:52,745] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 97, batch_idx: 2000, global_img_step: 569, aug_ops:[('TranslateX', tensor([-0.9328])), ('ShearX', tensor([-0.0291])), ('Equalize', tensor([-0.0357]))]
[2022-08-22 23:08:43,900] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 97	 Inner Train loss: 0.6319, acc=0.7602, lr=0.000000	
[2022-08-22 23:09:36,599] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 97	 Test loss: 0.6330, score: 0.7717
[2022-08-22 23:09:36,600] implicit-augment.py->main line:454 [INFO]98% (98/100)
[2022-08-22 23:09:37,593] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9285, -7.3287, -4.3751, -2.9635, -5.3338, -2.4849,  1.6315, -2.2072,
        -2.4849, -5.3690, -3.2684, -1.7863, -0.4433, -3.4186, -4.4247])
[2022-08-22 23:09:37,598] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2666,  0.4618, -0.3272,  0.0000, -0.3290,  0.2889, -0.4323,
        -1.2623,  0.5653])
[2022-08-22 23:09:37,774] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 98, batch_idx: 0, global_img_step: 570, aug_ops:[('Hed', tensor([0.0250, 1.0000, 0.2530])), ('ShearY', tensor([-0.2602]))]
[2022-08-22 23:09:37,774] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000105	gLtNorm 0.0021 (0.0021)	gLvNorm 0.1581 (0.1581)	mvpNorm 0.1938 (0.1938)

[2022-08-22 23:31:50,184] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 98, batch_idx: 2500, global_img_step: 571, aug_ops:[('elastic transform', tensor([0.0685])), ('Rotate', tensor([-0.7306])), ('ShearY', tensor([0.5116]))]
[2022-08-22 23:31:50,185] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000105	gLtNorm 0.0215 (0.7431)	gLvNorm 0.0751 (0.2577)	mvpNorm 0.0362 (1.0063)

[2022-08-22 23:54:00,379] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 98, batch_idx: 5000, global_img_step: 572, aug_ops:[('idenity', [1.0])]
[2022-08-22 23:54:00,380] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000105	gLtNorm 0.1521 (0.7191)	gLvNorm 0.0715 (0.2673)	mvpNorm 0.0472 (0.9875)

[2022-08-22 23:55:07,118] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 98, batch_idx: 0, global_img_step: 573, aug_ops:[('gaussian noise', tensor([0.0301])), ('ShearY', tensor([0.7102]))]
[2022-08-23 00:09:06,610] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 98, batch_idx: 1000, global_img_step: 574, aug_ops:[('contrast', tensor([-0.1303])), ('Hed', tensor([ 0.5702,  0.5379, -0.7734])), ('TranslateX', tensor([0.7110])), ('ShearY', tensor([0.7627]))]
[2022-08-23 00:23:05,285] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 98, batch_idx: 2000, global_img_step: 575, aug_ops:[('Hsv', tensor([-0.1590,  0.0247,  0.0345])), ('TranslateX', tensor([-0.8817])), ('Equalize', tensor([0.0155]))]
[2022-08-23 00:30:55,744] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 98	 Inner Train loss: 0.6401, acc=0.7572, lr=0.000000	
[2022-08-23 00:31:48,616] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 98	 Test loss: 0.6376, score: 0.7740
[2022-08-23 00:31:48,617] implicit-augment.py->main line:454 [INFO]99% (99/100)
[2022-08-23 00:31:49,678] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramP_tensor([-3.9275, -7.3276, -4.3740, -2.9645, -5.3328, -2.4849,  1.6304, -2.2072,
        -2.4849, -5.3679, -3.2695, -1.7874, -0.4423, -3.4176, -4.4236])
[2022-08-23 00:31:49,684] automodels.py->Med_hyperHesTrain line:932 [INFO]data point 0 weight: paramM_tensor([-0.2464, -0.4473, -0.2684, -0.7280, -0.7616, -0.3188,  0.9084, -0.3682,
        -1.4487,  0.2666,  0.4607, -0.3272,  0.0000, -0.3290,  0.2889, -0.4323,
        -1.2613,  0.5653])
[2022-08-23 00:31:49,878] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 99, batch_idx: 0, global_img_step: 576, aug_ops:[('saturation', tensor([0.0351])), ('TranslateX', tensor([0.0243])), ('TranslateY', tensor([1.])), ('Equalize', tensor([0.3294]))]
[2022-08-23 00:31:49,878] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 0% (0/5124), task_lr=0.000000, hyper_lr=0.000064	gLtNorm 0.0474 (0.0474)	gLvNorm 0.2541 (0.2541)	mvpNorm 0.1641 (0.1641)

[2022-08-23 00:54:01,502] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 99, batch_idx: 2500, global_img_step: 577, aug_ops:[('contrast', tensor([-0.4818])), ('Rotate', tensor([-0.0973])), ('TranslateX', tensor([-0.5617])), ('ShearX', tensor([-0.1854])), ('ShearY', tensor([-0.9126])), ('Equalize', tensor([0.2413]))]
[2022-08-23 00:54:01,504] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 49% (2500/5124), task_lr=0.000000, hyper_lr=0.000064	gLtNorm 0.0263 (0.7605)	gLvNorm 0.0368 (0.3164)	mvpNorm 0.0034 (1.0465)

[2022-08-23 01:16:13,330] automodels.py->Med_hyperHesTrain line:957 [INFO]hyperTrain epoch: 99, batch_idx: 5000, global_img_step: 578, aug_ops:[('Rotate', tensor([-0.2460])), ('TranslateY', tensor([0.2115])), ('ShearX', tensor([-0.5759]))]
[2022-08-23 01:16:13,331] automodels.py->Med_hyperHesTrain line:963 [INFO]hyperTrain batch 98% (5000/5124), task_lr=0.000000, hyper_lr=0.000064	gLtNorm 0.0446 (0.7251)	gLvNorm 0.0034 (0.3149)	mvpNorm 0.0661 (1.0236)

[2022-08-23 01:17:20,291] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 99, batch_idx: 0, global_img_step: 579, aug_ops:[('gaussian blur', tensor([-0.1582])), ('ShearY', tensor([0.5357])), ('Equalize', tensor([-0.3538]))]
[2022-08-23 01:31:19,217] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 99, batch_idx: 1000, global_img_step: 580, aug_ops:[('gaussian blur', tensor([-0.8474]))]
[2022-08-23 01:45:18,565] automodels.py->Med_innerTrain line:1035 [INFO]Train epoch: 99, batch_idx: 2000, global_img_step: 581, aug_ops:[('brightness', tensor([-0.1296])), ('Hed', tensor([ 0.2635, -0.0421, -0.7579])), ('sharpen', tensor([-1.]))]
[2022-08-23 01:53:08,583] automodels.py->Med_innerTrain line:1047 [INFO]Epoch: 99	 Inner Train loss: 0.6365, acc=0.7578, lr=0.000000	
[2022-08-23 01:54:01,276] automodels.py->Med_innerTest line:1209 [INFO]Epoch: 99	 Test loss: 0.6316, score: 0.7656
[2022-08-23 01:54:01,532] implicit-augment.py->main line:497 [INFO]save train history at: /home/rayeh/Desktop/Project/Med_AutoDO/picture/run1_UNet_e100_opt_HES_est_True_aug_model_SEP_los_model_NONE_ir_1_sr_1.0_nr_0.0.jpg
[2022-08-23 01:54:01,532] implicit-augment.py->main line:499 [INFO]BEST trained model has 0.7740 Dice score

[2022-08-23 03:29:56,267] model_test.py-><module> line:25 [INFO]test new WSI
[2022-08-23 03:30:42,353] model_test.py-><module> line:60 [INFO]test loss: 1.1973849988351917, test score: 0.600185780221431
